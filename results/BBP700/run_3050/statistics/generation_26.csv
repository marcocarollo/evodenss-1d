id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:34 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:87 kernel_size:4 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:28 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:adadelta batch_size:32 epochs:100	100	1000	True	31129.81836		559871	11	-1	212.4201853275299	{'train_loss': [733360.812, 355189.719, 314149.375, 298352.938, 290419.344, 283170.531, 277091.969, 271972.469, 267231.625, 263857.969, 260680.656, 258647.156, 257194.547, 255117.406, 252951.219, 252617.078, 249367.391, 249279.234, 247182.391, 246169.516, 245310.938, 244050.531, 242881.312, 242014.375, 240819.953, 240881.172, 238897.656, 238725.203, 238304.922, 238279.109, 237189.484, 235680.156, 234601.797, 233665.406, 235446.016, 232210.938, 232463.047, 231449.625, 231654.547, 231608.281, 230868.516, 229585.328, 230159.625, 228909.109, 229476.656, 228510.328, 227413.297, 227602.797, 226954.234, 227160.766, 226911.0, 226725.641, 226113.188, 225721.953, 224413.984, 224379.578, 224661.203, 223932.703, 224014.531, 223385.094, 222584.734, 222936.078, 222393.938, 222684.688, 222949.531, 222098.891, 222358.578, 220775.781, 221371.969, 220095.328, 220867.188, 219892.031, 220456.812, 220259.047, 219301.031, 218720.844, 218012.875, 218031.219, 218427.828, 218505.25, 218544.219, 218003.547, 217509.844, 216590.547, 216953.156, 217609.469, 217435.0, 217226.031, 216638.844, 215956.266, 215923.766, 215852.844, 215406.891, 215180.703, 214743.109, 213805.641, 214667.766, 213819.562, 213784.297, 213542.078], 'val_loss': [3442.295, 2977.972, 2829.992, 2785.188, 2750.792, 2662.732, 2620.559, 2591.072, 2578.283, 2537.078, 2527.192, 2522.855, 2531.386, 2504.471, 2464.761, 2477.208, 2449.105, 2462.881, 2437.016, 2405.326, 2391.712, 2399.029, 2376.047, 2372.7, 2363.687, 2368.531, 2348.679, 2338.153, 2339.404, 2325.806, 2325.165, 2318.269, 2315.067, 2323.117, 2300.583, 2296.028, 2308.466, 2311.041, 2305.047, 2267.946, 2277.307, 2276.863, 2258.482, 2254.715, 2278.23, 2263.76, 2243.721, 2234.561, 2241.853, 2265.788, 2231.278, 2248.326, 2244.158, 2226.638, 2225.745, 2227.753, 2232.815, 2220.758, 2228.415, 2221.148, 2226.489, 2220.033, 2239.827, 2226.619, 2227.065, 2217.378, 2219.622, 2201.646, 2209.825, 2213.503, 2220.773, 2202.497, 2221.544, 2204.947, 2213.552, 2209.32, 2204.394, 2197.0, 2215.419, 2205.529, 2177.829, 2186.805, 2189.717, 2204.281, 2207.105, 2202.101, 2194.509, 2162.906, 2192.193, 2179.523, 2180.349, 2187.87, 2196.227, 2168.164, 2202.633, 2167.531, 2164.582, 2165.568, 2175.128, 2180.07]}	100	100	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:34 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:87 kernel_size:4 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:28 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:adadelta batch_size:7 epochs:100	100	1000	True	31767.65039		559871	11	-1	592.0544571876526	{'train_loss': [422153.156, 308645.344, 300982.625, 294756.688, 288790.344, 281270.844, 275762.719, 270560.031, 266950.969, 263427.781, 261257.141, 258736.172, 257024.219, 255480.719, 253002.516, 252260.047, 249688.031, 249614.5, 248495.375, 247074.953, 245360.656, 244507.656, 244058.219, 243638.141, 242341.484, 241421.531, 240184.641, 240100.797, 239441.562, 238567.984, 238223.109, 237669.125, 236497.0, 235731.094, 235294.938, 235719.688, 234745.0, 234608.453, 233199.922, 233829.719, 232783.469, 231465.125, 230885.078, 231694.531, 231354.781, 229706.031, 229903.344, 230010.578, 228457.828, 228164.484, 227352.828, 228476.906, 227988.078, 225930.938, 226508.266, 226771.297, 225399.031, 224816.25, 223732.703, 224016.391, 223946.781, 223359.875, 222386.016, 222066.156, 221428.141, 220496.203, 221177.234, 219726.047, 219824.797, 219249.281, 219917.078, 218403.516, 218242.125, 218115.0, 217593.062, 217904.297, 216276.359, 216395.453, 216029.578, 215980.703, 215951.484, 214932.078, 214948.0, 214775.875, 215704.938, 214808.359, 213029.312, 212747.375, 213038.734, 212899.031, 212162.797, 212753.125, 212269.438, 211483.719, 211290.328, 210846.125, 211127.25, 211028.281, 210107.531, 210308.781], 'val_loss': [647.56, 628.648, 614.93, 604.245, 587.451, 577.182, 567.81, 561.897, 553.967, 557.097, 548.512, 544.394, 542.589, 531.768, 533.474, 525.746, 530.172, 522.21, 520.702, 514.341, 517.99, 513.977, 508.91, 512.173, 505.819, 505.05, 511.883, 503.676, 503.16, 503.285, 502.209, 504.07, 500.143, 498.107, 492.784, 495.7, 500.566, 497.519, 499.838, 494.171, 495.811, 499.458, 493.21, 494.881, 489.519, 491.533, 497.883, 495.054, 490.695, 486.065, 483.148, 485.213, 483.69, 487.136, 494.174, 490.621, 486.157, 487.196, 491.276, 486.618, 486.895, 489.178, 488.143, 492.026, 485.529, 483.262, 478.654, 482.657, 484.044, 482.773, 484.272, 485.251, 483.167, 479.929, 486.313, 480.436, 479.642, 476.818, 480.891, 476.015, 477.001, 478.341, 479.843, 474.43, 473.29, 473.367, 471.356, 476.292, 479.284, 480.622, 477.364, 478.39, 481.804, 478.066, 482.142, 473.041, 481.195, 479.658, 480.984, 474.463]}	100	100	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:34 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:87 kernel_size:4 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:adadelta batch_size:32 epochs:100	100	1000	True	31386.33984		392220	10	-1	206.7608036994934	{'train_loss': [474626.781, 328139.5, 306802.531, 298323.719, 292220.031, 286042.219, 281936.594, 277471.219, 273408.094, 268503.25, 264318.375, 262692.406, 257374.297, 254663.203, 253787.531, 251591.297, 250428.938, 248878.703, 247270.922, 246521.516, 245044.828, 243846.453, 243116.766, 242634.047, 240914.312, 240473.844, 239360.531, 239480.75, 237965.75, 238019.281, 236421.812, 235439.281, 236276.578, 234963.906, 234415.125, 233517.812, 233992.906, 232288.875, 232878.859, 231638.266, 230918.312, 231311.25, 230204.062, 230280.094, 230310.969, 229799.547, 229741.609, 230119.266, 228832.094, 227932.594, 228842.281, 227724.422, 227755.688, 227069.719, 227724.188, 225708.703, 226538.031, 226274.625, 225032.328, 225174.375, 225673.5, 225436.297, 224863.438, 225167.281, 224070.25, 224492.719, 223692.672, 223180.812, 223291.688, 223169.297, 223621.062, 222638.219, 222339.344, 221994.328, 222728.891, 221785.484, 222448.234, 222028.688, 220537.266, 221191.422, 221349.125, 220307.438, 220628.953, 220284.344, 220569.516, 220720.766, 219454.5, 219448.891, 218868.094, 219610.266, 218880.812, 218125.359, 218957.094, 219324.438, 218006.203, 218860.703, 218548.859, 217363.75, 217037.641, 217288.781], 'val_loss': [3129.11, 2886.982, 2805.667, 2767.027, 2726.178, 2710.97, 2632.715, 2611.458, 2549.976, 2542.984, 2504.639, 2494.272, 2489.535, 2424.324, 2407.95, 2413.672, 2403.321, 2373.971, 2372.327, 2357.208, 2348.718, 2366.006, 2356.121, 2336.198, 2330.548, 2344.722, 2338.395, 2334.133, 2336.498, 2359.94, 2313.581, 2318.795, 2306.909, 2307.919, 2307.584, 2314.878, 2288.949, 2296.787, 2311.708, 2273.267, 2273.332, 2264.926, 2309.943, 2273.122, 2249.82, 2272.091, 2278.627, 2278.609, 2280.597, 2273.753, 2260.323, 2258.382, 2272.031, 2261.144, 2262.366, 2242.441, 2239.747, 2260.425, 2250.081, 2262.265, 2241.058, 2248.108, 2234.914, 2267.268, 2231.732, 2231.173, 2233.113, 2240.829, 2242.162, 2254.666, 2246.68, 2239.186, 2245.296, 2249.264, 2225.854, 2242.072, 2243.473, 2250.078, 2233.675, 2217.465, 2223.7, 2229.308, 2218.559, 2227.673, 2232.453, 2229.107, 2226.971, 2220.301, 2216.078, 2209.054, 2211.873, 2219.922, 2209.259, 2213.635, 2203.621, 2218.039, 2214.718, 2211.018, 2208.607, 2208.638]}	100	100	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:34 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:87 kernel_size:4 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:28 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:deconv1d out_channels:84 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:True bias:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:adadelta batch_size:32 epochs:100	100	1000	True	137419.59375		53408244	11	-1	300.724157333374	{'train_loss': [1531415.75, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0], 'val_loss': [10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216]}	100	100	True
