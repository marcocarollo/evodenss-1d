id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	31856.88672		452251	14	-1	234.5948302745819	{'train_loss': [417540.406, 353943.625, 324198.469, 313715.469, 307451.625, 303852.188, 300507.562, 298109.75, 296315.625, 294249.594, 291412.781, 287991.656, 285436.688, 282493.688, 278303.938, 274960.125, 271070.75, 269587.812, 267315.281, 265945.969, 264176.594, 261480.172, 260334.625, 259060.531, 258041.375, 256515.469, 255271.672, 253829.359, 252821.281, 251100.859, 250269.688, 248056.375, 247273.047, 247240.375, 245110.672, 244403.812, 243515.594, 242508.484, 241432.609, 241568.828, 239444.984, 239898.281, 238653.312, 238093.281, 237931.125, 237357.891, 236095.219, 236273.234, 234626.641, 234466.578, 233374.391, 233997.5, 233678.188, 231932.375, 232014.094, 232169.672, 231663.359, 231325.859, 230635.609, 230185.891, 230188.266, 228987.312, 229352.609, 228307.844, 228805.062, 229850.078, 227744.562, 228008.297, 227593.328, 227169.109, 226562.234, 226922.016, 226313.266, 224858.891, 225739.781, 225661.875, 226126.859, 225453.922, 224647.078, 224952.906, 224129.906, 225056.625, 223593.047, 223802.281, 223620.141, 223699.656, 222918.453, 223173.156, 222364.375, 223374.062, 221801.625, 222330.797, 221192.172, 221800.547, 220534.656, 221467.969, 219909.203, 221933.266, 220571.922, 219838.031], 'val_loss': [3572.915, 3074.035, 2954.966, 2916.757, 2873.925, 2838.832, 2828.482, 2820.442, 2803.361, 2784.468, 2739.188, 2718.728, 2706.348, 2658.629, 2625.133, 2616.322, 2610.213, 2574.031, 2544.147, 2566.76, 2533.306, 2518.672, 2516.169, 2493.312, 2461.076, 2502.668, 2450.208, 2443.928, 2417.403, 2435.341, 2402.369, 2401.177, 2404.677, 2369.808, 2393.285, 2354.855, 2325.979, 2351.975, 2344.228, 2316.993, 2314.24, 2317.611, 2311.679, 2316.438, 2291.097, 2306.709, 2309.096, 2297.153, 2297.318, 2288.332, 2287.948, 2301.501, 2283.666, 2292.988, 2304.191, 2302.462, 2338.419, 2307.048, 2294.91, 2303.144, 2272.342, 2289.347, 2264.918, 2259.658, 2265.14, 2252.307, 2285.2, 2248.829, 2287.322, 2269.218, 2272.022, 2284.331, 2264.84, 2255.939, 2275.937, 2283.099, 2261.259, 2235.763, 2250.674, 2274.109, 2252.212, 2264.093, 2252.804, 2252.854, 2257.491, 2250.204, 2228.149, 2241.96, 2253.438, 2232.617, 2212.108, 2231.574, 2221.299, 2205.964, 2246.459, 2207.883, 2264.575, 2230.489, 2244.865, 2222.02]}	100	100	True
