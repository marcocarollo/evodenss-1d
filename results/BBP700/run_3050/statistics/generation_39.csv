id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:75 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:104 kernel_size:9 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:72 kernel_size:7 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:adadelta batch_size:32 epochs:100	100	1000	True	31372.67773		469896	10	-1	207.41118454933167	{'train_loss': [594943.562, 353783.375, 321437.656, 306883.719, 298434.469, 290877.312, 285749.281, 281332.562, 276532.188, 273501.625, 269772.938, 267263.125, 264072.188, 264034.031, 261001.25, 259909.062, 257372.547, 256847.062, 254198.609, 253570.281, 253216.688, 251913.875, 250264.484, 249427.406, 248580.062, 248576.281, 246735.484, 246335.297, 245330.25, 244080.094, 243539.547, 243385.859, 242341.953, 242526.141, 242099.344, 239383.188, 240343.453, 239112.469, 239661.234, 239099.969, 237521.484, 237333.344, 237212.625, 237017.859, 236157.922, 235271.984, 235162.688, 234749.016, 234599.938, 233652.812, 233389.859, 233143.266, 231801.25, 231499.891, 231671.969, 231372.188, 230540.938, 230105.312, 230717.75, 229751.922, 229711.25, 228897.906, 229421.828, 228518.281, 227979.75, 227935.891, 227287.828, 227533.078, 226768.719, 226168.156, 226173.969, 225543.719, 225522.953, 225285.844, 225324.734, 225108.562, 224582.141, 223346.078, 223675.641, 223169.625, 222376.859, 222462.438, 222609.125, 221867.578, 222217.062, 221139.0, 221065.531, 220453.094, 221164.5, 220638.891, 219776.188, 220368.219, 220169.844, 219838.047, 219579.781, 219391.906, 218606.469, 218791.422, 219455.734, 218213.984], 'val_loss': [3437.588, 3015.588, 2894.4, 2842.94, 2795.167, 2747.347, 2685.844, 2650.594, 2609.457, 2575.359, 2570.197, 2531.711, 2520.78, 2503.258, 2463.044, 2462.117, 2446.444, 2430.611, 2426.561, 2424.386, 2410.485, 2387.425, 2393.853, 2380.975, 2381.555, 2361.861, 2347.101, 2343.422, 2331.34, 2319.968, 2311.269, 2312.125, 2324.242, 2299.98, 2297.636, 2288.615, 2307.146, 2290.449, 2280.9, 2277.957, 2294.918, 2285.551, 2278.917, 2265.157, 2272.633, 2282.333, 2276.997, 2262.558, 2260.643, 2252.161, 2272.821, 2257.295, 2238.814, 2242.083, 2238.507, 2237.952, 2238.653, 2239.631, 2235.116, 2253.582, 2252.916, 2239.489, 2237.099, 2225.044, 2213.206, 2229.609, 2222.442, 2222.514, 2213.453, 2222.613, 2204.121, 2208.428, 2208.783, 2221.308, 2225.275, 2223.224, 2214.568, 2207.328, 2200.94, 2206.85, 2193.859, 2189.4, 2212.986, 2203.489, 2196.626, 2194.699, 2184.13, 2193.237, 2191.648, 2179.434, 2188.595, 2178.329, 2180.056, 2188.453, 2185.059, 2182.03, 2182.034, 2162.061, 2169.111, 2172.256]}	100	100	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:75 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:104 kernel_size:9 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:72 kernel_size:7 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:6 layer:conv1d out_channels:65 kernel_size:6 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:adadelta batch_size:32 epochs:100	100	1000	True	137280.54688		5666223	10	-1	207.31523990631104	{'train_loss': [1169460.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0], 'val_loss': [10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216]}	100	100	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:62 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:104 kernel_size:9 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:deconv1d out_channels:72 kernel_size:7 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:adam lr:0.14894710059582128 beta1:0.8874178548365992 beta2:0.8877287323911984 weight_decay:4.290145998639963e-05 batch_size:32 epochs:100	100	1000	True	142320.48438		638003	11	-1	232.12370419502258	{'train_loss': [1076788.375, 1092782.375, 1102894.625, 1103687.5, 1091485.25, 1070024.0, 1142619.5, 1076053.25, 1115166.0, 1130625.625, 1153705.125, 1075641.25, 1094917.875, 1075737.375, 1077056.5, 1092893.375, 1068886.75, 1080577.0, 1099224.75, 1067682.25, 1079526.375, 1100782.375, 1085324.0, 1081298.5, 1097142.375, 1089220.0, 1073537.25, 1085093.75, 1103430.875, 1070868.625, 1084987.875, 1071857.75, 1108288.125, 1094537.625, 1083340.875, 1094669.0, 1081710.375, 1079127.875, 1087868.5, 1075016.375, 1091046.125, 1077509.625, 1086680.75, 1109820.875, 1082235.25, 1080448.625, 1101299.625, 1078241.875, 1081863.5, 1088026.75, 1081370.375, 1084874.0, 1088302.25, 1089862.25, 1075658.375, 1091693.75, 1089418.0, 1078404.375, 1068290.125, 1127452.0, 1078562.875, 1075036.375, 1111060.875, 1076485.75, 1091379.375, 1105621.75, 1072324.0, 1090227.25, 1107631.375, 1114107.625, 1078830.0, 1101897.625, 1087080.75, 1076746.75, 1075889.0, 1120152.75, 1080464.125, 1074808.875, 1112551.5, 1106209.0, 1073870.0, 1106965.875, 1103692.25, 1071838.0, 1095467.5, 1099138.125, 1079437.875, 1079503.375, 1101741.0, 1071339.375, 1084765.625, 1105463.125, 1077102.375, 1077528.75, 1089508.75, 1089123.25, 1077853.5, 1085939.0, 1097363.75, 1082410.125], 'val_loss': [10587.216, 14628.123, 10587.216, 11160.085, 10587.216, 10587.216, 11217.792, 10587.216, 12321.572, 10587.136, 10587.216, 11585.986, 10586.368, 10587.215, 10586.887, 10587.216, 10959.354, 10587.216, 10587.216, 10585.748, 11132.621, 10587.216, 10587.216, 10587.216, 10972.104, 10587.216, 10587.216, 11158.834, 10587.216, 10857.823, 10587.216, 10685.803, 10587.216, 11019.637, 10587.216, 10587.216, 10892.289, 10634.775, 10587.216, 11280.95, 10586.881, 10587.216, 11009.793, 10587.216, 10870.238, 10587.216, 10587.216, 11300.392, 10571.406, 10684.192, 10587.216, 10587.026, 10685.917, 10587.216, 10566.529, 10790.782, 10587.211, 10587.216, 12828.103, 10587.216, 10587.178, 10587.216, 10586.417, 10587.216, 10587.216, 10836.505, 10850.973, 10580.182, 10914.707, 10587.216, 10587.216, 10587.216, 10587.216, 10587.21, 10587.216, 10587.216, 10587.216, 10548.814, 10577.652, 10743.216, 10587.216, 10587.216, 10587.216, 10587.216, 10889.383, 10587.216, 10587.216, 10583.543, 10790.017, 10587.216, 10561.647, 11053.453, 10587.216, 10910.657, 11177.945, 10586.859, 10587.216, 10901.848, 10587.216, 11001.667]}	100	100	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:104 kernel_size:9 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:72 kernel_size:7 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:71 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:6 layer:conv1d out_channels:27 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:adadelta batch_size:32 epochs:100	100	1000	True	137277.34375		4570335	10	-1	211.00605607032776	{'train_loss': [1164599.875, 1087504.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0, 1066921.0], 'val_loss': [10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216, 10587.216]}	100	100	True
