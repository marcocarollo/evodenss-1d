id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:42 kernel_size:6 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:conv1d out_channels:30 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:10 layer:conv1d out_channels:96 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:13 layer:conv1d out_channels:113 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:14 layer:conv1d out_channels:75 kernel_size:9 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:15 layer:fc act:selu out_features:200 bias:True input:16 learning:adadelta lr:0.05229362301733192 batch_size:74 epochs:100	100	2000	True	3593.31641		1272847	18	-1	154.60377097129822	{'train_loss': [11013.909, 10448.54, 9865.67, 8369.854, 7301.174, 6846.046, 6562.904, 6366.072, 6124.397, 5937.91, 5820.38, 5685.346, 5565.18, 5525.679, 5447.321, 5375.157, 5326.347, 5265.644, 5193.994, 5171.644, 5107.372, 5088.39, 5053.178, 5041.587, 4973.689, 4976.344, 4927.967, 4909.143, 4888.864, 4852.92, 4847.481, 4807.801, 4782.105, 4786.875, 4753.331, 4734.386, 4733.88, 4689.747, 4713.73, 4676.004, 4678.552, 4645.489, 4633.514, 4597.167, 4600.7, 4573.666, 4556.539, 4555.683, 4569.243, 4549.606, 4521.932, 4527.458, 4514.833, 4487.893, 4501.584, 4482.43, 4447.146, 4457.988, 4462.372, 4438.206, 4437.539, 4434.531, 4427.598, 4397.109, 4400.928, 4388.265, 4386.499, 4372.349, 4379.906, 4343.844, 4339.697, 4357.538, 4312.78, 4346.21, 4315.798, 4313.899, 4289.162, 4309.94, 4282.275, 4277.862, 4276.276, 4283.645, 4279.06, 4255.77, 4260.068, 4241.104, 4243.868, 4241.869, 4216.985, 4217.751, 4232.868, 4234.988, 4212.145, 4182.631, 4192.44, 4211.889, 4209.967, 4194.467, 4167.205, 4188.325], 'val_loss': [8284.618, 8015.911, 6659.224, 5978.982, 5397.06, 5322.853, 5179.355, 5069.42, 4982.083, 4933.411, 4664.017, 4556.479, 4452.507, 4470.008, 4341.637, 4361.475, 4289.923, 4280.186, 4254.185, 4241.494, 4196.733, 4132.843, 4224.588, 4202.693, 4199.918, 4161.799, 4126.913, 4103.342, 4109.425, 4113.635, 4047.008, 4066.189, 4067.147, 4050.779, 4040.677, 3962.107, 3992.023, 4071.697, 3962.233, 3974.579, 3993.024, 3949.954, 4003.273, 3921.893, 3923.918, 3931.409, 3905.99, 3840.766, 3942.433, 3927.354, 3914.562, 3977.586, 3831.804, 3864.781, 3875.605, 3846.991, 3850.725, 3867.804, 3846.719, 3748.552, 3805.401, 3779.198, 3758.113, 3762.513, 3812.61, 3857.398, 3822.372, 3787.458, 3749.646, 3761.687, 3807.457, 3833.344, 3774.207, 3708.054, 3769.297, 3752.645, 3700.895, 3742.307, 3735.464, 3700.707, 3736.226, 3721.593, 3738.76, 3685.237, 3655.083, 3702.492, 3623.578, 3637.966, 3656.285, 3653.631, 3630.871, 3661.625, 3657.181, 3660.409, 3719.285, 3682.888, 3635.265, 3731.89, 3631.933, 3584.772]}	100	100	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:42 kernel_size:6 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:conv1d out_channels:30 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:10 layer:conv1d out_channels:96 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:13 layer:conv1d out_channels:113 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:14 layer:conv1d out_channels:75 kernel_size:9 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:15 layer:fc act:selu out_features:200 bias:True input:16 learning:adadelta lr:0.05229362301733192 batch_size:74 epochs:100	100	3000	True	3641.83179		1272847	18	-1	127.11534476280212	{'train_loss': [11042.361, 10004.303, 7939.708, 7308.499, 6961.282, 6748.172, 6597.503, 6412.375, 6269.341, 6132.414, 6013.301, 5909.52, 5816.946, 5752.519, 5673.988, 5576.268, 5519.254, 5471.146, 5419.948, 5359.622, 5318.482, 5260.852, 5246.661, 5189.663, 5127.775, 5099.949, 5056.817, 5029.523, 5012.354, 4959.088, 4946.629, 4896.727, 4884.926, 4895.891, 4831.84, 4812.467, 4794.308, 4760.503, 4752.542, 4719.04, 4694.145, 4679.433, 4659.016, 4652.999, 4610.394, 4616.306, 4621.091, 4572.281, 4558.644, 4537.671, 4531.596, 4533.453, 4515.56, 4508.577, 4494.02, 4494.688, 4459.847, 4456.871, 4434.013, 4440.804, 4423.644, 4389.974, 4397.309, 4363.875, 4370.387, 4371.755, 4371.174, 4335.92, 4348.947, 4356.67, 4326.803, 4339.97, 4315.925, 4308.456, 4306.071, 4289.328, 4283.916, 4263.947, 4267.426, 4262.459, 4247.977, 4236.444, 4263.866, 4251.273, 4220.736, 4225.313, 4211.563, 4222.263, 4189.307, 4216.299, 4198.779, 4186.268, 4174.756, 4169.764, 4177.457, 4171.277, 4175.972, 4179.338, 4174.867, 4147.373], 'val_loss': [8204.768, 6508.429, 5738.159, 5422.938, 5453.063, 5396.147, 4854.752, 4892.074, 4746.232, 4630.338, 4587.197, 4569.407, 4528.5, 4464.287, 4440.498, 4478.63, 4422.451, 4367.455, 4265.345, 4311.605, 4253.184, 4207.799, 4159.081, 4114.485, 4099.275, 4166.624, 4068.57, 4085.692, 4098.481, 4043.694, 4060.715, 4028.551, 4010.274, 4056.69, 3977.883, 4005.996, 3953.608, 3882.11, 3969.699, 3936.235, 3899.247, 3929.931, 3933.836, 3904.248, 3824.629, 3945.95, 3884.449, 3894.145, 3836.138, 3835.867, 3928.689, 3814.648, 3846.401, 3898.689, 3824.244, 3792.322, 3840.948, 3782.261, 3819.74, 3824.078, 3831.394, 3816.843, 3823.08, 3773.014, 3806.405, 3742.212, 3732.905, 3707.211, 3777.661, 3721.683, 3761.343, 3684.601, 3746.342, 3705.07, 3715.217, 3699.706, 3693.945, 3668.765, 3735.29, 3746.289, 3729.696, 3691.4, 3669.119, 3740.096, 3697.62, 3619.028, 3622.475, 3688.34, 3676.222, 3716.243, 3649.977, 3619.469, 3696.193, 3648.88, 3664.418, 3596.544, 3640.189, 3620.669, 3605.879, 3574.761]}	0	100	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:42 kernel_size:6 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:conv1d out_channels:30 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:10 layer:conv1d out_channels:79 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:deconv1d out_channels:123 kernel_size:2 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:13 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:14 layer:conv1d out_channels:113 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:15 layer:conv1d out_channels:61 kernel_size:9 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:16 layer:fc act:selu out_features:200 bias:True input:17 learning:gradient_descent lr:0.05229362301733192 momentum:0.7616558544436657 weight_decay:0.0007503777806463071 nesterov:True batch_size:74 epochs:100	100	1000	True	22220.0625		1748367	19	-1	156.5057463645935	{'train_loss': [86124.391, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143, 25921.143], 'val_loss': [22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49, 22187.49]}	100	100	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:118 kernel_size:2 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:56 kernel_size:6 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:6 layer:conv1d out_channels:30 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:118 kernel_size:2 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:10 layer:conv1d out_channels:96 kernel_size:8 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 layer:deconv1d out_channels:116 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:13 layer:deconv1d out_channels:113 kernel_size:9 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:14 layer:conv1d out_channels:59 kernel_size:9 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:15 layer:fc act:selu out_features:200 bias:True input:16 learning:adadelta lr:0.05229362301733192 batch_size:74 epochs:100	100	2000	True	3740.64233		2053465	18	-1	148.90416526794434	{'train_loss': [11301.73, 10937.754, 9068.416, 7795.889, 7298.831, 6816.181, 6466.698, 6219.84, 6021.547, 5882.941, 5769.822, 5664.776, 5545.355, 5469.037, 5427.268, 5340.514, 5286.0, 5208.926, 5197.633, 5120.217, 5102.209, 5045.595, 5011.821, 4983.655, 4963.783, 4917.025, 4903.778, 4853.197, 4861.084, 4806.51, 4834.819, 4766.491, 4760.802, 4719.056, 4710.814, 4704.664, 4677.621, 4664.601, 4676.156, 4627.968, 4605.338, 4601.033, 4578.179, 4588.438, 4568.852, 4522.185, 4530.046, 4525.236, 4516.68, 4499.639, 4501.422, 4494.286, 4469.538, 4456.098, 4447.577, 4438.754, 4417.599, 4428.207, 4415.079, 4414.811, 4381.113, 4389.81, 4393.198, 4365.473, 4352.84, 4360.807, 4331.505, 4338.94, 4314.347, 4328.919, 4307.339, 4290.219, 4290.338, 4277.383, 4282.454, 4298.599, 4298.479, 4248.585, 4258.578, 4233.103, 4250.701, 4242.635, 4226.597, 4212.385, 4225.897, 4233.032, 4224.697, 4222.118, 4174.236, 4192.725, 4178.987, 4186.303, 4173.133, 4185.978, 4183.506, 4198.801, 4185.955, 4130.558, 4144.3, 4141.864], 'val_loss': [8311.026, 7106.599, 6805.959, 6003.893, 5698.934, 5390.194, 5138.531, 4974.022, 4782.75, 4624.458, 4536.947, 4431.883, 4401.859, 4360.062, 4297.569, 4252.521, 4255.88, 4253.9, 4201.956, 4141.608, 4209.293, 4161.863, 4027.716, 4206.17, 4105.867, 4013.204, 4010.039, 4103.678, 4085.244, 4016.849, 4033.793, 3919.919, 3924.415, 3955.669, 3978.284, 3909.128, 3943.077, 3892.946, 3920.743, 3953.915, 3943.668, 3892.787, 3831.251, 3950.755, 3854.524, 3795.44, 3821.845, 3900.603, 3833.194, 3901.73, 3749.928, 3844.149, 3845.621, 3782.111, 3795.664, 3876.285, 3883.643, 3808.368, 3862.222, 3795.201, 3870.167, 3811.288, 3805.653, 3863.56, 3790.418, 3778.825, 3868.313, 3816.167, 3735.92, 3822.117, 3814.711, 3827.936, 3795.005, 3765.638, 3774.634, 3819.151, 3718.155, 3781.704, 3773.482, 3734.036, 3661.334, 3694.681, 3671.123, 3778.158, 3723.316, 3650.135, 3719.971, 3772.258, 3769.642, 3732.75, 3754.549, 3729.133, 3653.657, 3634.055, 3749.65, 3669.483, 3606.469, 3654.302, 3625.325, 3685.092]}	0	100	True
