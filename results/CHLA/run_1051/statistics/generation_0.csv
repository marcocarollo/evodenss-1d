id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	26883.29688		452251	14	-1	223.3796603679657	{'train_loss': [432642.719, 368068.219, 321520.469, 280795.094, 265266.375, 256609.141, 251198.125, 247556.562, 244412.031, 241190.984, 239145.047, 237140.594, 236040.531, 233723.062, 233240.516, 232088.344, 230483.906, 229843.891, 228539.766, 227572.188, 227402.875, 226069.812, 225369.531, 225127.484, 224032.797, 223708.25, 223181.672, 222996.984, 223229.797, 222148.531, 221598.688, 221161.5, 220205.547, 220646.453, 219877.875, 219634.969, 219257.062, 218759.859, 218619.359, 217978.641, 217583.516, 217009.438, 216824.141, 216370.125, 216487.703, 215878.219, 215639.172, 215251.766, 214968.688, 214168.094, 214575.406, 214680.531, 213886.172, 213435.641, 213615.359, 212844.875, 212961.094, 212790.734, 212007.453, 212630.938, 211844.25, 211844.547, 211077.656, 210851.172, 210990.422, 209940.844, 210372.531, 210951.5, 210346.266, 209733.594, 209407.219, 209707.531, 208606.5, 209003.156, 209629.828, 209432.406, 208755.375, 208671.203, 209105.328, 208892.641, 208475.641, 207824.844, 207638.125, 208098.703, 207396.5, 207829.984, 207897.016, 207301.781, 206824.281, 206515.844, 206952.766, 206244.0, 206866.703, 206638.516, 206201.984, 206083.922, 206220.156, 205914.078, 205745.203, 205893.938], 'val_loss': [3995.536, 3316.418, 2954.485, 2772.797, 2701.422, 2690.769, 2643.54, 2628.118, 2618.515, 2572.494, 2588.823, 2550.478, 2537.778, 2527.092, 2540.487, 2505.216, 2501.78, 2517.567, 2499.308, 2505.977, 2462.48, 2489.675, 2482.893, 2453.798, 2493.58, 2434.725, 2448.27, 2430.172, 2429.555, 2435.871, 2433.315, 2414.126, 2419.762, 2403.248, 2426.591, 2416.19, 2424.222, 2421.111, 2405.177, 2405.99, 2439.909, 2408.511, 2410.708, 2403.648, 2408.881, 2400.899, 2403.633, 2402.811, 2383.388, 2400.039, 2394.482, 2411.298, 2407.816, 2397.835, 2402.633, 2389.497, 2392.359, 2388.551, 2383.352, 2387.481, 2395.223, 2383.885, 2385.358, 2378.649, 2378.733, 2376.016, 2376.941, 2382.147, 2372.374, 2367.848, 2395.985, 2364.335, 2369.565, 2368.235, 2377.373, 2361.875, 2368.05, 2364.713, 2377.628, 2385.984, 2382.422, 2360.548, 2364.837, 2352.367, 2366.52, 2353.948, 2385.689, 2358.079, 2361.427, 2367.42, 2367.391, 2360.834, 2354.513, 2351.314, 2359.769, 2362.291, 2370.336, 2362.212, 2356.921, 2354.583]}	100	100	True
