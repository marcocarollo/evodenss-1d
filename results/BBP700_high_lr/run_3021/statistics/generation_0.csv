id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta lr:0.1262432328377348 batch_size:32 epochs:100	100	1000	True	32797.06641		452251	14	-1	207.76139760017395	{'train_loss': [385011.031, 363440.875, 330149.281, 321368.0, 315705.531, 309755.156, 306327.25, 303668.875, 301261.312, 299298.719, 297279.75, 295489.344, 293908.031, 292241.219, 290905.188, 288591.281, 287860.5, 285932.719, 284350.25, 283266.719, 281900.875, 280713.719, 279682.188, 278125.906, 277028.188, 276119.219, 274136.969, 273549.531, 272282.312, 271590.438, 269379.688, 269058.5, 267389.562, 266816.094, 264789.656, 264390.812, 264052.188, 262841.719, 261916.328, 260951.734, 260521.594, 259399.141, 258808.812, 258381.062, 257775.781, 257550.344, 257034.25, 255887.047, 255221.406, 253903.453, 254414.453, 252555.375, 252852.734, 252147.875, 252041.906, 251684.141, 250615.812, 249731.375, 249566.344, 249789.375, 249432.609, 248394.844, 247582.734, 247447.312, 247679.625, 247899.938, 246562.547, 246294.891, 246257.234, 245624.031, 244752.016, 245193.609, 244172.906, 244564.734, 243888.797, 243656.188, 243787.547, 243269.719, 243340.391, 242714.734, 242102.281, 242120.938, 241259.453, 241205.172, 240995.891, 240702.203, 240546.359, 239881.781, 239818.047, 239518.656, 239621.75, 238867.172, 239379.453, 238590.906, 239405.078, 238489.031, 237673.844, 238128.922, 237468.938, 237849.641], 'val_loss': [3411.013, 3150.369, 2998.775, 2966.049, 2918.947, 2885.367, 2855.99, 2843.281, 2822.651, 2807.168, 2795.561, 2774.818, 2774.949, 2748.111, 2738.88, 2731.021, 2723.433, 2716.845, 2700.761, 2691.995, 2675.782, 2668.149, 2656.326, 2642.729, 2625.598, 2623.269, 2603.113, 2604.976, 2594.392, 2585.071, 2587.296, 2575.485, 2566.344, 2549.718, 2539.74, 2540.17, 2514.676, 2509.819, 2519.831, 2499.068, 2504.772, 2490.661, 2489.61, 2484.104, 2476.266, 2466.686, 2473.881, 2464.275, 2447.066, 2441.716, 2441.268, 2442.952, 2441.015, 2441.079, 2440.156, 2416.566, 2437.919, 2422.473, 2419.789, 2411.969, 2429.816, 2423.896, 2391.074, 2411.07, 2409.919, 2400.182, 2398.903, 2388.378, 2391.84, 2403.027, 2380.673, 2405.483, 2403.105, 2388.666, 2387.072, 2380.798, 2393.129, 2363.199, 2373.906, 2379.755, 2380.425, 2370.337, 2352.55, 2383.655, 2370.265, 2365.27, 2357.887, 2350.391, 2373.047, 2343.523, 2373.608, 2365.528, 2358.95, 2379.178, 2351.088, 2334.298, 2345.513, 2340.366, 2363.112, 2349.168]}	100	100	True
