id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:22 epochs:50	50	500	True	0.40979		507033	13	-1	177.84491991996765	{'train_loss': [19.163, 2.517, 0.458, 0.281, 0.259, 0.261, 0.268, 0.263, 0.27, 0.267, 0.263, 0.264, 0.265, 0.277, 0.28, 0.256, 0.255, 0.264, 0.27, 0.269, 0.278, 0.264, 0.26, 0.267, 0.262, 0.269, 0.27, 0.291, 0.281, 0.291, 0.289, 0.268, 0.257, 0.293, 0.29, 0.277, 0.276, 0.264, 0.266, 0.268, 0.283, 0.275, 0.269, 0.258, 0.279, 0.287, 0.268, 0.277, 0.281, 0.287], 'val_loss': [6.522, 0.805, 0.406, 0.658, 0.392, 0.276, 0.251, 0.533, 0.314, 0.46, 0.446, 0.813, 0.325, 0.418, 0.271, 0.255, 0.52, 0.248, 0.348, 0.401, 0.981, 0.265, 0.429, 0.739, 0.312, 0.287, 0.32, 0.397, 0.344, 0.741, 0.274, 0.407, 0.534, 0.608, 0.293, 0.309, 0.284, 0.406, 0.232, 0.433, 0.281, 0.323, 0.335, 0.978, 0.656, 0.67, 0.594, 0.61, 0.383, 0.404]}	50	50	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:22 kernel_size:1 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.883968459716141 weight_decay:0.00016298549688121864 batch_size:22 epochs:50	50	500	True	0.28986		343341	12	-1	173.70782613754272	{'train_loss': [23.325, 5.19, 1.004, 0.393, 0.25, 0.232, 0.241, 0.249, 0.243, 0.245, 0.258, 0.249, 0.251, 0.259, 0.249, 0.258, 0.261, 0.256, 0.259, 0.254, 0.251, 0.26, 0.267, 0.268, 0.264, 0.263, 0.259, 0.26, 0.26, 0.252, 0.257, 0.257, 0.263, 0.258, 0.27, 0.28, 0.271, 0.273, 0.256, 0.258, 0.261, 0.266, 0.254, 0.256, 0.262, 0.255, 0.25, 0.269, 0.264, 0.249], 'val_loss': [13.844, 1.8, 0.563, 0.312, 0.212, 0.246, 0.235, 0.631, 0.254, 0.251, 0.248, 0.236, 0.242, 1.778, 0.517, 0.234, 0.311, 0.958, 0.317, 0.278, 0.345, 0.361, 0.633, 0.29, 0.362, 0.341, 0.242, 0.756, 0.235, 0.538, 0.272, 0.265, 0.302, 0.423, 0.324, 0.628, 0.496, 0.432, 0.241, 0.677, 0.37, 0.654, 0.223, 0.482, 0.301, 0.378, 0.269, 0.565, 0.234, 0.281]}	50	50	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.026341539887969535 beta1:0.803196421382289 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:22 epochs:50	50	500	True	2.03709		507033	13	-1	179.54397749900818	{'train_loss': [8.897, 4.938, 0.53, 0.322, 0.371, 0.307, 0.296, 0.338, 0.293, 0.315, 0.301, 0.345, 0.378, 0.333, 0.29, 0.432, 0.339, 0.356, 0.342, 0.316, 0.298, 0.323, 0.332, 0.324, 0.268, 0.445, 0.348, 0.334, 0.294, 0.316, 0.321, 0.339, 0.319, 0.334, 0.275, 0.399, 0.34, 0.297, 0.435, 0.373, 0.329, 0.354, 0.408, 0.326, 0.314, 0.283, 0.349, 0.311, 0.334, 0.319], 'val_loss': [7.852, 0.603, 0.267, 0.209, 0.744, 0.465, 0.706, 0.232, 0.245, 0.198, 0.253, 0.254, 0.247, 0.21, 0.315, 0.331, 0.254, 0.561, 5.928, 1.186, 0.339, 0.211, 7.397, 0.205, 0.195, 0.331, 0.258, 0.207, 0.354, 0.304, 0.433, 0.185, 0.345, 0.268, 18.17, 0.268, 0.41, 0.246, 0.299, 0.302, 0.195, 0.545, 0.342, 0.498, 0.193, 0.235, 0.248, 0.837, 6.622, 2.027]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:4 epochs:50	42	500	True	0.17516		507033	13	-1	505.2517545223236	{'train_loss': [2.014, 0.193, 0.199, 0.199, 0.199, 0.195, 0.197, 0.186, 0.19, 0.194, 0.197, 0.187, 0.192, 0.188, 0.192, 0.193, 0.197, 0.196, 0.189, 0.199, 0.197, 0.189, 0.197, 0.187, 0.185, 0.19, 0.195, 0.195, 0.199, 0.19, 0.193, 0.192, 0.193, 0.19, 0.2, 0.204, 0.216, 0.186, 0.187, 0.188, 0.2, 0.19], 'val_loss': [0.181, 0.169, 0.17, 0.167, 0.165, 0.18, 0.169, 0.168, 0.175, 0.174, 0.171, 0.169, 0.174, 0.175, 0.168, 0.18, 0.175, 0.167, 0.173, 0.171, 0.171, 0.165, 0.167, 0.182, 0.161, 0.164, 0.18, 0.172, 0.169, 0.18, 0.173, 0.198, 0.18, 0.169, 0.18, 0.17, 0.171, 0.173, 0.164, 0.167, 0.172, 0.164]}	42	42	False
