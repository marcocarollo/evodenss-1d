id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:124 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:4 epochs:50	43	500	True	0.22101		744253	13	-1	539.7596416473389	{'train_loss': [9.364, 0.195, 0.192, 0.188, 0.187, 0.199, 0.198, 0.197, 0.203, 0.202, 0.195, 0.195, 0.2, 0.208, 0.201, 0.207, 0.204, 0.192, 0.207, 0.19, 0.196, 0.197, 0.199, 0.203, 0.206, 0.201, 0.202, 0.199, 0.192, 0.207, 0.203, 0.198, 0.206, 0.194, 0.217, 0.2, 0.193, 0.199, 0.194, 0.2, 0.202, 0.203, 0.205], 'val_loss': [0.171, 0.183, 0.168, 0.17, 0.164, 0.19, 0.173, 0.202, 0.176, 0.189, 0.175, 0.191, 0.263, 0.197, 0.172, 0.191, 0.185, 0.188, 0.18, 0.172, 0.195, 0.172, 0.189, 0.206, 0.177, 0.175, 0.171, 0.183, 0.205, 0.192, 0.183, 0.177, 0.177, 0.18, 0.189, 0.174, 0.267, 0.197, 0.178, 0.181, 0.178, 0.17, 0.21]}	43	43	False
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:70 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:gradient_descent lr:0.040719393771330166 momentum:0.9198981496682245 weight_decay:0.0008681084503414633 nesterov:False batch_size:57 epochs:50	50	500	True	5.82394		339037	12	-1	134.63216710090637	{'train_loss': [10.365, 8.255, 7.918, 7.605, 7.338, 7.111, 6.918, 6.754, 6.614, 6.495, 6.393, 6.307, 6.233, 6.17, 6.116, 6.067, 6.033, 6.006, 6.176, 6.047, 6.032, 5.999, 5.97, 5.945, 5.925, 5.907, 5.892, 5.88, 5.868, 5.859, 5.854, 5.845, 5.845, 5.83, 4.196, 6.627, 6.064, 6.027, 5.994, 5.966, 5.943, 5.923, 5.906, 5.892, 5.88, 5.87, 5.861, 5.854, 5.847, 5.842], 'val_loss': [8.302, 8.039, 7.702, 7.414, 7.169, 6.96, 6.783, 6.632, 6.503, 6.393, 6.3, 6.221, 6.153, 6.096, 6.049, 6.034, 5.983, 5.959, 6.431, 6.0, 5.966, 5.935, 5.908, 5.886, 5.867, 5.851, 5.838, 5.826, 5.817, 5.817, 5.811, 5.798, 5.802, 5.926, 369.406, 6.029, 5.996, 5.961, 5.93, 5.905, 5.883, 5.865, 5.85, 5.837, 5.826, 5.817, 5.809, 5.802, 5.795, 5.786]}	50	50	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:124 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:4 epochs:50	42	500	True	0.18958		744253	13	-1	511.00993156433105	{'train_loss': [7.783, 0.191, 0.192, 0.194, 0.194, 0.191, 0.194, 0.188, 0.193, 0.194, 0.19, 0.189, 0.201, 0.201, 0.192, 0.191, 0.189, 0.195, 0.202, 0.198, 0.2, 0.202, 0.197, 0.191, 0.211, 0.198, 0.199, 0.195, 0.192, 0.192, 0.19, 0.2, 0.193, 0.212, 0.189, 0.194, 0.198, 0.198, 0.2, 0.195, 0.195, 0.196], 'val_loss': [0.172, 0.175, 0.168, 0.183, 0.168, 0.199, 0.165, 0.177, 0.181, 0.167, 0.181, 0.165, 0.232, 0.171, 0.17, 0.176, 0.174, 0.175, 0.17, 0.175, 0.176, 0.183, 0.178, 0.169, 0.249, 0.17, 0.171, 0.179, 0.174, 0.172, 0.169, 0.195, 0.178, 0.179, 0.162, 0.173, 0.173, 0.2, 0.183, 0.18, 0.208, 0.179]}	42	42	False
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:4 epochs:50	45	500	True	0.17896		522105	12	-1	508.08283972740173	{'train_loss': [3.853, 0.185, 0.185, 0.185, 0.185, 0.187, 0.184, 0.187, 0.186, 0.19, 0.187, 0.19, 0.184, 0.189, 0.185, 0.19, 0.186, 0.184, 0.185, 0.185, 0.185, 0.185, 0.181, 0.184, 0.185, 0.192, 0.186, 0.187, 0.187, 0.185, 0.19, 0.184, 0.185, 0.187, 0.187, 0.191, 0.184, 0.184, 0.183, 0.188, 0.187, 0.184, 0.187, 0.188, 0.186], 'val_loss': [0.165, 0.168, 0.164, 0.166, 0.175, 0.327, 0.174, 0.176, 0.174, 0.176, 0.162, 0.172, 0.173, 0.169, 0.164, 0.175, 0.16, 0.168, 0.176, 0.171, 0.163, 0.163, 0.161, 0.166, 0.203, 0.18, 0.175, 0.167, 0.166, 0.174, 0.164, 0.168, 0.17, 0.168, 0.164, 0.189, 0.169, 0.163, 0.184, 0.174, 0.173, 0.163, 0.164, 0.165, 0.168]}	45	45	False
