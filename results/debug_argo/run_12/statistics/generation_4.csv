id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:22 epochs:50	50	500	True	0.19885		507033	13	-1	194.38470101356506	{'train_loss': [20.773, 2.634, 0.497, 0.34, 0.293, 0.222, 0.206, 0.204, 0.208, 0.207, 0.205, 0.208, 0.203, 0.203, 0.209, 0.204, 0.202, 0.205, 0.205, 0.202, 0.204, 0.207, 0.201, 0.202, 0.202, 0.203, 0.204, 0.205, 0.207, 0.215, 0.206, 0.205, 0.203, 0.211, 0.21, 0.202, 0.203, 0.207, 0.205, 0.205, 0.207, 0.212, 0.214, 0.21, 0.205, 0.207, 0.208, 0.213, 0.21, 0.209], 'val_loss': [8.136, 0.953, 0.345, 0.566, 0.233, 0.191, 0.26, 0.176, 0.183, 0.183, 0.181, 0.182, 0.183, 0.18, 0.181, 0.183, 0.188, 0.191, 0.184, 0.178, 0.184, 0.178, 0.177, 0.181, 0.183, 0.241, 0.195, 0.182, 0.182, 0.188, 0.186, 0.203, 0.181, 0.188, 0.179, 0.176, 0.181, 0.241, 0.181, 0.182, 0.18, 0.185, 0.188, 0.188, 0.176, 0.189, 0.181, 0.195, 0.191, 0.188]}	50	50	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:adam lr:0.026341539887969535 beta1:0.8360331051560174 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:22 epochs:50	50	500	True	0.60779		522105	12	-1	198.31350135803223	{'train_loss': [9.494, 8.185, 2.263, 0.436, 0.42, 0.37, 0.31, 0.396, 0.443, 0.316, 0.384, 0.352, 0.369, 0.402, 0.352, 0.339, 0.348, 0.399, 0.346, 0.362, 0.352, 0.369, 0.35, 0.353, 0.384, 0.347, 0.343, 0.556, 0.337, 0.31, 0.381, 0.372, 0.404, 0.382, 0.362, 0.333, 0.381, 0.312, 0.374, 0.475, 0.334, 0.377, 0.418, 0.335, 0.384, 0.374, 0.345, 0.447, 0.386, 0.391], 'val_loss': [4.404, 6.627, 0.57, 0.647, 0.294, 0.368, 0.288, 0.205, 0.365, 0.256, 0.276, 1.447, 0.227, 0.528, 0.482, 0.401, 0.215, 0.185, 2.036, 0.242, 0.399, 0.279, 0.274, 0.268, 0.388, 0.489, 0.236, 0.879, 0.224, 0.318, 0.25, 0.363, 0.402, 0.379, 0.2, 0.574, 0.324, 0.409, 0.435, 0.246, 0.226, 0.33, 0.186, 0.241, 0.426, 0.521, 0.488, 0.202, 0.197, 0.597]}	50	50	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:adam lr:0.026341539887969535 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.0009328019745155216 batch_size:22 epochs:50	50	500	True	0.32436		522105	12	-1	189.52890706062317	{'train_loss': [19.087, 3.118, 0.421, 0.268, 0.278, 0.286, 0.268, 0.277, 0.261, 0.286, 0.265, 0.29, 0.273, 0.267, 0.267, 0.272, 0.277, 0.277, 0.289, 0.269, 0.26, 0.265, 0.295, 0.267, 0.271, 0.267, 0.28, 0.293, 0.268, 0.27, 0.28, 0.284, 0.318, 0.282, 0.288, 0.268, 0.273, 0.28, 0.276, 0.268, 0.278, 0.271, 0.275, 0.259, 0.267, 0.268, 0.276, 0.28, 0.282, 0.267], 'val_loss': [9.433, 1.18, 0.317, 0.561, 0.61, 1.231, 0.487, 0.242, 0.761, 0.536, 0.326, 0.327, 0.298, 0.786, 0.368, 0.319, 0.597, 1.894, 0.302, 0.804, 0.246, 0.65, 0.27, 1.03, 0.832, 0.443, 1.004, 0.994, 0.314, 0.485, 0.416, 0.366, 0.549, 0.464, 0.515, 0.422, 0.672, 0.817, 0.544, 0.289, 0.651, 0.447, 0.297, 0.562, 0.486, 0.285, 0.31, 0.913, 0.629, 0.312]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:24 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:122 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:adam lr:0.0918014146625562 beta1:0.9732440384721085 beta2:0.9470697755428685 weight_decay:0.00016298549688121864 batch_size:22 epochs:50	50	500	True	1.2217		691553	13	-1	215.2355456352234	{'train_loss': [462.423, 250.681, 74.276, 46.535, 25.086, 20.767, 8.9, 1.451, 0.836, 0.78, 1.017, 0.797, 0.957, 0.797, 0.921, 0.975, 0.887, 1.0, 0.848, 0.896, 1.129, 0.879, 0.894, 0.765, 1.116, 0.903, 1.095, 1.049, 0.956, 0.917, 0.862, 1.046, 0.923, 0.951, 0.963, 0.838, 0.85, 0.935, 0.87, 0.703, 0.996, 0.938, 1.074, 0.925, 1.019, 1.036, 0.815, 1.101, 1.263, 0.933], 'val_loss': [577.474, 212.191, 1988.139, 506.388, 61.864, 23.452, 2.536, 1.155, 0.608, 0.915, 0.842, 0.747, 0.691, 0.741, 0.978, 0.872, 0.979, 0.668, 1.437, 1.16, 0.887, 0.964, 0.795, 0.825, 1.074, 0.795, 1.121, 0.97, 1.511, 0.868, 0.953, 1.266, 1.17, 0.847, 0.926, 0.779, 1.066, 0.873, 0.645, 0.779, 0.989, 1.977, 0.688, 0.917, 0.776, 0.819, 0.551, 0.859, 1.102, 1.211]}	50	50	True
