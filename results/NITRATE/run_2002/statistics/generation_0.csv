id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adam lr:0.08835175881075448 beta1:0.9460386875373169 beta2:0.9975553842663847 weight_decay:9.685360722189728e-05 batch_size:83 epochs:100	100	1000	True	5004.36963		452251	14	-1	83.64320111274719	{'train_loss': [23917.082, 6810.602, 4529.583, 4054.545, 3901.118, 3860.562, 3735.818, 3660.015, 3642.937, 3656.246, 3586.32, 3556.182, 3522.878, 3488.231, 3464.323, 3386.723, 3386.517, 3353.586, 3345.53, 3361.967, 3347.749, 3448.644, 3418.676, 3384.107, 3391.793, 3413.472, 3353.002, 3392.076, 3321.336, 3364.752, 3325.502, 3318.741, 3378.087, 3433.186, 3324.651, 3459.325, 3385.523, 3480.278, 3456.462, 3332.767, 3312.27, 3392.773, 3343.796, 3363.381, 3371.831, 3525.019, 3442.024, 3347.76, 3499.507, 3370.501, 3394.481, 3404.992, 3315.368, 3316.532, 3395.157, 3520.857, 4024.266, 4201.895, 4594.495, 5101.652, 3918.27, 3424.494, 3359.722, 3253.953, 3232.342, 3271.131, 3312.246, 3257.22, 3294.492, 3354.132, 3309.647, 3230.199, 3285.724, 3449.642, 3483.066, 3368.829, 3391.884, 3328.827, 3275.381, 3275.473, 3211.956, 3269.274, 3293.703, 3399.268, 3295.218, 3262.05, 3257.451, 3273.64, 3262.845, 3266.27, 3249.778, 3331.011, 3311.631, 3231.854, 3119.908, 3078.229, 3176.55, 3218.793, 3301.615, 3455.134], 'val_loss': [12308.162, 4194.529, 3297.825, 3185.137, 3112.406, 3112.003, 2969.757, 2984.023, 2965.82, 2937.9, 2907.876, 2861.193, 2794.197, 2809.882, 2739.3, 2785.07, 2668.323, 2684.784, 2740.525, 2668.744, 2758.755, 2767.129, 2896.109, 2802.958, 2747.799, 2751.564, 2737.436, 2782.562, 2711.452, 2699.202, 2898.762, 2708.189, 2816.827, 2880.745, 2790.249, 2797.492, 3106.073, 2753.075, 2744.012, 2856.192, 2667.478, 2691.602, 2883.031, 2880.477, 2753.48, 3137.257, 3011.451, 2776.668, 3123.601, 2765.949, 3058.527, 2726.19, 2898.196, 2934.797, 2839.05, 3426.772, 4290.776, 5483.5, 3175.354, 3890.134, 2782.074, 2908.867, 2647.748, 2791.939, 2648.309, 2645.029, 2718.569, 2746.862, 2694.822, 2973.381, 2769.542, 2669.918, 2779.457, 2965.42, 2873.928, 3182.909, 2992.682, 2636.384, 2644.42, 2757.315, 2650.889, 2692.812, 2822.753, 2769.618, 2671.548, 2691.015, 2564.12, 2587.016, 2719.146, 2876.524, 2745.095, 3085.351, 2764.464, 2524.864, 2589.337, 2659.489, 2695.944, 2755.629, 2581.77, 5122.944]}	100	100	True
