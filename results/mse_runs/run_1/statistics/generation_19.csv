id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:52 kernel_size:5 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:7 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:84 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:6 layer:fc act:selu out_features:200 bias:True input:7 learning:gradient_descent lr:0.08985018259086422 momentum:0.9290943164834226 weight_decay:6.06273516826541e-05 nesterov:False batch_size:6 epochs:50	50	200	True	0.19234		204360	9	-1	201.5462498664856	{'train_loss': [0.133, 0.117, 0.116, 0.114, 0.107, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105, 0.105], 'val_loss': [0.112, 0.095, 0.089, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086]}	50	50	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:38 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:52 kernel_size:5 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:7 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:100 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:gradient_descent lr:0.00014674304046009604 momentum:0.9290943164834226 weight_decay:6.06273516826541e-05 nesterov:False batch_size:6 epochs:50	47	200	True	1.09459		211870	10	-1	203.19165587425232	{'train_loss': [0.335, 0.132, 0.124, 0.121, 0.119, 0.117, 0.116, 0.115, 0.115, 0.114, 0.114, 0.113, 0.113, 0.112, 0.112, 0.112, 0.112, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108], 'val_loss': [0.096, 0.089, 0.089, 0.089, 0.089, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.087, 0.087, 0.088, 0.087, 0.088, 0.087, 0.088, 0.088, 0.087, 0.087, 0.088, 0.087, 0.087, 0.088, 0.087, 0.087, 0.087, 0.087, 0.087, 0.087, 0.087, 0.087, 0.087, 0.087, 0.087]}	47	47	False
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:52 kernel_size:5 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:7 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:84 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:6 layer:fc act:selu out_features:200 bias:True input:7 learning:gradient_descent lr:0.08985018259086422 momentum:0.9290943164834226 weight_decay:6.06273516826541e-05 nesterov:False batch_size:46 epochs:50	50	200	True	0.69701		204360	9	-1	138.19673609733582	{'train_loss': [0.16, 0.11, 0.11, 0.109, 0.109, 0.108, 0.108, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.107, 0.107, 0.108, 0.108, 0.108, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108], 'val_loss': [0.099, 0.1, 0.097, 0.099, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.098, 0.1, 0.101, 0.104, 0.105, 0.105, 0.104, 0.104, 0.103, 0.102, 0.102, 0.101, 0.101, 0.1, 0.1, 0.099, 0.099, 0.099, 0.098, 0.098, 0.098, 0.098, 0.098, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097, 0.097]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:84 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:89 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:True bias:True input:4 layer:fc act:selu out_features:200 bias:True input:5 learning:gradient_descent lr:0.08985018259086422 momentum:0.9290943164834226 weight_decay:6.06273516826541e-05 nesterov:False batch_size:5 epochs:50	45	200	True	199098544160768.0		7336463	7	-1	204.05340051651	{'train_loss': [62597044.0, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773, 5.773], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 5.739, 5.739, 5.739, 5.739, 5.739, 5.739]}	45	45	False
