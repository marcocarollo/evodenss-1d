2024-11-18 18:28:33,393 :: INFO :: __main__ :: [0] -- Starting fresh run
2024-11-18 18:30:15,047 :: INFO :: __main__ :: [0] -- Starting fresh run
2024-11-18 18:30:15,861 :: INFO :: __main__ :: [0] -- Dataset partition sizes:
2024-11-18 18:30:15,861 :: INFO :: __main__ :: [0] -- DatasetType.EVO_TEST size -- 379
2024-11-18 18:30:15,862 :: INFO :: __main__ :: [0] -- DatasetType.VALIDATION size -- 379
2024-11-18 18:30:15,862 :: INFO :: __main__ :: [0] -- DatasetType.DOWNSTREAM_TRAIN size -- 3028
2024-11-18 18:30:15,862 :: INFO :: __main__ :: [0] -- DatasetType.TEST size -- 498
2024-11-18 18:30:15,862 :: INFO :: __main__ :: [0] -- Starting evolution for run 0
2024-11-18 18:30:15,918 :: INFO :: __main__ :: [0] -- Using 2 GPUs
2024-11-18 18:30:15,918 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 0
2024-11-18 18:30:15,918 :: INFO :: evodenss.evolution.engine :: [0] -- Creating the initial population
2024-11-18 18:30:16,254 :: INFO :: evodenss.networks.module :: [0] -- Using ARGO grammar for features module
2024-11-18 18:30:16,258 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 18:30:16,320 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0007463019938134078 batch_size:46 epochs:50
2024-11-18 18:30:19,554 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:30:19,555 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:30:26,385 :: INFO :: evodenss.train.trainers :: [0] -- [6.01s] TRAIN epoch 0 -- loss: tensor([0.1891], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:26,386 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.189
2024-11-18 18:30:26,386 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:27,120 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:30:28,983 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 1 -- loss: tensor([0.1201], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:28,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:30:28,986 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:29,573 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:30:31,366 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 2 -- loss: tensor([0.1167], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:31,369 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:30:31,369 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:31,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:30:33,777 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 3 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:33,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:30:33,789 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:34,435 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:30:36,351 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 4 -- loss: tensor([0.1137], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:36,355 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:30:36,355 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:36,999 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:30:38,840 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 5 -- loss: tensor([0.1137], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:38,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:30:38,843 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:39,380 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:30:41,135 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 6 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:41,138 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:30:41,138 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:41,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:30:43,524 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 7 -- loss: tensor([0.1129], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:43,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:30:43,527 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:44,176 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:30:46,002 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 8 -- loss: tensor([0.1131], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:46,005 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:30:46,005 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:46,578 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:30:48,434 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 9 -- loss: tensor([0.1163], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:48,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:30:48,437 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:48,970 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:30:50,920 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 10 -- loss: tensor([0.1131], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:50,923 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:30:50,923 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:51,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:30:53,307 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 11 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:53,310 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:30:53,310 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:53,924 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:30:55,798 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 12 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:55,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:30:55,801 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:56,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:30:57,878 :: INFO :: evodenss.train.trainers :: [0] -- [1.55s] TRAIN epoch 13 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:30:57,880 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:30:57,880 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:30:58,423 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:31:00,069 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 14 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:00,072 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:31:00,072 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:00,642 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:31:02,377 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 15 -- loss: tensor([0.1147], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:02,380 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:31:02,380 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:02,975 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:31:04,775 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 16 -- loss: tensor([0.1124], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:04,778 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:31:04,778 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:05,450 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:31:07,296 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 17 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:07,299 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:31:07,299 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:07,943 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:31:09,846 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 18 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:09,849 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:31:09,849 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:10,495 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:31:12,143 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 19 -- loss: tensor([0.1141], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:12,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:31:12,145 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:12,789 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:31:14,757 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 20 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:14,760 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:31:14,760 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:15,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:31:17,280 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 21 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:17,283 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:31:17,283 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:17,809 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:31:19,801 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 22 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:19,804 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:31:19,804 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:20,349 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:31:22,014 :: INFO :: evodenss.train.trainers :: [0] -- [1.66s] TRAIN epoch 23 -- loss: tensor([0.1116], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:22,016 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:31:22,016 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:22,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:31:24,824 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 24 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:24,833 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:31:24,833 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:25,402 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:31:27,004 :: INFO :: evodenss.train.trainers :: [0] -- [1.6s] TRAIN epoch 25 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:27,007 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:31:27,007 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:27,666 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:31:29,557 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 26 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:29,559 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:31:29,559 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:30,091 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:31:31,940 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 27 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:31,942 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:31:31,942 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:32,580 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:31:34,205 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 28 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:34,208 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:34,208 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:34,756 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:31:36,436 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 29 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:36,439 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:36,439 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:36,967 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:31:38,819 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 30 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:38,822 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:38,822 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:39,353 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:31:41,184 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 31 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:41,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:41,187 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:41,820 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:31:43,636 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 32 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:43,639 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:43,639 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:44,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:31:45,799 :: INFO :: evodenss.train.trainers :: [0] -- [1.56s] TRAIN epoch 33 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:45,803 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:31:45,803 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:46,392 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:31:48,105 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 34 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:48,108 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:31:48,108 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:48,678 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:31:50,529 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 35 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:50,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:50,532 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:51,128 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:31:52,763 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 36 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:52,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:31:52,766 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:53,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:31:55,219 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 37 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:55,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:31:55,222 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:55,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:31:57,592 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 38 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:57,596 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:31:57,596 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:31:58,132 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:31:59,902 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 39 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:31:59,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:31:59,907 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:00,556 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:32:02,387 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 40 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:02,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:02,390 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:02,988 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:32:04,853 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 41 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:04,856 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:04,856 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:05,518 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:32:07,386 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 42 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:07,389 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:07,389 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:07,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:32:09,596 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 43 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:09,599 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:09,599 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:10,168 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:32:12,028 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 44 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:12,031 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:12,031 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:12,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:32:14,547 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 45 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:14,549 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:14,549 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:15,159 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:32:16,914 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 46 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:16,916 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:16,916 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:17,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:32:19,335 :: INFO :: evodenss.train.trainers :: [0] -- [1.76s] TRAIN epoch 47 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:19,349 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:19,349 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:20,015 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:32:21,732 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 48 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:21,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:21,737 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:22,326 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:32:24,029 :: INFO :: evodenss.train.trainers :: [0] -- [1.7s] TRAIN epoch 49 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:24,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:32:24,046 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:25,308 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 472923,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 128.98720932006836,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.15566,  losses: {'train_loss': [0.189, 0.12, 0.117, 0.116, 0.114, 0.114, 0.112, 0.113, 0.113, 0.116, 0.113, 0.111, 0.11, 0.109, 0.11, 0.115, 0.112, 0.112, 0.11, 0.114, 0.11, 0.111, 0.11, 0.112, 0.109, 0.11, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.107, 0.108, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107], 'val_loss': [0.122, 0.103, 0.105, 0.102, 0.102, 0.102, 0.1, 0.1, 0.103, 0.101, 0.1, 0.103, 0.104, 0.103, 0.108, 0.1, 0.102, 0.099, 0.1, 0.102, 0.1, 0.102, 0.1, 0.105, 0.1, 0.099, 0.098, 0.099, 0.098, 0.098, 0.098, 0.098, 0.099, 0.098, 0.1, 0.099, 0.098, 0.098, 0.099, 0.099, 0.098, 0.098, 0.099, 0.098, 0.099, 0.103, 0.098, 0.097, 0.098, 0.103]}),  max_epochs_reached: True

2024-11-18 18:32:25,311 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 18:32:25,314 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 0, id: 0
2024-11-18 18:32:25,318 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200]
2024-11-18 18:32:25,321 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0]
2024-11-18 18:32:25,327 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.15566]
2024-11-18 18:32:30,742 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1999], device='cuda:0')
2024-11-18 18:32:30,768 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 0: 0.15566
2024-11-18 18:32:30,771 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.15566



2024-11-18 18:32:30,801 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 1
2024-11-18 18:32:30,804 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 18:32:30,817 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 18:32:30,822 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 18:32:30,825 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 18:32:30,828 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 18:32:30,832 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 18:32:30,835 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-18 18:32:30,846 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:32:30,852 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 18:32:30,856 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 18:32:30,859 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 18:32:30,862 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 18:32:30,866 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 18:32:30,869 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 18:32:30,872 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 18:32:30,875 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 18:32:30,878 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 18:32:30,881 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:32:30,886 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 18:32:30,889 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 18:32:30,894 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 18:32:30,898 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 18:32:30,901 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 18:32:30,905 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 18:32:30,908 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 18:32:30,912 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 18:32:30,915 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 18:32:30,919 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:32:30,924 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 18:32:30,930 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 18:32:30,934 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0007463019938134078 batch_size:46 epochs:50
2024-11-18 18:32:30,951 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:32:30,951 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:32:32,954 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 0 -- loss: tensor([0.1817], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:32,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.182
2024-11-18 18:32:32,957 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:33,625 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:32:35,584 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 1 -- loss: tensor([0.1180], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:35,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:32:35,587 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:36,374 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:32:38,320 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 2 -- loss: tensor([0.1144], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:38,323 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:32:38,323 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:39,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:32:40,767 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 3 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:40,769 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:32:40,769 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:41,397 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:32:43,472 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 4 -- loss: tensor([0.1121], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:43,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:32:43,475 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:44,195 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:32:46,163 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 5 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:46,176 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:32:46,176 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:46,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:32:48,759 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 6 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:48,761 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:32:48,761 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:49,391 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:32:51,395 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 7 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:51,398 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:32:51,398 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:52,026 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:32:54,309 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 8 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:54,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:32:54,312 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:54,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:32:57,053 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 9 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:57,057 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:32:57,057 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:32:57,717 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:32:59,732 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 10 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:32:59,734 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:32:59,734 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:00,425 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:33:02,353 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 11 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:02,356 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:33:02,356 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:03,042 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:33:05,255 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 12 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:05,258 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:33:05,258 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:05,988 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:33:07,823 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 13 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:07,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:33:07,826 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:08,589 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:33:10,456 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 14 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:10,458 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:33:10,458 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:11,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:33:13,063 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 15 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:13,066 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:33:13,066 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:13,823 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:33:16,044 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 16 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:16,047 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:33:16,047 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:16,713 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:33:18,621 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 17 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:18,623 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:18,623 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:19,352 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:33:21,027 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 18 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:21,030 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:21,030 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:21,792 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:33:23,835 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 19 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:23,838 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:23,838 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:24,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:33:26,575 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 20 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:26,583 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:26,583 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:27,204 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:33:29,152 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 21 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:29,155 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:29,155 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:29,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:33:31,739 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 22 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:31,742 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:31,742 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:32,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:33:34,267 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 23 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:34,270 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:34,270 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:34,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:33:36,962 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 24 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:36,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:36,965 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:37,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:33:39,734 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 25 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:39,737 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:33:39,737 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:40,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:33:42,521 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 26 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:42,524 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:42,524 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:43,261 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:33:45,152 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 27 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:45,155 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:45,155 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:45,837 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:33:47,617 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 28 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:47,620 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:47,620 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:48,351 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:33:50,428 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 29 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:50,430 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:50,431 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:51,181 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:33:53,183 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 30 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:53,186 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:53,186 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:53,856 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:33:55,924 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 31 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:55,929 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:55,929 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:56,624 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:33:58,686 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 32 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:33:58,689 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:33:58,689 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:33:59,449 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:34:01,359 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 33 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:01,362 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:01,362 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:02,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:34:03,999 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 34 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:04,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:04,002 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:04,701 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:34:06,530 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 35 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:06,533 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:06,533 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:07,270 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:34:09,356 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 36 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:09,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:09,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:10,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:34:12,023 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 37 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:12,026 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:12,026 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:12,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:34:14,572 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 38 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:14,585 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:14,585 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:15,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:34:17,216 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 39 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:17,218 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:34:17,218 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:17,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:34:19,925 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 40 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:19,928 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:34:19,928 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:20,559 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:34:22,629 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 41 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:22,633 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:22,633 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:23,344 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:34:25,214 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 42 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:25,217 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:25,217 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:25,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:34:27,985 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 43 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:27,995 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:27,995 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:28,615 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:34:30,581 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 44 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:30,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:30,584 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:31,311 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:34:33,129 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 45 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:33,132 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:33,132 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:33,851 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:34:36,006 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 46 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:36,010 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:36,010 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:36,635 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:34:38,596 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 47 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:38,599 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:38,599 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:39,324 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:34:41,726 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 48 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:41,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:41,736 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:42,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:34:44,543 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 49 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:44,545 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:34:44,545 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:45,917 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 472923,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 134.98259162902832,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.16347,  losses: {'train_loss': [0.182, 0.118, 0.114, 0.113, 0.112, 0.112, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.11, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107], 'val_loss': [0.118, 0.103, 0.104, 0.102, 0.101, 0.101, 0.102, 0.099, 0.102, 0.104, 0.099, 0.101, 0.101, 0.101, 0.104, 0.1, 0.1, 0.099, 0.098, 0.099, 0.099, 0.098, 0.099, 0.099, 0.1, 0.098, 0.099, 0.099, 0.098, 0.098, 0.101, 0.097, 0.1, 0.107, 0.099, 0.099, 0.097, 0.108, 0.105, 0.1, 0.099, 0.105, 0.1, 0.099, 0.099, 0.101, 0.104, 0.107, 0.101, 0.104]}),  max_epochs_reached: True

2024-11-18 18:34:45,921 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.16347
2024-11-18 18:34:45,928 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 18:34:45,931 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:11 kernel_size:2 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :deconv1d out_channels:94 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :deconv1d out_channels:114 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0007463019938134078 batch_size:62 epochs:50
2024-11-18 18:34:45,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:34:45,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:34:48,340 :: INFO :: evodenss.train.trainers :: [0] -- [2.39s] TRAIN epoch 0 -- loss: tensor([0.2764], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:48,343 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.276
2024-11-18 18:34:48,343 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:49,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:34:51,269 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 1 -- loss: tensor([0.1514], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:51,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.151
2024-11-18 18:34:51,272 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:52,004 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:34:53,942 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 2 -- loss: tensor([0.1422], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:53,949 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.142
2024-11-18 18:34:53,949 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:54,816 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:34:56,845 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 3 -- loss: tensor([0.1393], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:56,848 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.139
2024-11-18 18:34:56,848 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:34:57,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:34:59,822 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 4 -- loss: tensor([0.1372], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:34:59,825 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.137
2024-11-18 18:34:59,825 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:00,637 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:35:02,493 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 5 -- loss: tensor([0.1368], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:02,501 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.137
2024-11-18 18:35:02,501 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:03,217 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:35:05,288 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 6 -- loss: tensor([0.1326], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:05,291 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.133
2024-11-18 18:35:05,291 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:06,003 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:35:08,090 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 7 -- loss: tensor([0.1315], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:08,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-18 18:35:08,093 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:08,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:35:10,837 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 8 -- loss: tensor([0.1308], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:10,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-18 18:35:10,840 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:11,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:35:13,428 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 9 -- loss: tensor([0.1304], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:13,431 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.13
2024-11-18 18:35:13,431 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:14,160 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:35:16,206 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 10 -- loss: tensor([0.1290], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:16,210 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.129
2024-11-18 18:35:16,210 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:17,083 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:35:19,087 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 11 -- loss: tensor([0.1279], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:19,098 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.128
2024-11-18 18:35:19,098 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:19,823 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:35:21,871 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 12 -- loss: tensor([0.1267], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:21,874 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.127
2024-11-18 18:35:21,874 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:22,675 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:35:24,488 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 13 -- loss: tensor([0.1260], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:24,491 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.126
2024-11-18 18:35:24,491 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:25,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:35:27,096 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 14 -- loss: tensor([0.1307], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:27,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-18 18:35:27,099 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:27,925 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:35:30,074 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 15 -- loss: tensor([0.1277], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:30,077 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.128
2024-11-18 18:35:30,077 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:30,820 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:35:32,927 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 16 -- loss: tensor([0.1250], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:32,930 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.125
2024-11-18 18:35:32,930 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:33,645 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:35:35,648 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 17 -- loss: tensor([0.1270], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:35,650 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.127
2024-11-18 18:35:35,651 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:36,432 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:35:38,437 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 18 -- loss: tensor([0.1250], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:38,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.125
2024-11-18 18:35:38,440 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:39,192 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:35:41,196 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 19 -- loss: tensor([0.1230], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:41,199 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.123
2024-11-18 18:35:41,199 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:41,915 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:35:43,739 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 20 -- loss: tensor([0.1216], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:43,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-18 18:35:43,759 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:44,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:35:46,676 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 21 -- loss: tensor([0.1210], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:46,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 18:35:46,679 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:47,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:35:49,602 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 22 -- loss: tensor([0.1204], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:49,604 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:35:49,604 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:50,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:35:52,609 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 23 -- loss: tensor([0.1199], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:52,620 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:35:52,620 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:53,394 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:35:55,168 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 24 -- loss: tensor([0.1170], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:55,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:35:55,172 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:55,972 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:35:57,895 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 25 -- loss: tensor([0.1181], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:35:57,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:35:57,897 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:35:58,770 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:36:00,652 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 26 -- loss: tensor([0.1171], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:00,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:36:00,655 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:01,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:36:03,578 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 27 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:03,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:36:03,603 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:04,466 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:36:06,385 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 28 -- loss: tensor([0.1160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:06,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:36:06,388 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:07,262 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:36:09,380 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 29 -- loss: tensor([0.1150], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:09,382 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:36:09,382 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:10,097 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:36:12,078 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 30 -- loss: tensor([0.1141], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:12,081 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:36:12,081 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:12,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:36:14,814 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 31 -- loss: tensor([0.1132], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:14,816 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:36:14,816 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:15,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:36:17,541 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 32 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:17,544 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:36:17,544 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:18,374 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:36:20,507 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 33 -- loss: tensor([0.1122], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:20,509 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:36:20,510 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:21,255 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:36:23,313 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 34 -- loss: tensor([0.1115], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:23,315 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:36:23,315 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:24,037 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:36:25,824 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 35 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:25,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:36:25,826 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:26,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:36:28,753 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 36 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:28,755 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:36:28,755 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:29,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:36:31,417 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 37 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:31,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:36:31,424 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:32,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:36:34,201 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 38 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:34,204 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:36:34,204 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:35,094 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:36:37,171 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 39 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:37,174 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:36:37,174 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:37,887 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:36:40,279 :: INFO :: evodenss.train.trainers :: [0] -- [2.39s] TRAIN epoch 40 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:40,282 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:36:40,282 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:41,095 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:36:42,976 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 41 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:42,979 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:36:42,979 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:43,886 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:36:46,028 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 42 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:46,030 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:36:46,030 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:46,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:36:48,893 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 43 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:48,896 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:36:48,896 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:49,641 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:36:52,015 :: INFO :: evodenss.train.trainers :: [0] -- [2.37s] TRAIN epoch 44 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:52,017 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:36:52,017 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:52,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:36:54,682 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 45 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:54,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:36:54,685 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:55,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:36:57,431 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 46 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:57,443 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:36:57,443 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:36:58,209 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:36:59,930 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 47 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:36:59,933 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:36:59,933 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:00,677 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:37:02,692 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 48 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:02,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:37:02,694 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:03,494 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:37:05,425 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 49 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:05,429 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:37:05,429 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:07,060 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 792420,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 141.12771558761597,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.16007,  losses: {'train_loss': [0.276, 0.151, 0.142, 0.139, 0.137, 0.137, 0.133, 0.131, 0.131, 0.13, 0.129, 0.128, 0.127, 0.126, 0.131, 0.128, 0.125, 0.127, 0.125, 0.123, 0.122, 0.121, 0.12, 0.12, 0.117, 0.118, 0.117, 0.116, 0.116, 0.115, 0.114, 0.113, 0.112, 0.112, 0.111, 0.111, 0.111, 0.111, 0.11, 0.111, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.11, 0.109, 0.109], 'val_loss': [0.245, 0.099, 0.152, 0.136, 0.1, 0.118, 0.089, 0.094, 0.097, 0.098, 0.094, 0.108, 0.088, 0.091, 0.139, 0.095, 0.089, 0.105, 0.089, 0.088, 0.094, 0.086, 0.091, 0.095, 0.088, 0.085, 0.082, 0.082, 0.088, 0.082, 0.086, 0.085, 0.083, 0.083, 0.082, 0.081, 0.081, 0.082, 0.082, 0.081, 0.085, 0.082, 0.083, 0.088, 0.082, 0.085, 0.083, 0.086, 0.082, 0.082]}),  max_epochs_reached: True

2024-11-18 18:37:07,063 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.16007
2024-11-18 18:37:07,069 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-18 18:37:07,073 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0008520037620936978 batch_size:46 epochs:50
2024-11-18 18:37:07,087 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:37:07,087 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:37:09,310 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 0 -- loss: tensor([0.1769], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:09,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.177
2024-11-18 18:37:09,313 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:10,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:37:12,203 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 1 -- loss: tensor([0.1238], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:12,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-18 18:37:12,205 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:12,894 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:37:15,292 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 2 -- loss: tensor([0.1189], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:15,294 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:37:15,294 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:15,959 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:37:17,870 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 3 -- loss: tensor([0.1171], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:17,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:37:17,873 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:18,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:37:20,802 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 4 -- loss: tensor([0.1159], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:20,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:37:20,805 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:21,472 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:37:23,519 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 5 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:23,521 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:37:23,521 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:24,175 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:37:26,183 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 6 -- loss: tensor([0.1136], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:26,186 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:37:26,186 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:26,928 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:37:28,837 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 7 -- loss: tensor([0.1140], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:28,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:37:28,839 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:29,555 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:37:31,331 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 8 -- loss: tensor([0.1136], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:31,335 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:37:31,335 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:32,122 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:37:34,006 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 9 -- loss: tensor([0.1128], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:34,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:37:34,009 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:34,764 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:37:36,877 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 10 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:36,880 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:37:36,880 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:37,536 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:37:39,623 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 11 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:39,625 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:37:39,625 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:40,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:37:42,601 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 12 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:42,604 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:37:42,604 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:43,371 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:37:45,306 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 13 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:45,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:37:45,309 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:45,973 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:37:47,847 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 14 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:47,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:37:47,850 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:48,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:37:50,738 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 15 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:50,741 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:37:50,741 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:51,506 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:37:53,699 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 16 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:53,701 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:37:53,701 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:54,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:37:56,841 :: INFO :: evodenss.train.trainers :: [0] -- [2.47s] TRAIN epoch 17 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:56,844 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:37:56,844 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:37:57,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:37:59,710 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 18 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:37:59,713 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:37:59,713 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:00,446 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:38:02,272 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 19 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:02,274 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:38:02,274 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:02,937 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:38:05,261 :: INFO :: evodenss.train.trainers :: [0] -- [2.32s] TRAIN epoch 20 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:05,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:38:05,264 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:05,979 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:38:07,981 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 21 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:07,984 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:38:07,985 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:08,726 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:38:10,836 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 22 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:10,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:38:10,839 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:11,604 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:38:13,717 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 23 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:13,720 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:38:13,720 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:14,438 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:38:16,563 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 24 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:16,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:38:16,566 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:17,288 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:38:19,495 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 25 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:19,498 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:19,498 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:20,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:38:21,880 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 26 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:21,882 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:21,882 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:22,594 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:38:24,733 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 27 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:24,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:24,736 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:25,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:38:27,314 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 28 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:27,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:27,317 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:28,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:38:29,949 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 29 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:29,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:29,952 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:30,682 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:38:32,398 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 30 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:32,401 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:32,401 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:33,164 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:38:35,002 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 31 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:35,005 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:35,005 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:35,856 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:38:37,712 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 32 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:37,715 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:37,715 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:38,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:38:40,340 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 33 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:40,343 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:40,343 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:41,054 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:38:43,008 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 34 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:43,011 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:43,011 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:43,717 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:38:45,541 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 35 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:45,544 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:45,544 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:46,320 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:38:48,160 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 36 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:48,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:48,163 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:48,940 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:38:51,039 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 37 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:51,041 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:51,041 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:51,825 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:38:53,948 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 38 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:53,951 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:53,951 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:54,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:38:56,825 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 39 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:56,827 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:38:56,827 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:38:57,487 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:38:59,424 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 40 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:38:59,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:38:59,427 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:00,190 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:39:02,333 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 41 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:02,336 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:39:02,336 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:02,994 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:39:04,914 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 42 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:04,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:39:04,917 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:05,691 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:39:07,869 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 43 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:07,872 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:39:07,872 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:08,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:39:10,730 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 44 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:10,733 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:39:10,733 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:11,521 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:39:13,414 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 45 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:13,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:39:13,417 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:14,153 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:39:16,194 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 46 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:16,198 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:39:16,198 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:16,869 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:39:18,657 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 47 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:18,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:39:18,660 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:19,429 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:39:21,393 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 48 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:21,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:39:21,396 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:22,109 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:39:24,269 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 49 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:24,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:39:24,272 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:25,634 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 445191,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 138.55993175506592,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.14469,  losses: {'train_loss': [0.177, 0.124, 0.119, 0.117, 0.116, 0.115, 0.114, 0.114, 0.114, 0.113, 0.113, 0.112, 0.113, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.108, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.106, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.106, 0.106], 'val_loss': [0.131, 0.105, 0.106, 0.105, 0.107, 0.107, 0.106, 0.104, 0.103, 0.103, 0.109, 0.113, 0.104, 0.102, 0.103, 0.106, 0.103, 0.103, 0.101, 0.101, 0.1, 0.104, 0.098, 0.098, 0.101, 0.099, 0.098, 0.098, 0.098, 0.1, 0.097, 0.097, 0.098, 0.099, 0.1, 0.097, 0.098, 0.1, 0.098, 0.097, 0.099, 0.097, 0.1, 0.097, 0.1, 0.102, 0.099, 0.099, 0.098, 0.1]}),  max_epochs_reached: True

2024-11-18 18:39:25,637 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.14469
2024-11-18 18:39:25,643 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-18 18:39:25,647 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:64 kernel_size:1 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:66 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:lars lr_weights:0.1491783101750241 lr_biases:0.0024462105423644857 momentum:0.7297638980577819 weight_decay:6.595228251526335e-06 batch_size:46 epochs:50
2024-11-18 18:39:25,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:39:25,661 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:39:27,831 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 0 -- loss: tensor([0.9785], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:27,834 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.978
2024-11-18 18:39:27,834 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:28,628 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:39:30,561 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 1 -- loss: tensor([0.9592], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:30,564 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.959
2024-11-18 18:39:30,564 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:31,313 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:39:33,420 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 2 -- loss: tensor([0.9497], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:33,422 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.95
2024-11-18 18:39:33,422 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:34,200 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:39:35,894 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 3 -- loss: tensor([0.9383], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:35,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.938
2024-11-18 18:39:35,897 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:36,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:39:38,579 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 4 -- loss: tensor([0.9238], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:38,582 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.924
2024-11-18 18:39:38,582 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:39,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:39:41,198 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 5 -- loss: tensor([0.9107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:41,204 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.911
2024-11-18 18:39:41,204 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:41,969 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:39:44,180 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 6 -- loss: tensor([0.9011], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:44,183 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.901
2024-11-18 18:39:44,183 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:44,895 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:39:46,781 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 7 -- loss: tensor([0.8915], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:46,784 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.892
2024-11-18 18:39:46,785 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:47,444 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:39:49,569 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 8 -- loss: tensor([0.8792], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:49,571 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.879
2024-11-18 18:39:49,572 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:50,338 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:39:52,433 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 9 -- loss: tensor([0.8692], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:52,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.869
2024-11-18 18:39:52,436 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:53,197 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:39:55,082 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 10 -- loss: tensor([0.8566], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:55,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.857
2024-11-18 18:39:55,099 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:55,866 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:39:58,206 :: INFO :: evodenss.train.trainers :: [0] -- [2.34s] TRAIN epoch 11 -- loss: tensor([0.8467], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:39:58,208 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.847
2024-11-18 18:39:58,208 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:39:58,877 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:40:01,101 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 12 -- loss: tensor([0.8379], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:01,105 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.838
2024-11-18 18:40:01,105 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:01,887 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:40:03,765 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 13 -- loss: tensor([0.8291], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:03,768 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.829
2024-11-18 18:40:03,768 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:04,553 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:40:06,637 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 14 -- loss: tensor([0.8190], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:06,640 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.819
2024-11-18 18:40:06,640 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:07,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:40:09,319 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 15 -- loss: tensor([0.8100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:09,321 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.81
2024-11-18 18:40:09,322 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:10,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:40:12,110 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 16 -- loss: tensor([0.7984], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:12,113 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.798
2024-11-18 18:40:12,113 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:12,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:40:14,910 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 17 -- loss: tensor([0.7909], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:14,912 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.791
2024-11-18 18:40:14,913 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:15,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:40:17,555 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 18 -- loss: tensor([0.7829], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:17,557 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.783
2024-11-18 18:40:17,557 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:18,255 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:40:20,396 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 19 -- loss: tensor([0.7734], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:20,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.773
2024-11-18 18:40:20,399 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:21,061 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:40:23,042 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 20 -- loss: tensor([0.7673], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:23,045 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.767
2024-11-18 18:40:23,045 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:23,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:40:25,775 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 21 -- loss: tensor([0.7590], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:25,778 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.759
2024-11-18 18:40:25,778 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:26,467 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:40:28,392 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 22 -- loss: tensor([0.7491], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:28,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.749
2024-11-18 18:40:28,395 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:29,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:40:30,889 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 23 -- loss: tensor([0.7438], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:30,891 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.744
2024-11-18 18:40:30,892 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:31,597 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:40:33,458 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 24 -- loss: tensor([0.7336], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:33,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.734
2024-11-18 18:40:33,460 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:34,186 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:40:36,183 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 25 -- loss: tensor([0.7268], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:36,185 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.727
2024-11-18 18:40:36,185 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:36,859 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:40:39,062 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 26 -- loss: tensor([0.7194], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:39,065 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.719
2024-11-18 18:40:39,065 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:39,707 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:40:41,731 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 27 -- loss: tensor([0.7128], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:41,734 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.713
2024-11-18 18:40:41,734 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:42,449 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:40:44,456 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 28 -- loss: tensor([0.7044], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:44,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.704
2024-11-18 18:40:44,460 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:45,120 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:40:47,127 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 29 -- loss: tensor([0.6979], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:47,154 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.698
2024-11-18 18:40:47,154 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:47,870 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:40:49,969 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 30 -- loss: tensor([0.6911], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:49,971 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.691
2024-11-18 18:40:49,971 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:50,749 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:40:52,949 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 31 -- loss: tensor([0.6853], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:52,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.685
2024-11-18 18:40:52,952 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:53,717 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:40:55,720 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 32 -- loss: tensor([0.6789], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:55,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.679
2024-11-18 18:40:55,723 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:56,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:40:58,508 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 33 -- loss: tensor([0.6722], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:40:58,510 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.672
2024-11-18 18:40:58,510 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:40:59,287 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:41:01,520 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 34 -- loss: tensor([0.6669], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:01,524 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.667
2024-11-18 18:41:01,524 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:02,194 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:41:04,142 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 35 -- loss: tensor([0.6601], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:04,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.66
2024-11-18 18:41:04,145 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:04,931 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:41:06,914 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 36 -- loss: tensor([0.6550], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:06,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.655
2024-11-18 18:41:06,917 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:07,703 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:41:09,611 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 37 -- loss: tensor([0.6490], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:09,614 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.649
2024-11-18 18:41:09,614 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:10,357 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:41:12,755 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 38 -- loss: tensor([0.6434], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:12,775 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.643
2024-11-18 18:41:12,775 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:13,443 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:41:15,364 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 39 -- loss: tensor([0.6381], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:15,367 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.638
2024-11-18 18:41:15,367 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:16,122 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:41:18,208 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 40 -- loss: tensor([0.6331], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:18,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.633
2024-11-18 18:41:18,211 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:18,877 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:41:20,982 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 41 -- loss: tensor([0.6276], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:20,985 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.628
2024-11-18 18:41:20,985 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:21,662 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:41:23,684 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 42 -- loss: tensor([0.6227], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:23,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.623
2024-11-18 18:41:23,687 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:24,416 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:41:26,569 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 43 -- loss: tensor([0.6168], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:26,572 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.617
2024-11-18 18:41:26,572 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:27,340 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:41:29,309 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 44 -- loss: tensor([0.6130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:29,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.613
2024-11-18 18:41:29,312 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:29,970 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:41:31,867 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 45 -- loss: tensor([0.6076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:31,870 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.608
2024-11-18 18:41:31,870 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:32,535 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:41:34,743 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 46 -- loss: tensor([0.6028], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:34,746 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.603
2024-11-18 18:41:34,746 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:35,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:41:37,449 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 47 -- loss: tensor([0.5987], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:37,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.599
2024-11-18 18:41:37,452 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:38,112 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:41:40,169 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 48 -- loss: tensor([0.5951], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:40,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.595
2024-11-18 18:41:40,172 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:40,841 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:41:43,240 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 49 -- loss: tensor([0.5897], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:43,256 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.59
2024-11-18 18:41:43,256 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:44,737 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 422449,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 139.08842396736145,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 8.34891,  losses: {'train_loss': [0.978, 0.959, 0.95, 0.938, 0.924, 0.911, 0.901, 0.892, 0.879, 0.869, 0.857, 0.847, 0.838, 0.829, 0.819, 0.81, 0.798, 0.791, 0.783, 0.773, 0.767, 0.759, 0.749, 0.744, 0.734, 0.727, 0.719, 0.713, 0.704, 0.698, 0.691, 0.685, 0.679, 0.672, 0.667, 0.66, 0.655, 0.649, 0.643, 0.638, 0.633, 0.628, 0.623, 0.617, 0.613, 0.608, 0.603, 0.599, 0.595, 0.59], 'val_loss': [0.735, 0.723, 0.716, 0.712, 0.707, 0.705, 0.705, 0.711, 0.713, 0.713, 0.716, 0.72, 0.727, 0.726, 0.73, 0.733, 0.733, 0.734, 0.734, 0.732, 0.733, 0.733, 0.729, 0.726, 0.725, 0.72, 0.717, 0.711, 0.709, 0.705, 0.703, 0.698, 0.693, 0.69, 0.687, 0.684, 0.676, 0.675, 0.667, 0.665, 0.661, 0.659, 0.652, 0.649, 0.644, 0.64, 0.638, 0.629, 0.627, 0.622]}),  max_epochs_reached: True

2024-11-18 18:41:44,741 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 8.34891
2024-11-18 18:41:44,751 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 18:41:44,758 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 2, id: 2
2024-11-18 18:41:44,761 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-18 18:41:44,764 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-18 18:41:44,769 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.16347, 0.16007, 0.14469, 8.34891]
2024-11-18 18:41:48,048 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1826], device='cuda:0')
2024-11-18 18:41:48,052 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 1: 0.14469
2024-11-18 18:41:48,055 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.14469



2024-11-18 18:41:48,114 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 2
2024-11-18 18:41:48,126 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 18:41:48,139 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 18:41:48,144 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 18:41:48,147 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:41:48,153 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 18:41:48,157 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 18:41:48,162 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 18:41:48,166 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:41:48,172 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: True
2024-11-18 18:41:48,181 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 18:41:48,187 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 18:41:48,192 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 18:41:48,196 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 18:41:48,200 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 18:41:48,204 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 18:41:48,208 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 18:41:48,212 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:41:48,217 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 18:41:48,223 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 18:41:48,226 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0008520037620936978 batch_size:46 epochs:50
2024-11-18 18:41:48,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:41:48,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:41:50,368 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 0 -- loss: tensor([0.1774], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:50,370 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.177
2024-11-18 18:41:50,371 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:51,022 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:41:53,082 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 1 -- loss: tensor([0.1261], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:53,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.126
2024-11-18 18:41:53,085 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:53,798 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:41:56,366 :: INFO :: evodenss.train.trainers :: [0] -- [2.57s] TRAIN epoch 2 -- loss: tensor([0.1215], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:56,369 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 18:41:56,369 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:41:57,171 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:41:59,298 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 3 -- loss: tensor([0.1179], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:41:59,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:41:59,301 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:00,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:42:02,232 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 4 -- loss: tensor([0.1189], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:02,235 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:42:02,235 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:03,017 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:42:04,864 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 5 -- loss: tensor([0.1195], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:04,867 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:42:04,867 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:05,577 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:42:07,755 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 6 -- loss: tensor([0.1169], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:07,757 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:42:07,757 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:08,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:42:10,594 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 7 -- loss: tensor([0.1170], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:10,598 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:42:10,598 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:11,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:42:13,344 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 8 -- loss: tensor([0.1176], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:13,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:42:13,347 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:14,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:42:16,127 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 9 -- loss: tensor([0.1182], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:16,130 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:42:16,130 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:16,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:42:19,243 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 10 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:19,257 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:42:19,257 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:19,968 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:42:22,009 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 11 -- loss: tensor([0.1194], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:22,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:42:22,012 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:22,782 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:42:24,849 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 12 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:24,854 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:42:24,854 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:25,565 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:42:27,691 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 13 -- loss: tensor([0.1169], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:27,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:42:27,694 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:28,409 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:42:30,378 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 14 -- loss: tensor([0.1200], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:30,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:42:30,381 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:31,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:42:32,954 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 15 -- loss: tensor([0.1187], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:32,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:42:32,957 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:33,707 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:42:35,831 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 16 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:35,835 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:42:35,836 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:36,591 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:42:38,693 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 17 -- loss: tensor([0.1127], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:38,695 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:42:38,695 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:39,408 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:42:41,481 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 18 -- loss: tensor([0.1172], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:41,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:42:41,483 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:42,245 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:42:44,356 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 19 -- loss: tensor([0.1124], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:44,360 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:42:44,360 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:45,071 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:42:47,143 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 20 -- loss: tensor([0.1135], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:47,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:42:47,146 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:47,864 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:42:50,015 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 21 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:50,018 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:42:50,018 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:50,728 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:42:52,673 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 22 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:52,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:42:52,683 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:53,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:42:55,780 :: INFO :: evodenss.train.trainers :: [0] -- [2.38s] TRAIN epoch 23 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:55,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:42:55,783 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:56,503 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:42:58,515 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 24 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:42:58,518 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:42:58,518 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:42:59,221 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:43:01,233 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 25 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:01,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:43:01,239 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:01,954 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:43:03,936 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 26 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:03,939 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:43:03,939 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:04,656 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:43:06,740 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 27 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:06,742 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:43:06,743 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:07,453 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:43:09,473 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 28 -- loss: tensor([0.1116], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:09,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:43:09,483 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:10,192 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:43:12,231 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 29 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:12,234 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:43:12,234 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:12,947 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:43:15,023 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 30 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:15,026 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:43:15,026 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:15,738 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:43:17,628 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 31 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:17,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:43:17,631 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:18,357 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:43:20,523 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 32 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:20,526 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:43:20,526 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:21,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:43:23,277 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 33 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:23,280 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:43:23,280 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:23,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:43:26,081 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 34 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:26,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:43:26,084 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:26,810 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:43:28,875 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 35 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:28,878 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:43:28,878 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:29,606 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:43:31,798 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 36 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:31,800 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:31,800 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:32,522 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:43:34,784 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 37 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:34,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:34,788 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:35,540 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:43:37,563 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 38 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:37,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:37,567 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:38,342 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:43:40,326 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 39 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:40,329 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:40,329 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:41,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:43:43,017 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 40 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:43,020 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:43,021 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:43,729 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:43:46,019 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 41 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:46,022 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:46,022 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:46,768 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:43:48,756 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 42 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:48,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:48,759 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:49,472 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:43:51,457 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 43 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:51,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:51,460 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:52,173 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:43:54,204 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 44 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:54,207 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:54,207 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:54,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:43:57,007 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 45 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:57,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:43:57,009 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:43:57,719 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:43:59,772 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 46 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:43:59,775 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:43:59,775 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:00,506 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:44:02,682 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 47 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:02,690 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:44:02,690 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:03,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:44:05,510 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 48 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:05,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:44:05,513 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:06,224 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:44:08,209 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 49 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:08,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:44:08,212 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:09,682 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 445191,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 141.45403170585632,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.14447,  losses: {'train_loss': [0.177, 0.126, 0.121, 0.118, 0.119, 0.12, 0.117, 0.117, 0.118, 0.118, 0.116, 0.119, 0.115, 0.117, 0.12, 0.119, 0.116, 0.113, 0.117, 0.112, 0.113, 0.115, 0.111, 0.112, 0.111, 0.111, 0.111, 0.111, 0.112, 0.111, 0.111, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.107, 0.108, 0.108], 'val_loss': [0.129, 0.107, 0.111, 0.108, 0.1, 0.105, 0.101, 0.112, 0.127, 0.105, 0.112, 0.103, 0.119, 0.117, 0.103, 0.115, 0.104, 0.104, 0.106, 0.102, 0.101, 0.102, 0.103, 0.103, 0.098, 0.103, 0.101, 0.099, 0.1, 0.098, 0.102, 0.098, 0.098, 0.098, 0.098, 0.098, 0.097, 0.097, 0.098, 0.097, 0.098, 0.099, 0.098, 0.097, 0.098, 0.098, 0.098, 0.098, 0.097, 0.097]}),  max_epochs_reached: True

2024-11-18 18:44:09,715 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.14447
2024-11-18 18:44:09,722 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 18:44:09,725 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :deconv1d out_channels:39 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :deconv1d out_channels:63 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:False bias:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:8.050752729086422e-05 batch_size:46 epochs:50
2024-11-18 18:44:09,739 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:44:09,739 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:44:11,793 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 0 -- loss: tensor([2.6777], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:11,796 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 2.678
2024-11-18 18:44:11,796 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:12,576 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:44:14,682 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 1 -- loss: tensor([1.3351], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:14,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.335
2024-11-18 18:44:14,685 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:15,404 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:44:17,578 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 2 -- loss: tensor([1.4119], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:17,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.412
2024-11-18 18:44:17,581 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:18,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:44:20,378 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 3 -- loss: tensor([1.3673], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:20,380 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.367
2024-11-18 18:44:20,380 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:21,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:44:23,210 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 4 -- loss: tensor([1.3613], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:23,213 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.361
2024-11-18 18:44:23,213 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:23,929 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:44:25,873 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 5 -- loss: tensor([1.3273], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:25,885 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.327
2024-11-18 18:44:25,885 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:26,602 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:44:28,376 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 6 -- loss: tensor([1.2668], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:28,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.267
2024-11-18 18:44:28,381 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:29,098 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:44:31,105 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 7 -- loss: tensor([1.1541], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:31,107 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.154
2024-11-18 18:44:31,107 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:31,914 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:44:33,974 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 8 -- loss: tensor([1.0950], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:33,977 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 1.095
2024-11-18 18:44:33,977 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:34,682 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:44:36,813 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 9 -- loss: tensor([0.9677], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:36,816 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.968
2024-11-18 18:44:36,816 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:37,520 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:44:39,583 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 10 -- loss: tensor([0.8842], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:39,586 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.884
2024-11-18 18:44:39,586 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:40,296 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:44:42,689 :: INFO :: evodenss.train.trainers :: [0] -- [2.39s] TRAIN epoch 11 -- loss: tensor([0.7965], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:42,692 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.796
2024-11-18 18:44:42,692 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:43,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:44:45,438 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 12 -- loss: tensor([0.6846], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:45,441 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.685
2024-11-18 18:44:45,441 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:46,150 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:44:48,186 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 13 -- loss: tensor([0.6072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:48,189 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.607
2024-11-18 18:44:48,189 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:48,906 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:44:51,147 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 14 -- loss: tensor([0.5106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:51,150 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.511
2024-11-18 18:44:51,150 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:51,883 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:44:54,070 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 15 -- loss: tensor([0.4536], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:54,073 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.454
2024-11-18 18:44:54,073 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:54,828 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:44:56,829 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 16 -- loss: tensor([0.3874], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:56,831 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.387
2024-11-18 18:44:56,832 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:44:57,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:44:59,667 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 17 -- loss: tensor([0.3335], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:44:59,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.333
2024-11-18 18:44:59,670 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:00,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:45:02,421 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 18 -- loss: tensor([0.2841], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:02,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.284
2024-11-18 18:45:02,424 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:03,233 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:45:05,283 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 19 -- loss: tensor([0.2491], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:05,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.249
2024-11-18 18:45:05,286 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:06,110 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:45:08,045 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 20 -- loss: tensor([0.2165], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:08,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.216
2024-11-18 18:45:08,048 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:08,769 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:45:10,666 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 21 -- loss: tensor([0.1889], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:10,669 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.189
2024-11-18 18:45:10,669 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:11,394 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:45:13,667 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 22 -- loss: tensor([0.1642], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:13,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.164
2024-11-18 18:45:13,670 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:14,386 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:45:16,501 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 23 -- loss: tensor([0.1488], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:16,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.149
2024-11-18 18:45:16,504 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:17,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:45:19,275 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 24 -- loss: tensor([0.1342], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:19,278 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.134
2024-11-18 18:45:19,278 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:19,999 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:45:22,075 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 25 -- loss: tensor([0.1245], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:22,078 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.125
2024-11-18 18:45:22,078 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:22,808 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:45:24,838 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 26 -- loss: tensor([0.1182], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:24,841 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:45:24,841 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:25,561 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:45:27,587 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 27 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:27,589 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:45:27,589 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:28,307 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:45:30,317 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 28 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:30,320 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:45:30,320 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:31,143 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:45:33,459 :: INFO :: evodenss.train.trainers :: [0] -- [2.32s] TRAIN epoch 29 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:33,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:45:33,462 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:34,173 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:45:36,234 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 30 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:36,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:45:36,237 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:36,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:45:38,883 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 31 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:38,886 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:45:38,886 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:39,599 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:45:41,709 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 32 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:41,712 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:45:41,712 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:42,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:45:44,474 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 33 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:44,477 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:45:44,478 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:45,196 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:45:47,173 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 34 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:47,175 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:45:47,175 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:47,894 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:45:49,837 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 35 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:49,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:45:49,839 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:50,609 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:45:52,647 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 36 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:52,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:45:52,660 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:53,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:45:55,363 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 37 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:55,379 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:45:55,379 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:56,167 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:45:58,028 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 38 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:45:58,031 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:45:58,032 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:45:58,744 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:46:00,731 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 39 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:00,735 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:00,735 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:01,444 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:46:03,414 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 40 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:03,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:03,417 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:04,135 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:46:06,210 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 41 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:06,213 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:06,213 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:06,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:46:08,819 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 42 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:08,822 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:08,822 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:09,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:46:11,410 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 43 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:11,414 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:11,414 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:12,127 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:46:14,184 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 44 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:14,188 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:14,188 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:14,923 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:46:17,007 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 45 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:17,011 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:17,011 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:17,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:46:19,735 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 46 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:19,738 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:19,738 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:20,456 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:46:22,538 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 47 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:22,540 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:22,541 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:23,256 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:46:25,335 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 48 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:25,342 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:25,342 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:26,061 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:46:27,937 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 49 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:27,940 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:46:27,940 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:29,458 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 5339486,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 139.7315354347229,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.19116,  losses: {'train_loss': [2.678, 1.335, 1.412, 1.367, 1.361, 1.327, 1.267, 1.154, 1.095, 0.968, 0.884, 0.796, 0.685, 0.607, 0.511, 0.454, 0.387, 0.333, 0.284, 0.249, 0.216, 0.189, 0.164, 0.149, 0.134, 0.125, 0.118, 0.115, 0.112, 0.111, 0.109, 0.109, 0.108, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107], 'val_loss': [1.038, 1.103, 0.457, 0.387, 0.641, 0.468, 1.448, 1.094, 0.243, 1.17, 0.736, 0.789, 0.143, 0.297, 0.266, 0.122, 0.172, 0.109, 0.121, 0.104, 0.099, 0.099, 0.111, 0.106, 0.104, 0.102, 0.1, 0.1, 0.101, 0.1, 0.099, 0.099, 0.098, 0.098, 0.098, 0.098, 0.098, 0.098, 0.098, 0.097, 0.097, 0.097, 0.098, 0.097, 0.097, 0.098, 0.098, 0.098, 0.098, 0.098]}),  max_epochs_reached: True

2024-11-18 18:46:29,461 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.19116
2024-11-18 18:46:29,468 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-18 18:46:29,472 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0008520037620936978 batch_size:34 epochs:50
2024-11-18 18:46:29,486 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:46:29,486 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:46:31,806 :: INFO :: evodenss.train.trainers :: [0] -- [2.32s] TRAIN epoch 0 -- loss: tensor([0.1647], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:31,808 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.165
2024-11-18 18:46:31,809 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:32,520 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:46:34,677 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 1 -- loss: tensor([0.1268], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:34,680 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.127
2024-11-18 18:46:34,680 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:35,344 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:46:37,458 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 2 -- loss: tensor([0.1237], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:37,463 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-18 18:46:37,463 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:38,122 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:46:40,247 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 3 -- loss: tensor([0.1217], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:40,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-18 18:46:40,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:40,927 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:46:43,049 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 4 -- loss: tensor([0.1199], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:43,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:46:43,052 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:43,793 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:46:45,932 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 5 -- loss: tensor([0.1192], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:45,936 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:46:45,936 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:46,611 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:46:48,730 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 6 -- loss: tensor([0.1178], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:48,733 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:46:48,733 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:49,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:46:51,522 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 7 -- loss: tensor([0.1167], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:51,525 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:46:51,525 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:52,200 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:46:54,208 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 8 -- loss: tensor([0.1179], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:54,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:46:54,211 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:54,944 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:46:56,947 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 9 -- loss: tensor([0.1198], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:56,950 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:46:56,951 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:46:57,617 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:46:59,724 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 10 -- loss: tensor([0.1172], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:46:59,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:46:59,727 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:00,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:47:02,648 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 11 -- loss: tensor([0.1159], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:02,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:47:02,651 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:03,315 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:47:05,401 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 12 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:05,404 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:47:05,405 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:06,068 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:47:08,313 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 13 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:08,315 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:47:08,315 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:08,992 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:47:11,077 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 14 -- loss: tensor([0.1136], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:11,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:47:11,080 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:11,752 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:47:13,952 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 15 -- loss: tensor([0.1144], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:13,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:47:13,955 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:14,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:47:16,753 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 16 -- loss: tensor([0.1141], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:16,756 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:47:16,756 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:17,463 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:47:19,646 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 17 -- loss: tensor([0.1121], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:19,649 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:47:19,649 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:20,349 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:47:22,488 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 18 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:22,501 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:47:22,501 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:23,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:47:25,251 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 19 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:25,254 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:47:25,254 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:25,914 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:47:27,948 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 20 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:27,951 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:47:27,952 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:28,606 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:47:30,571 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 21 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:30,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:47:30,574 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:31,251 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:47:33,268 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 22 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:33,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:47:33,272 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:33,937 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:47:36,185 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 23 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:36,188 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:47:36,188 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:36,905 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:47:38,834 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 24 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:38,838 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:47:38,838 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:39,516 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:47:41,159 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 25 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:41,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:47:41,162 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:41,840 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:47:44,117 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 26 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:44,119 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:47:44,119 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:44,804 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:47:46,972 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 27 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:46,975 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:47:46,975 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:47,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:47:49,731 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 28 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:49,734 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:47:49,734 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:50,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:47:52,421 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 29 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:52,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:47:52,424 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:53,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:47:55,344 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 30 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:55,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:47:55,347 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:56,034 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:47:57,901 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 31 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:47:57,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:47:57,904 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:47:58,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:48:00,607 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 32 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:00,610 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:48:00,610 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:01,298 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:48:03,489 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 33 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:03,497 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:48:03,497 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:04,178 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:48:06,401 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 34 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:06,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:06,406 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:07,087 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:48:09,117 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 35 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:09,120 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:48:09,120 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:09,810 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:48:11,872 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 36 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:11,875 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:11,875 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:12,543 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:48:14,134 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 37 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:14,139 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:14,139 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:14,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:48:17,021 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 38 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:17,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:17,027 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:17,698 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:48:19,770 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 39 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:19,774 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:19,774 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:20,459 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:48:22,532 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 40 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:22,535 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:48:22,535 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:23,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:48:25,239 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 41 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:25,242 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:25,242 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:25,960 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:48:28,009 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 42 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:28,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:28,012 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:28,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:48:30,917 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 43 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:30,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:30,926 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:31,618 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:48:33,640 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 44 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:33,643 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:33,643 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:34,322 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:48:36,566 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 45 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:36,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:36,569 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:37,228 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:48:39,240 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 46 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:39,243 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:39,244 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:39,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:48:41,956 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 47 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:41,959 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:48:41,959 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:42,627 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:48:44,720 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 48 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:44,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:48:44,723 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:45,404 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:48:47,563 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 49 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:47,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:48:47,566 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:48,959 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 445191,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 139.4855706691742,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.14217,  losses: {'train_loss': [0.165, 0.127, 0.124, 0.122, 0.12, 0.119, 0.118, 0.117, 0.118, 0.12, 0.117, 0.116, 0.115, 0.115, 0.114, 0.114, 0.114, 0.112, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106], 'val_loss': [0.121, 0.109, 0.111, 0.107, 0.105, 0.104, 0.105, 0.103, 0.105, 0.104, 0.118, 0.101, 0.099, 0.1, 0.102, 0.1, 0.101, 0.102, 0.096, 0.099, 0.096, 0.108, 0.097, 0.101, 0.104, 0.101, 0.092, 0.096, 0.104, 0.103, 0.093, 0.099, 0.093, 0.092, 0.095, 0.095, 0.092, 0.096, 0.099, 0.09, 0.093, 0.096, 0.091, 0.097, 0.108, 0.1, 0.178, 0.108, 0.112, 0.093]}),  max_epochs_reached: True

2024-11-18 18:48:48,962 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.14217
2024-11-18 18:48:48,969 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-18 18:48:48,972 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:12 kernel_size:5 stride:1 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :deconv1d out_channels:17 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0006683652309594539 batch_size:46 epochs:50
2024-11-18 18:48:48,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:48:48,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:48:51,406 :: INFO :: evodenss.train.trainers :: [0] -- [2.42s] TRAIN epoch 0 -- loss: tensor([0.2102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:51,409 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.21
2024-11-18 18:48:51,409 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:52,183 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:48:54,200 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 1 -- loss: tensor([0.1386], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:54,203 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.139
2024-11-18 18:48:54,203 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:54,923 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:48:56,879 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 2 -- loss: tensor([0.1334], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:56,882 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.133
2024-11-18 18:48:56,882 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:48:57,604 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:48:59,711 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 3 -- loss: tensor([0.1294], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:48:59,714 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.129
2024-11-18 18:48:59,714 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:00,434 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:49:02,993 :: INFO :: evodenss.train.trainers :: [0] -- [2.56s] TRAIN epoch 4 -- loss: tensor([0.1276], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:02,996 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.128
2024-11-18 18:49:02,996 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:03,726 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:49:05,584 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 5 -- loss: tensor([0.1268], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:05,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.127
2024-11-18 18:49:05,587 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:06,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:49:08,411 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 6 -- loss: tensor([0.1235], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:08,414 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-18 18:49:08,415 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:09,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:49:11,258 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 7 -- loss: tensor([0.1221], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:11,261 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-18 18:49:11,261 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:11,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:49:13,950 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 8 -- loss: tensor([0.1282], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:13,953 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.128
2024-11-18 18:49:13,953 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:14,680 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:49:16,655 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 9 -- loss: tensor([0.1237], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:16,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-18 18:49:16,658 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:17,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:49:19,395 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 10 -- loss: tensor([0.1220], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:19,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-18 18:49:19,399 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:20,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:49:22,166 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 11 -- loss: tensor([0.1213], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:22,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 18:49:22,169 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:22,879 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:49:24,839 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 12 -- loss: tensor([0.1230], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:24,842 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.123
2024-11-18 18:49:24,842 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:25,605 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:49:27,673 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 13 -- loss: tensor([0.1190], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:27,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:49:27,685 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:28,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:49:30,340 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 14 -- loss: tensor([0.1190], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:30,343 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:49:30,343 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:31,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:49:33,114 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 15 -- loss: tensor([0.1194], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:33,117 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:49:33,117 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:33,849 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:49:36,303 :: INFO :: evodenss.train.trainers :: [0] -- [2.45s] TRAIN epoch 16 -- loss: tensor([0.1193], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:36,307 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:49:36,307 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:37,024 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:49:39,061 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 17 -- loss: tensor([0.1209], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:39,065 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 18:49:39,065 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:39,789 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:49:41,745 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 18 -- loss: tensor([0.1216], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:41,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-18 18:49:41,748 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:42,473 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:49:44,598 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 19 -- loss: tensor([0.1181], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:44,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:49:44,601 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:45,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:49:47,374 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 20 -- loss: tensor([0.1168], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:47,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:49:47,377 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:48,118 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:49:50,132 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 21 -- loss: tensor([0.1174], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:50,135 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:49:50,135 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:50,858 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:49:52,877 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 22 -- loss: tensor([0.1177], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:52,879 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:49:52,880 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:53,602 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:49:55,660 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 23 -- loss: tensor([0.1166], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:55,663 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:49:55,663 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:56,387 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:49:58,400 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 24 -- loss: tensor([0.1164], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:49:58,403 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:49:58,403 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:49:59,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:50:01,390 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 25 -- loss: tensor([0.1145], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:01,393 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:50:01,393 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:02,131 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:50:03,962 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 26 -- loss: tensor([0.1129], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:03,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:50:03,965 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:04,704 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:50:06,658 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 27 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:06,676 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:50:06,676 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:07,403 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:50:09,371 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 28 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:09,374 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:50:09,374 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:10,128 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:50:12,223 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 29 -- loss: tensor([0.1116], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:12,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:50:12,237 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:12,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:50:15,376 :: INFO :: evodenss.train.trainers :: [0] -- [2.41s] TRAIN epoch 30 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:15,379 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:50:15,379 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:16,103 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:50:18,065 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 31 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:18,068 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:50:18,068 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:18,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:50:20,813 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 32 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:20,816 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:50:20,816 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:21,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:50:23,622 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 33 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:23,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:50:23,626 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:24,345 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:50:26,394 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 34 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:26,397 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:50:26,397 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:27,123 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:50:29,182 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 35 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:29,186 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:50:29,186 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:29,914 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:50:31,873 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 36 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:31,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:50:31,876 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:32,598 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:50:34,696 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 37 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:34,699 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:50:34,699 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:35,425 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:50:37,409 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 38 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:37,412 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:50:37,412 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:38,137 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:50:40,290 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 39 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:40,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:50:40,294 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:41,033 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:50:42,923 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 40 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:42,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:50:42,926 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:43,653 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:50:45,672 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 41 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:45,675 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:50:45,675 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:46,415 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:50:48,482 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 42 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:48,485 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:50:48,485 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:49,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:50:51,361 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 43 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:51,364 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:50:51,364 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:52,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:50:54,536 :: INFO :: evodenss.train.trainers :: [0] -- [2.39s] TRAIN epoch 44 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:54,539 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:50:54,539 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:55,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:50:57,402 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 45 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:50:57,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:50:57,407 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:50:58,131 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:51:00,159 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 46 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:00,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:51:00,162 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:00,875 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:51:02,850 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 47 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:02,861 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:51:02,861 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:03,580 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:51:05,655 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 48 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:05,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:51:05,658 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:06,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:51:08,506 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 49 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:08,508 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:51:08,508 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:09,998 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 540803,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 141.02351474761963,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.17592,  losses: {'train_loss': [0.21, 0.139, 0.133, 0.129, 0.128, 0.127, 0.124, 0.122, 0.128, 0.124, 0.122, 0.121, 0.123, 0.119, 0.119, 0.119, 0.119, 0.121, 0.122, 0.118, 0.117, 0.117, 0.118, 0.117, 0.116, 0.115, 0.113, 0.113, 0.112, 0.112, 0.111, 0.111, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.108], 'val_loss': [0.147, 0.116, 0.108, 0.114, 0.107, 0.104, 0.103, 0.129, 0.103, 0.101, 0.104, 0.11, 0.103, 0.104, 0.103, 0.123, 0.107, 0.103, 0.109, 0.106, 0.106, 0.111, 0.104, 0.099, 0.101, 0.101, 0.101, 0.103, 0.105, 0.104, 0.101, 0.104, 0.1, 0.099, 0.1, 0.099, 0.1, 0.1, 0.101, 0.099, 0.1, 0.099, 0.098, 0.099, 0.098, 0.099, 0.099, 0.098, 0.098, 0.098]}),  max_epochs_reached: True

2024-11-18 18:51:10,001 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.17592
2024-11-18 18:51:10,004 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 18:51:10,008 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 2, id: 2
2024-11-18 18:51:10,011 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-18 18:51:10,014 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-18 18:51:10,021 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.14447, 0.19116, 0.14217, 0.17592]
2024-11-18 18:51:13,356 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.2006], device='cuda:0')
2024-11-18 18:51:13,359 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 2: 0.14217
2024-11-18 18:51:13,363 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.14217



2024-11-18 18:51:13,431 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 3
2024-11-18 18:51:13,435 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 18:51:13,448 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 18:51:13,458 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 18:51:13,462 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 18:51:13,466 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 18:51:13,470 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 18:51:13,474 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:51:13,480 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 18:51:13,483 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 18:51:13,488 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 18:51:13,492 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 18:51:13,497 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 18:51:13,503 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 18:51:13,506 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:51:13,529 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 18:51:13,534 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 18:51:13,538 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 18:51:13,542 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 18:51:13,547 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 18:51:13,550 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 18:51:13,555 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 18:51:13,560 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 18:51:13,567 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 18:51:13,570 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0008520037620936978 batch_size:34 epochs:50
2024-11-18 18:51:13,586 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:51:13,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:51:15,733 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 0 -- loss: tensor([0.1692], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:15,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.169
2024-11-18 18:51:15,736 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:16,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:51:18,370 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 1 -- loss: tensor([0.1203], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:18,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:51:18,381 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:19,064 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:51:20,983 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 2 -- loss: tensor([0.1171], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:20,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:51:20,986 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:21,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:51:23,694 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 3 -- loss: tensor([0.1167], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:23,697 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:51:23,697 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:24,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:51:26,230 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 4 -- loss: tensor([0.1192], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:26,233 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:51:26,233 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:26,898 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:51:28,996 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 5 -- loss: tensor([0.1173], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:28,999 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:51:28,999 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:29,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:51:31,467 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 6 -- loss: tensor([0.1192], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:31,470 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:51:31,470 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:32,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:51:34,331 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 7 -- loss: tensor([0.1166], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:34,342 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:51:34,342 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:35,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:51:36,918 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 8 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:36,921 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:51:36,921 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:37,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:51:39,703 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 9 -- loss: tensor([0.1159], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:39,706 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:51:39,706 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:40,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:51:42,492 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 10 -- loss: tensor([0.1152], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:42,495 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:51:42,495 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:43,167 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:51:45,299 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 11 -- loss: tensor([0.1164], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:45,302 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:51:45,303 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:45,996 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:51:48,144 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 12 -- loss: tensor([0.1142], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:48,147 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:51:48,147 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:48,857 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:51:50,994 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 13 -- loss: tensor([0.1152], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:50,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:51:50,997 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:51,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:51:53,719 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 14 -- loss: tensor([0.1144], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:53,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:51:53,722 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:54,401 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:51:56,524 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 15 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:56,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:51:56,527 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:57,206 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:51:59,275 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 16 -- loss: tensor([0.1115], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:51:59,279 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:51:59,279 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:51:59,970 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:52:01,873 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 17 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:01,877 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:52:01,877 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:02,573 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:52:04,833 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 18 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:04,835 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:52:04,836 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:05,505 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:52:07,585 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 19 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:07,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:52:07,588 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:08,277 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:52:10,278 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 20 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:10,281 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:52:10,281 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:10,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:52:12,903 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 21 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:12,906 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:52:12,906 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:13,595 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:52:15,860 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 22 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:15,863 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:52:15,863 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:16,548 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:52:18,657 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 23 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:18,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:18,660 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:19,348 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:52:21,194 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 24 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:21,200 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:21,200 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:21,882 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:52:23,945 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 25 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:23,948 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:23,948 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:24,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:52:26,772 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 26 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:26,774 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:26,774 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:27,476 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:52:29,483 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 27 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:29,486 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:29,486 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:30,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:52:32,356 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 28 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:32,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:32,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:33,041 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:52:34,905 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 29 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:34,908 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:34,908 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:35,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:52:37,777 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 30 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:37,780 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:37,780 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:38,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:52:40,535 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 31 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:40,538 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:52:40,538 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:41,248 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:52:43,483 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 32 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:43,485 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:52:43,485 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:44,158 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:52:46,347 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 33 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:46,350 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:46,350 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:47,022 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:52:48,790 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 34 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:48,793 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:48,793 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:49,472 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:52:51,571 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 35 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:51,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:52:51,574 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:52,243 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:52:54,448 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 36 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:54,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:52:54,452 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:55,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:52:57,472 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 37 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:52:57,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:52:57,475 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:52:58,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:53:00,179 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 38 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:00,182 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:00,182 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:00,866 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:53:02,934 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 39 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:02,937 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:02,937 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:03,633 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:53:05,829 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 40 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:05,831 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:05,831 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:06,508 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:53:08,629 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 41 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:08,632 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:08,632 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:09,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:53:11,196 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 42 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:11,199 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:11,199 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:11,892 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:53:13,915 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 43 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:13,918 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:13,918 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:14,613 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:53:16,695 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 44 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:16,700 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:53:16,700 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:17,378 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:53:19,356 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 45 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:19,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:19,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:20,057 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:53:22,103 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 46 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:22,112 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:22,112 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:22,800 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:53:25,010 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 47 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:25,013 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:25,013 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:25,690 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:53:27,805 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 48 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:27,808 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:27,808 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:28,529 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:53:30,262 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 49 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:30,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:53:30,264 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:31,651 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 445191,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 138.07855653762817,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.14792,  losses: {'train_loss': [0.169, 0.12, 0.117, 0.117, 0.119, 0.117, 0.119, 0.117, 0.116, 0.116, 0.115, 0.116, 0.114, 0.115, 0.114, 0.112, 0.111, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.107, 0.108, 0.108, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107], 'val_loss': [0.116, 0.112, 0.105, 0.108, 0.104, 0.105, 0.105, 0.103, 0.111, 0.113, 0.099, 0.108, 0.098, 0.09, 0.1, 0.1, 0.101, 0.094, 0.097, 0.106, 0.094, 0.102, 0.098, 0.094, 0.095, 0.099, 0.096, 0.096, 0.092, 0.091, 0.098, 0.091, 0.099, 0.102, 0.096, 0.091, 0.096, 0.093, 0.092, 0.089, 0.093, 0.099, 0.098, 0.109, 0.103, 0.094, 0.093, 0.093, 0.111, 0.098]}),  max_epochs_reached: True

2024-11-18 18:53:31,653 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.14792
2024-11-18 18:53:31,660 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 18:53:31,680 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:48 kernel_size:3 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 
layer7: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:9 
layer12: :fc act:selu out_features:200 bias:True input:10 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:6.715758022365842e-05 batch_size:34 epochs:50
2024-11-18 18:53:31,700 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:53:31,700 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:53:33,845 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 0 -- loss: tensor([0.1653], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:33,848 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.165
2024-11-18 18:53:33,848 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:34,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:53:36,585 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 1 -- loss: tensor([0.1238], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:36,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-18 18:53:36,588 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:37,277 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:53:39,356 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 2 -- loss: tensor([0.1202], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:39,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:53:39,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:40,047 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:53:42,001 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 3 -- loss: tensor([0.1180], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:42,004 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:53:42,004 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:42,692 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:53:44,927 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 4 -- loss: tensor([0.1170], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:44,930 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 18:53:44,930 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:45,637 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:53:47,812 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 5 -- loss: tensor([0.1153], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:47,815 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:53:47,815 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:48,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:53:50,428 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 6 -- loss: tensor([0.1135], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:50,431 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 18:53:50,431 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:51,114 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:53:53,403 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 7 -- loss: tensor([0.1122], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:53,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:53:53,405 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:54,067 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:53:56,097 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 8 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:56,100 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:53:56,100 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:56,764 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:53:58,816 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 9 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:53:58,819 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:53:58,819 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:53:59,508 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:54:01,506 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 10 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:01,509 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:54:01,509 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:02,206 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:54:04,433 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 11 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:04,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:54:04,437 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:05,130 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:54:07,380 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 12 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:07,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:54:07,383 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:08,051 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:54:10,087 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 13 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:10,090 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:54:10,090 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:10,717 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:54:12,739 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 14 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:12,757 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:54:12,757 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:13,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:54:15,604 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 15 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:15,623 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:15,623 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:16,271 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:54:18,341 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 16 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:18,344 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:18,344 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:19,028 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:54:21,127 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 17 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:21,130 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:21,130 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:21,821 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:54:24,060 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 18 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:24,063 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:24,063 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:24,771 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:54:26,923 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 19 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:26,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:26,926 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:27,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:54:29,856 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 20 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:29,859 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:29,859 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:30,596 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:54:32,639 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 21 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:32,642 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:32,642 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:33,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:54:35,352 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 22 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:35,354 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:54:35,354 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:36,028 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:54:38,080 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 23 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:38,082 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:38,082 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:38,777 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:54:40,924 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 24 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:40,927 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:40,927 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:41,593 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:54:43,624 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 25 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:43,636 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:43,636 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:44,333 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:54:46,379 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 26 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:46,382 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:46,382 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:47,062 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:54:49,081 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 27 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:49,089 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:49,089 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:49,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:54:51,831 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 28 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:51,834 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:51,834 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:52,511 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:54:54,499 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 29 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:54,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:54,502 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:55,173 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:54:57,403 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 30 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:54:57,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:54:57,406 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:54:58,090 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:55:00,306 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 31 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:00,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:55:00,309 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:00,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:55:02,984 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 32 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:02,987 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:02,987 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:03,668 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:55:05,885 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 33 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:05,888 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:05,888 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:06,559 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:55:08,720 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 34 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:08,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:08,723 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:09,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:55:11,545 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 35 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:11,548 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:11,548 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:12,227 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:55:14,316 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 36 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:14,319 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:14,319 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:14,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:55:17,061 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 37 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:17,064 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:17,064 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:17,756 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:55:19,800 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 38 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:19,803 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:19,803 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:20,476 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:55:22,477 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 39 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:22,480 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:22,480 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:23,158 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:55:25,387 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 40 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:25,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:25,390 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:26,072 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:55:27,937 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 41 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:27,940 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:27,940 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:28,635 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:55:30,742 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 42 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:30,749 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:30,749 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:31,434 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:55:33,551 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 43 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:33,554 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:55:33,554 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:34,238 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:55:36,216 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 44 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:36,219 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:36,220 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:36,896 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:55:39,176 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 45 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:39,179 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:39,179 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:39,868 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:55:41,959 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 46 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:41,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:55:41,962 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:42,661 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:55:44,254 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 47 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:44,257 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:55:44,257 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:44,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:55:46,914 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 48 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:46,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:55:46,917 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:47,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:55:49,829 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 49 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:49,832 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:55:49,832 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:51,254 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 363291,  n_layers: 12,  n_layers_projector: -1,  training_time_spent: 139.57206797599792,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.20701,  losses: {'train_loss': [0.165, 0.124, 0.12, 0.118, 0.117, 0.115, 0.114, 0.112, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106], 'val_loss': [0.157, 0.132, 0.122, 0.118, 0.113, 0.109, 0.108, 0.103, 0.1, 0.1, 0.098, 0.106, 0.101, 0.098, 0.101, 0.1, 0.1, 0.098, 0.1, 0.096, 0.1, 0.1, 0.1, 0.097, 0.099, 0.097, 0.1, 0.098, 0.097, 0.093, 0.094, 0.094, 0.095, 0.095, 0.098, 0.098, 0.096, 0.095, 0.095, 0.091, 0.091, 0.092, 0.092, 0.091, 0.092, 0.091, 0.093, 0.092, 0.092, 0.091]}),  max_epochs_reached: True

2024-11-18 18:55:51,257 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.20701
2024-11-18 18:55:51,263 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-18 18:55:51,267 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0005411818573570027 batch_size:34 epochs:50
2024-11-18 18:55:51,281 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:55:51,281 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:55:53,561 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 0 -- loss: tensor([0.1932], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:53,564 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.193
2024-11-18 18:55:53,564 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:54,254 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:55:56,243 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 1 -- loss: tensor([0.1132], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:56,246 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:55:56,246 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:56,936 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:55:58,990 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 2 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:55:58,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:55:58,993 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:55:59,666 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:56:01,775 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 3 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:01,778 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:56:01,778 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:02,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:56:04,719 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 4 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:04,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:56:04,722 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:05,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:56:07,322 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 5 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:07,324 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 18:56:07,325 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:07,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:56:10,150 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 6 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:10,153 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:56:10,153 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:10,833 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:56:12,765 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 7 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:12,768 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:56:12,768 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:13,428 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:56:15,616 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 8 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:15,618 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 18:56:15,619 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:16,290 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:56:18,261 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 9 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:18,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:18,264 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:18,985 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:56:21,199 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 10 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:21,202 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:21,202 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:21,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:56:23,789 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 11 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:23,792 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:23,792 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:24,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:56:26,696 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 12 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:26,699 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:26,699 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:27,373 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:56:29,595 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 13 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:29,598 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:29,598 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:30,285 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:56:32,452 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 14 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:32,455 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:32,455 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:33,156 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:56:35,107 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 15 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:35,117 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:35,117 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:35,786 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:56:37,868 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 16 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:37,878 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:37,878 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:38,563 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:56:40,749 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 17 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:40,752 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:40,752 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:41,415 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:56:43,390 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 18 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:43,393 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:43,394 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:44,083 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:56:46,206 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 19 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:46,209 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:46,209 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:46,932 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:56:49,043 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 20 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:49,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:49,046 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:49,733 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:56:51,985 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 21 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:51,988 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:51,988 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:52,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:56:54,726 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 22 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:54,732 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:54,732 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:55,416 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:56:57,547 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 23 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:56:57,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:56:57,550 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:56:58,238 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:57:00,249 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 24 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:00,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:00,252 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:00,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:57:03,073 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 25 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:03,079 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:03,079 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:03,761 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:57:05,690 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 26 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:05,693 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:05,693 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:06,369 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:57:08,475 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 27 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:08,478 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:08,478 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:09,163 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:57:11,289 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 28 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:11,292 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:11,292 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:11,972 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:57:14,081 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 29 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:14,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:14,084 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:14,774 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:57:16,967 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 30 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:16,971 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:16,971 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:17,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:57:19,672 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 31 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:19,705 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 18:57:19,705 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:20,392 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:57:22,629 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 32 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:22,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:22,631 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:23,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:57:25,397 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 33 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:25,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:25,399 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:26,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:57:28,105 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 34 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:28,108 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:28,108 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:28,802 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:57:30,901 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 35 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:30,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:30,904 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:31,592 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:57:33,638 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 36 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:33,641 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:33,641 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:34,342 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:57:36,229 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 37 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:36,232 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 18:57:36,232 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:36,905 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 18:57:39,100 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 38 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:39,102 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:39,103 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:39,811 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 18:57:42,048 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 39 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:42,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:42,052 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:42,744 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 18:57:44,648 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 40 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:44,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:44,651 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:45,332 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 18:57:47,508 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 41 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:47,511 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 18:57:47,511 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:48,195 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 18:57:50,440 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 42 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:50,445 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:50,445 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:51,109 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 18:57:53,203 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 43 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:53,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 18:57:53,211 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:53,872 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 18:57:55,727 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 44 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:55,730 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:55,730 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:56,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 18:57:58,539 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 45 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:57:58,542 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:57:58,542 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:57:59,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 18:58:01,350 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 46 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:01,353 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:58:01,353 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:02,006 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 18:58:03,998 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 47 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:04,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:58:04,000 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:04,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 18:58:06,777 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 48 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:06,780 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:58:06,780 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:07,446 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 18:58:09,529 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 49 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:09,531 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 18:58:09,531 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:10,926 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 338215,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 139.65747451782227,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.13052,  losses: {'train_loss': [0.193, 0.113, 0.11, 0.109, 0.108, 0.108, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.105, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.098, 0.088, 0.087, 0.086, 0.089, 0.093, 0.087, 0.086, 0.087, 0.086, 0.089, 0.09, 0.088, 0.087, 0.087, 0.087, 0.092, 0.086, 0.086, 0.09, 0.091, 0.086, 0.089, 0.086, 0.098, 0.086, 0.087, 0.086, 0.086, 0.086, 0.087, 0.087, 0.091, 0.086, 0.086, 0.092, 0.093, 0.088, 0.095, 0.088, 0.09, 0.091, 0.089, 0.086, 0.086, 0.086, 0.086, 0.086, 0.089, 0.086]}),  max_epochs_reached: True

2024-11-18 18:58:10,929 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.13052
2024-11-18 18:58:10,935 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-18 18:58:10,938 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:86 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:8 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0008520037620936978 batch_size:51 epochs:50
2024-11-18 18:58:10,951 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 18:58:10,951 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 18:58:13,213 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 0 -- loss: tensor([0.1827], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:13,216 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.183
2024-11-18 18:58:13,216 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:14,024 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 18:58:16,235 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 1 -- loss: tensor([0.1277], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:16,238 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.128
2024-11-18 18:58:16,238 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:17,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 18:58:19,131 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 2 -- loss: tensor([0.1251], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:19,134 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.125
2024-11-18 18:58:19,134 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:19,950 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 18:58:21,943 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 3 -- loss: tensor([0.1234], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:21,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.123
2024-11-18 18:58:21,946 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:22,702 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 18:58:24,737 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 4 -- loss: tensor([0.1230], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:24,740 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.123
2024-11-18 18:58:24,741 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:25,484 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 18:58:27,492 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 5 -- loss: tensor([0.1211], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:27,495 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 18:58:27,495 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:28,247 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 18:58:30,464 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 6 -- loss: tensor([0.1200], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:30,467 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:58:30,467 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:31,241 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 18:58:33,332 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 7 -- loss: tensor([0.1201], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:33,334 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 18:58:33,334 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:34,077 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 18:58:35,932 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 8 -- loss: tensor([0.1187], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:35,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 18:58:35,934 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:36,706 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 18:58:38,638 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 9 -- loss: tensor([0.1180], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:38,641 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:58:38,641 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:39,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 18:58:41,503 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 10 -- loss: tensor([0.1176], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:41,506 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 18:58:41,506 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:42,267 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 18:58:44,250 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 11 -- loss: tensor([0.1160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:44,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 18:58:44,253 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:45,119 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 18:58:47,373 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 12 -- loss: tensor([0.1153], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:47,376 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:58:47,376 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:48,254 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 18:58:50,363 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 13 -- loss: tensor([0.1146], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:50,376 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:58:50,376 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:51,143 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 18:58:53,015 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 14 -- loss: tensor([0.1145], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:53,018 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:58:53,018 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:53,846 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 18:58:56,095 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 15 -- loss: tensor([0.1146], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:56,098 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 18:58:56,098 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:56,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 18:58:59,057 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 16 -- loss: tensor([0.1134], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:58:59,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:58:59,060 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:58:59,833 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 18:59:01,996 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 17 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:01,999 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:59:01,999 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:02,690 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 18:59:04,785 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 18 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:04,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:59:04,788 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:05,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 18:59:07,677 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 19 -- loss: tensor([0.1126], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:07,680 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 18:59:07,680 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:08,471 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 18:59:10,588 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 20 -- loss: tensor([0.1121], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:10,591 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:59:10,591 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:11,389 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 18:59:13,644 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 21 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:13,654 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:59:13,654 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:14,403 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 18:59:16,751 :: INFO :: evodenss.train.trainers :: [0] -- [2.35s] TRAIN epoch 22 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:16,755 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:59:16,755 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:17,517 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 18:59:19,772 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 23 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:19,784 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 18:59:19,784 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:20,545 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 18:59:22,472 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 24 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:22,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:59:22,475 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:23,232 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 18:59:25,495 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 25 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:25,498 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:59:25,498 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:26,253 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 18:59:28,226 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 26 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:28,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 18:59:28,229 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:28,979 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 18:59:31,325 :: INFO :: evodenss.train.trainers :: [0] -- [2.34s] TRAIN epoch 27 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:31,328 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:59:31,328 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:32,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 18:59:33,982 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 28 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:33,985 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:59:33,985 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:34,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 18:59:36,798 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 29 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:36,800 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:59:36,801 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:37,540 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 18:59:39,804 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 30 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:39,806 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 18:59:39,806 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:40,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 18:59:42,633 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 31 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:42,636 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:42,636 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:43,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 18:59:45,402 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 32 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:45,404 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:45,404 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:46,165 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 18:59:48,087 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 33 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:48,090 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:48,090 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:48,911 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 18:59:51,097 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 34 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:51,100 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:51,100 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:51,841 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 18:59:53,918 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 35 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:53,923 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:53,923 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:54,669 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 18:59:56,799 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 36 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:56,802 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:56,802 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 18:59:57,543 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 18:59:59,803 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 37 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 18:59:59,806 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 18:59:59,806 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:00,572 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:00:02,777 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 38 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:02,779 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:02,780 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:03,522 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:00:05,682 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 39 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:05,691 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:05,691 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:06,451 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:00:08,360 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 40 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:08,363 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:08,363 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:09,125 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:00:11,363 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 41 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:11,366 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:11,366 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:12,114 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:00:14,334 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 42 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:14,337 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:14,337 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:15,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:00:17,192 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 43 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:17,195 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:00:17,195 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:17,949 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:00:20,165 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 44 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:20,168 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:20,168 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:20,911 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:00:22,806 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 45 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:22,809 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:22,809 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:23,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:00:25,698 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 46 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:25,701 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:00:25,701 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:26,478 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:00:28,653 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 47 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:28,656 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:00:28,656 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:29,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:00:31,433 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 48 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:31,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:00:31,436 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:32,224 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:00:34,467 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 49 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:34,470 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:00:34,470 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:36,116 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 367855,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 145.17571759223938,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.19627,  losses: {'train_loss': [0.183, 0.128, 0.125, 0.123, 0.123, 0.121, 0.12, 0.12, 0.119, 0.118, 0.118, 0.116, 0.115, 0.115, 0.115, 0.115, 0.113, 0.113, 0.112, 0.113, 0.112, 0.112, 0.112, 0.112, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108], 'val_loss': [0.128, 0.105, 0.104, 0.101, 0.11, 0.1, 0.098, 0.1, 0.098, 0.097, 0.101, 0.096, 0.098, 0.099, 0.098, 0.097, 0.095, 0.096, 0.1, 0.096, 0.096, 0.092, 0.096, 0.092, 0.097, 0.097, 0.096, 0.099, 0.095, 0.094, 0.096, 0.106, 0.094, 0.112, 0.099, 0.092, 0.103, 0.102, 0.096, 0.107, 0.111, 0.114, 0.102, 0.102, 0.105, 0.098, 0.095, 0.1, 0.1, 0.105]}),  max_epochs_reached: True

2024-11-18 19:00:36,119 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.19627
2024-11-18 19:00:36,122 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 19:00:36,125 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 2, id: 2
2024-11-18 19:00:36,128 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-18 19:00:36,131 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-18 19:00:36,136 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.14792, 0.20701, 0.13052, 0.19627]
2024-11-18 19:00:39,192 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1809], device='cuda:0')
2024-11-18 19:00:39,195 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 3: 0.13052
2024-11-18 19:00:39,197 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.13052



2024-11-18 19:00:39,270 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 4
2024-11-18 19:00:39,273 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 19:00:39,286 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:00:39,289 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:00:39,293 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:00:39,307 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 19:00:39,311 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:00:39,314 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 19:00:39,317 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:00:39,323 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:00:39,326 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:00:39,330 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:00:39,333 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 19:00:39,337 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 19:00:39,340 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 19:00:39,344 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:00:39,347 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 19:00:39,350 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:00:39,356 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:00:39,359 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:00:39,363 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 19:00:39,366 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 19:00:39,369 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 19:00:39,372 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:00:39,375 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:00:39,615 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 19:00:39,622 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 19:00:39,625 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0005411818573570027 batch_size:34 epochs:50
2024-11-18 19:00:39,639 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:00:39,639 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:00:41,733 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 0 -- loss: tensor([0.2102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:41,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.21
2024-11-18 19:00:41,736 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:42,414 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:00:44,528 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 1 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:44,531 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:00:44,531 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:45,243 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:00:47,294 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 2 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:47,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:00:47,297 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:47,989 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:00:49,950 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 3 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:49,953 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:00:49,953 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:50,649 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:00:52,884 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 4 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:52,887 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:00:52,887 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:53,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:00:55,790 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 5 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:55,795 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:00:55,795 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:56,485 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:00:58,727 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 6 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:00:58,731 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:00:58,731 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:00:59,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:01:01,425 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 7 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:01,428 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:01:01,428 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:02,141 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:01:04,209 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 8 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:04,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:01:04,213 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:04,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:01:07,000 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 9 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:07,003 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:07,003 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:07,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:01:09,829 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 10 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:09,833 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:09,834 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:10,530 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:01:12,618 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 11 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:12,621 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:12,621 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:13,315 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:01:15,450 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 12 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:15,453 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:15,453 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:16,201 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:01:18,369 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 13 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:18,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:18,372 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:19,069 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:01:20,980 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 14 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:20,984 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:20,984 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:21,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:01:23,738 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 15 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:23,741 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:23,742 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:24,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:01:26,494 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 16 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:26,497 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:26,497 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:27,204 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:01:29,379 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 17 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:29,382 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:29,382 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:30,077 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:01:32,200 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 18 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:32,203 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:32,203 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:32,968 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:01:34,847 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 19 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:34,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:34,850 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:35,540 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:01:37,788 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 20 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:37,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:37,791 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:38,492 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:01:40,626 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 21 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:40,630 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:40,630 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:41,338 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:01:43,439 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 22 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:43,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:43,442 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:44,130 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:01:46,291 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 23 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:46,294 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:46,294 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:47,007 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:01:48,922 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 24 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:48,929 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:48,929 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:49,593 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:01:51,842 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 25 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:51,844 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:51,844 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:52,518 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:01:54,171 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 26 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:54,174 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:54,174 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:54,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:01:56,936 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 27 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:56,939 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:56,939 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:01:57,614 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:01:59,843 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 28 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:01:59,846 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:01:59,846 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:00,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:02:02,684 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 29 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:02,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:02:02,687 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:03,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:02:05,578 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 30 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:05,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:05,581 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:06,257 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:02:08,381 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 31 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:08,384 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:08,384 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:09,068 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:02:11,145 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 32 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:11,148 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:02:11,148 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:11,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:02:13,893 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 33 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:13,896 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:13,896 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:14,582 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:02:16,695 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 34 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:16,698 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:16,698 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:17,384 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:02:19,507 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 35 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:19,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:19,513 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:20,248 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:02:22,498 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 36 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:22,501 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:22,501 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:23,194 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:02:25,190 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 37 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:25,193 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:02:25,193 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:25,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:02:27,951 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 38 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:27,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:27,963 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:28,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:02:30,685 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 39 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:30,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:30,688 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:31,380 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:02:33,520 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 40 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:33,523 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:33,523 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:34,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:02:35,977 :: INFO :: evodenss.train.trainers :: [0] -- [1.76s] TRAIN epoch 41 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:35,979 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:35,980 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:36,632 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:02:38,837 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 42 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:38,840 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:38,840 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:39,556 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:02:41,653 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 43 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:41,659 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:02:41,659 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:42,356 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:02:44,564 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 44 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:44,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:44,566 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:45,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:02:47,423 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 45 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:47,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:47,427 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:48,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:02:50,309 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 46 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:50,313 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:50,313 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:51,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:02:53,269 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 47 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:53,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:53,272 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:53,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:02:56,053 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 48 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:56,056 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:02:56,056 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:02:56,749 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:02:58,757 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 49 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:02:58,760 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:02:58,760 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:00,173 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 338215,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 140.5466763973236,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.14322,  losses: {'train_loss': [0.21, 0.112, 0.109, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105], 'val_loss': [0.098, 0.087, 0.087, 0.086, 0.087, 0.086, 0.086, 0.09, 0.086, 0.086, 0.086, 0.087, 0.088, 0.096, 0.086, 0.087, 0.088, 0.086, 0.086, 0.086, 0.091, 0.089, 0.086, 0.087, 0.093, 0.086, 0.086, 0.092, 0.086, 0.086, 0.097, 0.092, 0.09, 0.103, 0.089, 0.087, 0.086, 0.089, 0.086, 0.086, 0.086, 0.088, 0.086, 0.087, 0.087, 0.088, 0.091, 0.088, 0.087, 0.088]}),  max_epochs_reached: True

2024-11-18 19:03:00,176 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.14322
2024-11-18 19:03:00,183 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 19:03:00,186 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:89 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0005411818573570027 batch_size:34 epochs:50
2024-11-18 19:03:00,199 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:03:00,199 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:03:02,261 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 0 -- loss: tensor([0.1983], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:02,263 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.198
2024-11-18 19:03:02,264 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:02,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:03:04,979 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 1 -- loss: tensor([0.1135], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:04,982 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:03:04,982 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:05,672 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:03:07,774 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 2 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:07,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:03:07,776 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:08,450 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:03:10,549 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 3 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:10,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:03:10,552 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:11,219 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:03:13,289 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 4 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:13,292 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:03:13,292 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:13,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:03:16,100 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 5 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:16,103 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:03:16,103 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:16,785 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:03:18,758 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 6 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:18,761 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:03:18,761 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:19,432 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:03:21,487 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 7 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:21,490 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:03:21,490 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:22,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:03:24,101 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 8 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:24,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:03:24,104 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:24,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:03:26,554 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 9 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:26,557 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:03:26,558 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:27,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:03:29,268 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 10 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:29,271 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:29,271 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:29,975 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:03:32,158 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 11 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:32,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:32,161 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:32,821 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:03:34,941 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 12 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:34,944 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:34,944 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:35,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:03:37,730 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 13 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:37,733 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:37,733 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:38,411 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:03:40,506 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 14 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:40,510 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:40,510 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:41,200 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:03:43,202 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 15 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:43,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:43,205 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:43,936 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:03:46,046 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 16 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:46,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:46,053 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:46,726 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:03:48,799 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 17 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:48,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:48,801 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:49,489 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:03:51,622 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 18 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:51,625 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:51,625 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:52,314 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:03:54,343 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 19 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:54,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:54,346 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:55,010 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:03:57,205 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 20 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:57,209 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:57,209 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:03:57,885 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:03:59,940 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 21 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:03:59,943 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:03:59,943 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:00,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:04:02,686 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 22 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:02,689 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:02,689 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:03,342 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:04:05,373 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 23 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:05,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:05,377 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:06,075 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:04:08,237 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 24 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:08,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:08,240 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:08,920 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:04:10,994 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 25 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:10,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:10,997 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:11,668 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:04:13,801 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 26 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:13,803 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:13,804 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:14,470 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:04:16,514 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 27 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:16,517 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:16,517 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:17,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:04:19,086 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 28 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:19,088 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:19,088 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:19,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:04:21,813 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 29 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:21,816 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:21,817 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:22,521 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:04:24,409 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 30 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:24,412 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:24,413 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:25,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:04:26,947 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 31 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:26,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:26,964 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:27,640 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:04:29,872 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 32 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:29,875 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:29,875 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:30,557 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:04:32,634 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 33 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:32,637 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:32,638 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:33,308 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:04:35,193 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 34 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:35,196 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:35,196 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:35,857 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:04:37,924 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 35 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:37,927 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:04:37,927 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:38,617 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:04:40,893 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 36 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:40,896 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:40,896 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:41,543 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:04:43,439 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 37 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:43,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:43,442 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:44,116 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:04:46,103 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 38 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:46,105 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:46,106 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:46,774 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:04:48,662 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 39 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:48,666 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:48,666 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:49,338 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:04:51,414 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 40 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:51,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:51,417 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:52,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:04:54,200 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 41 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:54,203 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:04:54,203 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:54,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:04:56,784 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 42 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:56,787 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:56,787 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:04:57,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:04:59,369 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 43 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:04:59,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:04:59,372 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:00,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:05:02,147 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 44 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:02,151 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:05:02,151 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:02,880 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:05:04,945 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 45 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:04,948 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:05:04,948 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:05,618 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:05:07,640 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 46 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:07,643 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:05:07,643 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:08,324 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:05:10,441 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 47 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:10,444 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:05:10,444 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:11,139 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:05:13,318 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 48 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:13,321 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:05:13,321 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:13,980 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:05:16,051 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 49 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:16,054 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:05:16,054 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:17,488 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 277162,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 137.30040287971497,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.13017,  losses: {'train_loss': [0.198, 0.113, 0.11, 0.109, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.108, 0.09, 0.088, 0.089, 0.089, 0.086, 0.087, 0.087, 0.089, 0.088, 0.088, 0.088, 0.091, 0.087, 0.086, 0.086, 0.104, 0.086, 0.09, 0.101, 0.088, 0.095, 0.091, 0.087, 0.086, 0.113, 0.085, 0.086, 0.088, 0.087, 0.086, 0.085, 0.088, 0.086, 0.09, 0.085, 0.096, 0.089, 0.086, 0.088, 0.086, 0.175, 0.226, 0.091, 0.086, 0.106, 0.11, 0.086, 0.093, 0.087]}),  max_epochs_reached: True

2024-11-18 19:05:17,499 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.13017
2024-11-18 19:05:17,506 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-18 19:05:17,510 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:21 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:124 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0005411818573570027 batch_size:58 epochs:50
2024-11-18 19:05:17,524 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:05:17,524 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:05:19,675 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 0 -- loss: tensor([0.3692], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:19,678 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.369
2024-11-18 19:05:19,678 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:20,518 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:05:22,621 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 1 -- loss: tensor([0.1255], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:22,624 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.126
2024-11-18 19:05:22,624 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:23,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:05:25,466 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 2 -- loss: tensor([0.1158], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:25,470 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:05:25,470 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:26,277 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:05:28,679 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 3 -- loss: tensor([0.1137], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:28,682 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:05:28,682 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:29,453 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:05:31,621 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 4 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:31,624 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:05:31,624 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:32,411 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:05:34,436 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 5 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:34,439 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:05:34,439 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:35,209 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:05:37,171 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 6 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:37,174 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:05:37,174 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:37,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:05:39,869 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 7 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:39,872 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:05:39,872 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:40,674 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:05:42,651 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 8 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:42,654 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:05:42,654 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:43,451 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:05:45,738 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 9 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:45,743 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:05:45,743 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:46,538 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:05:48,492 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 10 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:48,495 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:05:48,495 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:49,306 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:05:51,317 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 11 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:51,320 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:05:51,320 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:52,246 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:05:54,652 :: INFO :: evodenss.train.trainers :: [0] -- [2.4s] TRAIN epoch 12 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:54,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:05:54,655 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:55,445 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:05:57,325 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 13 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:05:57,328 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:05:57,328 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:05:58,138 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:06:00,523 :: INFO :: evodenss.train.trainers :: [0] -- [2.38s] TRAIN epoch 14 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:00,526 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:00,526 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:01,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:06:03,335 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 15 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:03,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:03,347 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:04,155 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:06:06,604 :: INFO :: evodenss.train.trainers :: [0] -- [2.45s] TRAIN epoch 16 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:06,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:06,607 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:07,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:06:09,408 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 17 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:09,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:09,421 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:10,220 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:06:12,209 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 18 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:12,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:12,213 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:12,990 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:06:14,889 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 19 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:14,892 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:14,892 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:15,674 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:06:17,720 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 20 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:17,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:17,727 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:18,514 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:06:20,704 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 21 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:20,708 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:20,708 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:21,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:06:23,509 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 22 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:23,512 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:23,512 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:24,306 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:06:26,332 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 23 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:26,335 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:26,335 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:27,153 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:06:29,118 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 24 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:29,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:29,121 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:29,910 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:06:31,931 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 25 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:31,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:31,934 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:32,741 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:06:34,703 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 26 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:34,706 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:34,706 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:35,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:06:37,848 :: INFO :: evodenss.train.trainers :: [0] -- [2.35s] TRAIN epoch 27 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:37,855 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:37,855 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:38,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:06:40,605 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 28 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:40,608 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:40,608 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:41,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:06:43,698 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 29 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:43,702 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:43,702 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:44,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:06:46,499 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 30 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:46,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:46,502 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:47,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:06:49,286 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 31 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:49,289 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:49,289 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:50,071 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:06:52,502 :: INFO :: evodenss.train.trainers :: [0] -- [2.43s] TRAIN epoch 32 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:52,505 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:06:52,506 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:53,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:06:55,503 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 33 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:55,506 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:55,506 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:56,302 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:06:58,534 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 34 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:06:58,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:06:58,537 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:06:59,344 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:07:01,313 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 35 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:01,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:01,317 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:02,119 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:07:04,069 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 36 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:04,072 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:07:04,072 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:04,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:07:06,848 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 37 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:06,851 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:06,851 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:07,639 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:07:09,640 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 38 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:09,643 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:09,643 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:10,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:07:12,675 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 39 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:12,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:12,679 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:13,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:07:15,456 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 40 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:15,465 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:15,465 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:16,287 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:07:18,273 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 41 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:18,287 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:07:18,287 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:19,094 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:07:21,078 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 42 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:21,081 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:21,081 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:21,890 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:07:24,040 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 43 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:24,043 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:24,044 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:24,869 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:07:27,311 :: INFO :: evodenss.train.trainers :: [0] -- [2.44s] TRAIN epoch 44 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:27,314 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:27,314 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:28,095 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:07:30,384 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 45 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:30,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:30,388 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:31,175 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:07:33,140 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 46 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:33,143 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:33,143 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:33,943 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:07:36,273 :: INFO :: evodenss.train.trainers :: [0] -- [2.33s] TRAIN epoch 47 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:36,276 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:36,276 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:37,073 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:07:39,352 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 48 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:39,355 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:39,355 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:40,122 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:07:42,378 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 49 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:42,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:07:42,381 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:44,043 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 384523,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 146.53128671646118,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.16146,  losses: {'train_loss': [0.369, 0.126, 0.116, 0.114, 0.113, 0.112, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.108, 0.108, 0.108, 0.109, 0.108, 0.108, 0.109, 0.108, 0.108, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108], 'val_loss': [0.144, 0.098, 0.093, 0.09, 0.09, 0.09, 0.089, 0.09, 0.09, 0.09, 0.089, 0.091, 0.09, 0.09, 0.09, 0.089, 0.091, 0.09, 0.089, 0.089, 0.089, 0.091, 0.09, 0.091, 0.091, 0.089, 0.089, 0.091, 0.09, 0.091, 0.089, 0.09, 0.089, 0.09, 0.089, 0.089, 0.089, 0.09, 0.089, 0.09, 0.089, 0.091, 0.091, 0.089, 0.09, 0.089, 0.089, 0.089, 0.091, 0.09]}),  max_epochs_reached: True

2024-11-18 19:07:44,046 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.16146
2024-11-18 19:07:44,053 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-18 19:07:44,056 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:59 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.5972954778411659 weight_decay:0.0005411818573570027 batch_size:56 epochs:50
2024-11-18 19:07:44,070 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:07:44,070 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:07:46,364 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 0 -- loss: tensor([0.2219], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:46,366 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.222
2024-11-18 19:07:46,366 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:47,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:07:49,164 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 1 -- loss: tensor([0.1232], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:49,167 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.123
2024-11-18 19:07:49,167 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:49,944 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:07:52,318 :: INFO :: evodenss.train.trainers :: [0] -- [2.37s] TRAIN epoch 2 -- loss: tensor([0.1204], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:52,321 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-18 19:07:52,322 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:53,227 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:07:55,159 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 3 -- loss: tensor([0.1189], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:55,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 19:07:55,161 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:55,958 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:07:58,014 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 4 -- loss: tensor([0.1185], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:07:58,022 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:07:58,022 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:07:58,883 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:08:00,953 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 5 -- loss: tensor([0.1177], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:00,956 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:08:00,956 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:01,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:08:03,923 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 6 -- loss: tensor([0.1176], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:03,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:08:03,926 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:04,697 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:08:06,725 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 7 -- loss: tensor([0.1174], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:06,728 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:08:06,728 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:07,510 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:08:09,529 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 8 -- loss: tensor([0.1172], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:09,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:08:09,532 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:10,357 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:08:12,638 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 9 -- loss: tensor([0.1168], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:12,640 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:08:12,640 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:13,428 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:08:15,595 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 10 -- loss: tensor([0.1165], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:15,597 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:08:15,597 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:16,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:08:18,532 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 11 -- loss: tensor([0.1167], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:18,534 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:08:18,534 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:19,318 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:08:21,290 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 12 -- loss: tensor([0.1165], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:21,302 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:08:21,302 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:22,083 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:08:24,348 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 13 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:24,350 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:24,350 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:25,151 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:08:27,027 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 14 -- loss: tensor([0.1161], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:27,030 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:27,030 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:27,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:08:30,180 :: INFO :: evodenss.train.trainers :: [0] -- [2.37s] TRAIN epoch 15 -- loss: tensor([0.1160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:30,183 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:30,184 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:31,064 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:08:33,223 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 16 -- loss: tensor([0.1158], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:33,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:33,226 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:34,010 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:08:35,965 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 17 -- loss: tensor([0.1160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:35,985 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:35,986 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:36,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:08:39,084 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 18 -- loss: tensor([0.1159], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:39,087 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:39,087 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:39,892 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:08:42,093 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 19 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:42,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:42,096 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:42,870 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:08:45,215 :: INFO :: evodenss.train.trainers :: [0] -- [2.34s] TRAIN epoch 20 -- loss: tensor([0.1160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:45,218 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:45,218 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:45,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:08:48,246 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 21 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:48,249 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:48,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:49,039 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:08:51,120 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 22 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:51,123 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:51,123 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:51,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:08:53,979 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 23 -- loss: tensor([0.1160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:53,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:53,983 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:54,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:08:56,692 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 24 -- loss: tensor([0.1157], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:56,695 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:56,696 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:08:57,484 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:08:59,513 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 25 -- loss: tensor([0.1157], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:08:59,515 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:08:59,515 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:00,403 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:09:02,643 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 26 -- loss: tensor([0.1152], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:02,646 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:02,646 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:03,432 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:09:05,570 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 27 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:05,573 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:05,574 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:06,361 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:09:08,389 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 28 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:08,392 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:08,392 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:09,183 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:09:11,534 :: INFO :: evodenss.train.trainers :: [0] -- [2.35s] TRAIN epoch 29 -- loss: tensor([0.1158], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:11,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:09:11,537 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:12,311 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:09:14,389 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 30 -- loss: tensor([0.1156], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:14,392 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:09:14,392 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:15,181 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:09:17,151 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 31 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:17,154 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:17,154 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:17,932 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:09:20,132 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 32 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:20,136 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:20,136 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:20,905 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:09:23,143 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 33 -- loss: tensor([0.1152], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:23,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:23,146 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:23,912 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:09:25,951 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 34 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:25,954 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:25,954 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:26,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:09:28,987 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 35 -- loss: tensor([0.1152], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:28,990 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:28,990 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:29,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:09:31,785 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 36 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:31,787 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:31,787 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:32,559 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:09:34,798 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 37 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:34,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:34,802 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:35,597 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:09:37,836 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 38 -- loss: tensor([0.1150], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:37,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:37,839 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:38,613 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:09:40,998 :: INFO :: evodenss.train.trainers :: [0] -- [2.38s] TRAIN epoch 39 -- loss: tensor([0.1153], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:41,002 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:41,002 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:41,762 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:09:43,987 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 40 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:43,990 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:43,990 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:44,767 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:09:46,770 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 41 -- loss: tensor([0.1153], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:46,773 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:46,773 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:47,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:09:49,548 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 42 -- loss: tensor([0.1148], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:49,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:49,550 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:50,321 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:09:52,278 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 43 -- loss: tensor([0.1155], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:52,281 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:52,281 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:53,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:09:55,319 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 44 -- loss: tensor([0.1153], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:55,322 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:55,322 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:56,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:09:58,238 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 45 -- loss: tensor([0.1147], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:09:58,241 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:09:58,241 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:09:59,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:10:01,433 :: INFO :: evodenss.train.trainers :: [0] -- [2.38s] TRAIN epoch 46 -- loss: tensor([0.1149], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:01,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:10:01,436 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:02,220 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:10:04,336 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 47 -- loss: tensor([0.1149], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:04,339 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:10:04,339 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:05,102 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:10:07,257 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 48 -- loss: tensor([0.1146], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:07,260 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:10:07,260 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:08,125 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:10:10,258 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 49 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:10,262 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:10:10,262 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:11,844 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 363566,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 147.78535532951355,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.17193,  losses: {'train_loss': [0.222, 0.123, 0.12, 0.119, 0.118, 0.118, 0.118, 0.117, 0.117, 0.117, 0.117, 0.117, 0.117, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.116, 0.115, 0.115, 0.115, 0.116, 0.116, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115, 0.115], 'val_loss': [0.148, 0.104, 0.094, 0.099, 0.092, 0.107, 0.092, 0.09, 0.092, 0.118, 0.115, 0.099, 0.089, 0.093, 0.093, 0.094, 0.104, 0.105, 0.089, 0.114, 0.09, 0.094, 0.092, 0.09, 0.105, 0.094, 0.096, 0.094, 0.12, 0.095, 0.117, 0.106, 0.123, 0.103, 0.092, 0.13, 0.099, 0.101, 0.105, 0.118, 0.1, 0.091, 0.091, 0.126, 0.093, 0.091, 0.091, 0.107, 0.091, 0.097]}),  max_epochs_reached: True

2024-11-18 19:10:11,846 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.17193
2024-11-18 19:10:11,849 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 19:10:11,852 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 1, id: 1
2024-11-18 19:10:11,854 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-18 19:10:11,857 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-18 19:10:11,863 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.14322, 0.13017, 0.16146, 0.17193]
2024-11-18 19:10:14,925 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1792], device='cuda:0')
2024-11-18 19:10:14,928 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 4: 0.13017
2024-11-18 19:10:14,931 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.13017



2024-11-18 19:10:15,007 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 5
2024-11-18 19:10:15,010 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 19:10:15,024 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:10:15,028 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 19:10:15,031 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 19:10:15,034 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 19:10:15,038 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 19:10:15,042 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 19:10:15,046 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-18 19:10:15,050 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 19:10:15,053 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-18 19:10:15,056 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:10:15,062 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:10:15,065 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 19:10:15,068 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 19:10:15,071 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 19:10:15,075 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:10:15,078 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:10:15,084 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:10:15,088 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:10:15,091 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 19:10:15,095 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 19:10:15,098 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:10:15,104 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 19:10:15,110 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 19:10:15,114 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:89 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0005411818573570027 batch_size:34 epochs:50
2024-11-18 19:10:15,129 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:10:15,129 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:10:17,222 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 0 -- loss: tensor([0.2042], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:17,235 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.204
2024-11-18 19:10:17,235 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:17,900 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:10:19,965 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 1 -- loss: tensor([0.1127], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:19,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:10:19,993 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:20,676 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:10:22,776 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 2 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:22,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:10:22,791 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:23,456 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:10:25,549 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 3 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:25,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:10:25,552 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:26,209 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:10:28,244 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 4 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:28,247 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:10:28,247 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:28,930 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:10:31,040 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 5 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:31,049 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:10:31,049 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:31,742 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:10:33,847 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 6 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:33,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:10:33,850 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:34,512 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:10:36,611 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 7 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:36,613 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:36,613 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:37,303 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:10:39,159 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 8 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:39,163 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:39,163 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:39,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:10:41,716 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 9 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:41,721 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:41,721 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:42,393 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:10:44,530 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 10 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:44,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:44,532 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:45,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:10:47,408 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 11 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:47,411 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:47,411 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:48,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:10:50,087 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 12 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:50,091 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:50,091 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:50,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:10:52,861 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 13 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:52,864 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:52,864 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:53,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:10:55,636 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 14 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:55,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:55,638 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:56,326 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:10:58,270 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 15 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:10:58,273 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:10:58,273 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:10:58,959 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:11:01,118 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 16 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:01,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:01,121 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:01,803 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:11:03,862 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 17 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:03,865 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:03,865 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:04,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:11:06,416 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 18 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:06,419 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:06,419 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:07,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:11:09,201 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 19 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:09,204 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:09,204 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:09,883 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:11:11,988 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 20 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:11,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:11,991 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:12,669 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:11:14,548 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 21 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:14,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:14,566 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:15,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:11:17,234 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 22 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:17,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:17,237 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:17,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:11:19,913 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 23 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:19,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:19,919 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:20,595 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:11:22,834 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 24 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:22,837 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:22,837 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:23,519 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:11:25,361 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 25 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:25,364 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:25,364 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:26,051 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:11:28,142 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 26 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:28,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:28,145 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:28,824 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:11:30,718 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 27 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:30,721 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:30,721 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:31,455 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:11:33,355 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 28 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:33,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:33,358 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:34,030 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:11:36,152 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 29 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:36,155 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:11:36,155 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:36,842 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:11:38,860 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 30 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:38,863 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:38,863 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:39,543 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:11:41,422 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 31 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:41,425 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:41,425 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:42,114 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:11:44,349 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 32 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:44,352 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:44,352 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:45,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:11:47,073 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 33 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:47,075 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:47,075 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:47,754 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:11:49,666 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 34 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:49,669 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:49,669 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:50,368 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:11:52,292 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 35 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:52,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:52,295 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:52,980 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:11:54,916 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 36 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:54,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:54,919 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:55,571 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:11:57,677 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 37 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:11:57,688 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:11:57,688 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:11:58,353 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:12:00,277 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 38 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:00,280 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:00,280 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:00,953 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:12:02,980 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 39 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:02,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:02,983 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:03,656 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:12:05,746 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 40 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:05,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:12:05,749 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:06,444 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:12:08,266 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 41 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:08,269 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:12:08,269 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:08,971 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:12:11,043 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 42 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:11,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:11,046 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:11,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:12:13,726 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 43 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:13,729 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:12:13,729 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:14,426 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:12:16,638 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 44 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:16,641 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:16,641 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:17,319 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:12:19,194 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 45 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:19,197 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:19,197 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:19,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:12:21,969 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 46 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:21,972 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:12:21,972 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:22,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:12:24,438 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 47 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:24,441 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:24,441 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:25,102 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:12:26,970 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 48 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:26,973 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:26,973 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:27,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:12:29,893 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 49 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:29,896 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:29,896 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:31,288 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 277162,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 136.17321968078613,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.13976,  losses: {'train_loss': [0.204, 0.113, 0.11, 0.108, 0.108, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106], 'val_loss': [0.106, 0.089, 0.089, 0.089, 0.088, 0.088, 0.093, 0.09, 0.09, 0.105, 0.086, 0.088, 0.091, 0.087, 0.1, 0.086, 0.086, 0.087, 0.09, 0.097, 0.087, 0.086, 0.086, 0.088, 0.092, 0.086, 0.086, 0.086, 0.088, 0.091, 0.087, 0.088, 0.089, 0.088, 0.088, 0.086, 0.087, 0.087, 0.086, 0.088, 0.088, 0.088, 0.091, 0.088, 0.086, 0.098, 0.087, 0.086, 0.086, 0.091]}),  max_epochs_reached: True

2024-11-18 19:12:31,291 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.13976
2024-11-18 19:12:31,299 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 19:12:31,303 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-18 19:12:31,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:12:31,318 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:12:33,501 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 0 -- loss: tensor([0.2774], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:33,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.277
2024-11-18 19:12:33,504 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:34,223 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:12:36,214 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 1 -- loss: tensor([0.1142], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:36,216 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:12:36,216 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:36,915 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:12:39,031 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 2 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:39,034 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:12:39,034 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:39,692 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:12:41,906 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 3 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:41,909 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:12:41,909 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:42,594 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:12:45,416 :: INFO :: evodenss.train.trainers :: [0] -- [2.82s] TRAIN epoch 4 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:45,419 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:12:45,419 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:46,160 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:12:48,287 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 5 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:48,290 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:12:48,290 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:48,948 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:12:51,022 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 6 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:51,025 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:12:51,025 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:51,699 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:12:53,582 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 7 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:53,585 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:12:53,585 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:54,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:12:56,247 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 8 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:56,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:12:56,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:56,925 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:12:58,952 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 9 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:12:58,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:12:58,955 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:12:59,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:13:01,597 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 10 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:01,606 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:01,606 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:02,304 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:13:04,096 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 11 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:04,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:04,100 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:04,780 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:13:06,774 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 12 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:06,804 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:06,804 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:07,487 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:13:09,410 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 13 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:09,413 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:09,413 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:10,087 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:13:12,166 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 14 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:12,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:12,169 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:12,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:13:15,119 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 15 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:15,122 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:15,122 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:15,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:13:17,735 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 16 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:17,738 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:17,739 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:18,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:13:20,511 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 17 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:20,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:20,513 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:21,181 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:13:23,292 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 18 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:23,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:23,295 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:23,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:13:26,008 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 19 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:26,011 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:26,011 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:26,708 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:13:28,663 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 20 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:28,665 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:28,665 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:29,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:13:31,370 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 21 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:31,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:31,383 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:32,079 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:13:34,071 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 22 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:34,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:34,093 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:34,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:13:36,810 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 23 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:36,813 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:36,813 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:37,498 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:13:39,693 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 24 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:39,696 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:39,696 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:40,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:13:42,290 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 25 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:42,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:42,293 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:42,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:13:44,947 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 26 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:44,949 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:44,949 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:45,639 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:13:47,883 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 27 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:47,885 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:13:47,885 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:48,564 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:13:50,639 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 28 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:50,642 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:50,642 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:51,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:13:53,406 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 29 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:53,409 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:53,409 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:54,081 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:13:56,075 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 30 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:56,078 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:56,078 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:56,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:13:58,933 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 31 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:13:58,936 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:13:58,936 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:13:59,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:14:01,566 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 32 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:01,572 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:14:01,572 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:02,248 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:14:04,541 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 33 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:04,544 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:04,544 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:05,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:14:07,460 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 34 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:07,463 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:07,464 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:08,144 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:14:10,302 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 35 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:10,310 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:10,310 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:10,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:14:13,120 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 36 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:13,123 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:14:13,123 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:13,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:14:15,840 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 37 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:15,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:15,843 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:16,534 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:14:18,422 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 38 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:18,425 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:18,425 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:19,110 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:14:21,024 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 39 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:21,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:21,027 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:21,701 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:14:23,910 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 40 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:23,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:23,913 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:24,577 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:14:26,623 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 41 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:26,625 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:14:26,626 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:27,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:14:29,293 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 42 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:29,296 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:29,296 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:29,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:14:32,101 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 43 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:32,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:32,104 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:32,779 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:14:34,803 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 44 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:34,806 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:34,806 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:35,484 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:14:37,530 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 45 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:37,533 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:37,533 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:38,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:14:40,309 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 46 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:40,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:40,312 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:40,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:14:43,007 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 47 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:43,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:43,012 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:43,692 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:14:45,849 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 48 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:45,852 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:45,852 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:46,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:14:48,404 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 49 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:48,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:14:48,407 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:49,846 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 282792,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 138.54087471961975,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.12807,  losses: {'train_loss': [0.277, 0.114, 0.11, 0.109, 0.108, 0.107, 0.107, 0.107, 0.106, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.101, 0.089, 0.086, 0.089, 0.088, 0.085, 0.085, 0.096, 0.086, 0.086, 0.087, 0.085, 0.089, 0.085, 0.091, 0.087, 0.085, 0.087, 0.087, 0.086, 0.086, 0.085, 0.088, 0.085, 0.085, 0.085, 0.085, 0.085, 0.086, 0.085, 0.088, 0.087, 0.085, 0.087, 0.087, 0.085, 0.087, 0.086, 0.085, 0.085, 0.085, 0.085, 0.086, 0.092, 0.092, 0.086, 0.086, 0.086, 0.085, 0.088]}),  max_epochs_reached: True

2024-11-18 19:14:49,851 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.12807
2024-11-18 19:14:49,858 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-18 19:14:49,862 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 
layer8: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:gradient_descent lr:0.0006449537531992261 momentum:0.8966410057730154 weight_decay:0.0005411818573570027 nesterov:False batch_size:34 epochs:50
2024-11-18 19:14:49,875 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:14:49,875 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:14:52,040 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 0 -- loss: tensor([0.5541], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:52,043 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.554
2024-11-18 19:14:52,043 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:52,735 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:14:54,579 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 1 -- loss: tensor([0.2287], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:54,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.229
2024-11-18 19:14:54,581 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:55,280 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:14:57,374 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 2 -- loss: tensor([0.1571], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:57,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.157
2024-11-18 19:14:57,377 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:14:58,051 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:14:59,941 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 3 -- loss: tensor([0.1341], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:14:59,944 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.134
2024-11-18 19:14:59,944 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:00,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:15:02,623 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 4 -- loss: tensor([0.1267], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:02,630 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.127
2024-11-18 19:15:02,630 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:03,335 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:15:05,584 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 5 -- loss: tensor([0.1229], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:05,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.123
2024-11-18 19:15:05,587 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:06,337 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:15:08,226 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 6 -- loss: tensor([0.1208], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:08,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 19:15:08,229 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:08,923 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:15:10,795 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 7 -- loss: tensor([0.1194], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:10,798 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-18 19:15:10,798 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:11,471 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:15:13,708 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 8 -- loss: tensor([0.1183], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:13,711 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:15:13,711 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:14,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:15:16,384 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 9 -- loss: tensor([0.1176], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:16,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:15:16,388 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:17,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:15:19,213 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 10 -- loss: tensor([0.1169], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:19,215 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:15:19,215 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:19,912 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:15:21,876 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 11 -- loss: tensor([0.1162], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:21,879 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:15:21,879 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:22,564 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:15:24,647 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 12 -- loss: tensor([0.1159], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:24,650 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:15:24,650 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:25,348 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:15:27,528 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 13 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:27,531 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:15:27,531 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:28,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:15:30,188 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 14 -- loss: tensor([0.1150], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:30,190 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:15:30,191 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:30,918 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:15:32,681 :: INFO :: evodenss.train.trainers :: [0] -- [1.76s] TRAIN epoch 15 -- loss: tensor([0.1144], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:32,684 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:15:32,684 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:33,373 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:15:35,489 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 16 -- loss: tensor([0.1137], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:35,492 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:15:35,492 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:36,182 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:15:38,366 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 17 -- loss: tensor([0.1137], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:38,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:15:38,372 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:39,083 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:15:41,344 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 18 -- loss: tensor([0.1134], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:41,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:15:41,347 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:42,039 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:15:44,149 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 19 -- loss: tensor([0.1132], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:44,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:15:44,152 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:44,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:15:46,922 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 20 -- loss: tensor([0.1129], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:46,925 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:15:46,925 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:47,616 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:15:49,737 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 21 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:49,740 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:15:49,740 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:50,426 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:15:52,417 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 22 -- loss: tensor([0.1126], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:52,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:15:52,420 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:53,106 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:15:55,042 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 23 -- loss: tensor([0.1124], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:55,045 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:15:55,046 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:55,762 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:15:57,865 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 24 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:15:57,868 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:15:57,868 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:15:58,563 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:16:00,559 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 25 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:00,562 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:16:00,562 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:01,276 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:16:03,376 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 26 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:03,379 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:16:03,379 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:04,137 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:16:06,280 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 27 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:06,282 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:16:06,282 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:06,976 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:16:09,007 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 28 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:09,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:16:09,012 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:09,717 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:16:11,554 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 29 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:11,557 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:11,557 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:12,242 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:16:14,216 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 30 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:14,219 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:14,219 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:14,966 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:16:17,024 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 31 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:17,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:17,027 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:17,714 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:16:19,962 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 32 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:19,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:19,965 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:20,650 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:16:22,898 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 33 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:22,900 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:22,900 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:23,593 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:16:25,669 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 34 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:25,672 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:25,672 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:26,365 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:16:28,373 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 35 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:28,376 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:16:28,376 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:29,055 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:16:31,159 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 36 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:31,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:31,162 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:31,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:16:33,920 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 37 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:33,924 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:33,924 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:34,606 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:16:36,690 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 38 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:36,693 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:36,693 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:37,369 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:16:39,260 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 39 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:39,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:39,272 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:39,967 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:16:41,757 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 40 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:41,760 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:41,760 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:42,461 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:16:44,579 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 41 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:44,582 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:44,582 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:45,290 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:16:47,500 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 42 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:47,503 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:47,503 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:48,196 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:16:50,191 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 43 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:50,194 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:50,194 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:50,887 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:16:52,854 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 44 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:52,857 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:52,857 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:53,528 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:16:55,578 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 45 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:55,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:55,581 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:56,269 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:16:58,259 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 46 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:16:58,261 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:16:58,261 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:16:58,939 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:17:00,862 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 47 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:00,869 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:17:00,869 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:01,555 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:17:03,548 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 48 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:03,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:17:03,551 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:04,221 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:17:06,466 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 49 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:06,469 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:06,469 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:07,907 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 281520,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 138.0438780784607,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 1.71033,  losses: {'train_loss': [0.554, 0.229, 0.157, 0.134, 0.127, 0.123, 0.121, 0.119, 0.118, 0.118, 0.117, 0.116, 0.116, 0.115, 0.115, 0.114, 0.114, 0.114, 0.113, 0.113, 0.113, 0.113, 0.113, 0.112, 0.112, 0.112, 0.112, 0.112, 0.112, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.109], 'val_loss': [0.228, 0.123, 0.108, 0.107, 0.108, 0.107, 0.107, 0.104, 0.105, 0.103, 0.102, 0.101, 0.101, 0.101, 0.1, 0.099, 0.099, 0.099, 0.099, 0.098, 0.098, 0.098, 0.097, 0.097, 0.096, 0.096, 0.096, 0.096, 0.096, 0.096, 0.095, 0.096, 0.095, 0.096, 0.095, 0.095, 0.095, 0.094, 0.094, 0.094, 0.094, 0.094, 0.094, 0.094, 0.093, 0.094, 0.094, 0.093, 0.094, 0.094]}),  max_epochs_reached: True

2024-11-18 19:17:07,910 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 1.71033
2024-11-18 19:17:07,917 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-18 19:17:07,920 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:75 kernel_size:4 stride:2 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.041687395500716665 alpha:0.8357924228993512 weight_decay:0.0005411818573570027 batch_size:34 epochs:50
2024-11-18 19:17:07,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:17:07,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:17:10,070 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 0 -- loss: tensor([0.2706], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:10,073 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.271
2024-11-18 19:17:10,073 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:10,778 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:17:12,759 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 1 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:12,762 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:17:12,763 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:13,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:17:15,328 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 2 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:15,331 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:17:15,331 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:16,003 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:17:17,997 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 3 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:18,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:18,000 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:18,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:17:20,790 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 4 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:20,793 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:20,793 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:21,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:17:23,286 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 5 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:23,289 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:23,289 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:23,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:17:26,171 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 6 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:26,174 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:17:26,174 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:26,844 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:17:28,995 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 7 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:28,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:28,998 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:29,681 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:17:31,898 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 8 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:31,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:17:31,901 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:32,580 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:17:34,661 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 9 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:34,664 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:34,664 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:35,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:17:37,256 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 10 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:37,270 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:17:37,270 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:37,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:17:40,038 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 11 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:40,041 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:40,041 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:40,728 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:17:42,938 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 12 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:42,941 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:42,941 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:43,614 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:17:45,589 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 13 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:45,592 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:45,592 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:46,271 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:17:48,271 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 14 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:48,274 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:17:48,274 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:48,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:17:50,885 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 15 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:50,888 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:50,888 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:51,582 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:17:53,578 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 16 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:53,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:53,581 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:54,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:17:56,500 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 17 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:56,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:17:56,504 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:57,204 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:17:59,169 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 18 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:17:59,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:17:59,172 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:17:59,911 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:18:01,870 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 19 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:01,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:01,873 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:02,554 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:18:04,573 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 20 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:04,576 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:04,576 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:05,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:18:07,358 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 21 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:07,362 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:07,362 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:08,058 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:18:10,117 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 22 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:10,120 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:10,120 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:10,862 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:18:12,948 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 23 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:12,956 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:12,956 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:13,630 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:18:15,697 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 24 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:15,700 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:15,700 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:16,371 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:18:18,420 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 25 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:18,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:18,424 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:19,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:18:21,213 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 26 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:21,245 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:21,245 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:21,928 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:18:24,167 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 27 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:24,170 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:24,170 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:24,859 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:18:26,887 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 28 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:26,890 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:26,890 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:27,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:18:29,626 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 29 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:29,629 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:29,629 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:30,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:18:32,288 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 30 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:32,311 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:32,311 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:33,004 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:18:35,221 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 31 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:35,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:35,226 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:35,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:18:38,243 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 32 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:38,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:38,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:38,936 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:18:41,146 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 33 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:41,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:18:41,149 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:41,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:18:43,926 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 34 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:43,929 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:43,929 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:44,621 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:18:46,819 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 35 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:46,824 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:46,824 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:47,505 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:18:49,558 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 36 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:49,560 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:49,560 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:50,236 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:18:52,416 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 37 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:52,419 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:18:52,419 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:53,095 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:18:55,210 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 38 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:55,213 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:55,213 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:55,886 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:18:58,146 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 39 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:18:58,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:18:58,149 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:18:58,818 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:19:00,896 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 40 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:00,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:19:00,907 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:01,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:19:03,615 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 41 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:03,617 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:19:03,617 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:04,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:19:06,340 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 42 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:06,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:19:06,346 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:07,011 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:19:09,032 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 43 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:09,035 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:19:09,035 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:09,714 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:19:12,015 :: INFO :: evodenss.train.trainers :: [0] -- [2.3s] TRAIN epoch 44 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:12,019 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:19:12,019 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:12,708 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:19:14,915 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 45 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:14,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:19:14,919 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:15,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:19:17,547 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 46 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:17,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:19:17,550 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:18,214 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:19:20,301 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 47 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:20,304 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:19:20,304 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:20,971 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:19:22,935 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 48 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:22,938 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:19:22,939 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:23,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:19:25,886 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 49 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:25,890 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:19:25,890 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:27,313 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 275685,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 139.39086270332336,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 2.93603,  losses: {'train_loss': [0.271, 0.111, 0.108, 0.109, 0.109, 0.109, 0.11, 0.109, 0.108, 0.109, 0.11, 0.109, 0.109, 0.109, 0.11, 0.109, 0.109, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.11, 0.109, 0.11, 0.11, 0.109, 0.11, 0.109, 0.109, 0.11, 0.112, 0.11, 0.11, 0.109, 0.11, 0.109, 0.109, 0.109, 0.109, 0.11, 0.11, 0.108, 0.109, 0.11, 0.109, 0.109, 0.108], 'val_loss': [0.134, 53.859, 4.315, 0.092, 0.093, 0.09, 0.095, 330726.0, 0.089, 0.1, 0.088, 0.267, 0.089, 11812.016, 0.094, 0.087, 0.089, 0.086, 0.562, 0.437, 0.087, 0.089, 0.101, 98.593, 0.087, 0.427, 0.117, 0.093, 0.117, 0.088, 7.619, 0.087, 0.103, 0.113, 35.115, 1530.989, 0.094, 0.122, 5.57, 0.088, 0.113, 0.415, 0.101, 0.123, 1.536, 19.82, 0.347, 0.098, 0.089, 1.481]}),  max_epochs_reached: True

2024-11-18 19:19:27,317 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 2.93603
2024-11-18 19:19:27,320 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 19:19:27,322 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 1, id: 1
2024-11-18 19:19:27,325 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-18 19:19:27,328 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-18 19:19:27,335 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.13976, 0.12807, 1.71033, 2.93603]
2024-11-18 19:19:30,385 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1741], device='cuda:0')
2024-11-18 19:19:30,388 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 5: 0.12807
2024-11-18 19:19:30,391 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.12807



2024-11-18 19:19:30,475 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 6
2024-11-18 19:19:30,478 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 19:19:30,493 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:19:30,497 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:19:30,501 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:19:30,505 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 19:19:30,509 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 19:19:30,512 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-18 19:19:30,517 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:19:30,520 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 19:19:30,525 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:19:30,530 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:19:30,534 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:19:30,538 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 19:19:30,542 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 19:19:30,545 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 19:19:30,549 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:19:30,551 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:19:30,556 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:19:30,559 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:19:30,562 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 19:19:30,566 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 19:19:30,568 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-18 19:19:30,572 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:19:30,579 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 19:19:30,586 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 19:19:30,589 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-18 19:19:30,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:19:30,604 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:19:32,700 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 0 -- loss: tensor([0.2702], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:32,703 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.27
2024-11-18 19:19:32,703 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:33,367 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:19:35,627 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 1 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:35,630 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:19:35,631 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:36,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:19:38,420 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 2 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:38,423 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:19:38,423 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:39,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:19:41,331 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 3 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:41,336 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:19:41,336 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:42,035 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:19:44,145 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 4 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:44,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:19:44,152 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:44,822 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:19:46,930 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 5 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:46,933 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:19:46,933 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:47,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:19:49,633 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 6 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:49,635 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:19:49,636 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:50,329 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:19:52,454 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 7 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:52,457 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:19:52,457 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:53,137 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:19:55,226 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 8 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:55,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:19:55,229 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:55,931 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:19:57,957 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 9 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:19:57,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:19:57,965 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:19:58,646 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:20:00,857 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 10 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:00,860 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:00,860 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:01,548 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:20:03,749 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 11 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:03,752 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:03,752 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:04,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:20:06,614 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 12 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:06,617 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:06,617 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:07,287 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:20:09,249 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 13 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:09,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:09,252 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:09,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:20:11,991 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 14 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:12,006 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:12,006 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:12,666 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:20:14,826 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 15 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:14,829 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:14,829 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:15,514 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:20:17,551 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 16 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:17,554 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:17,554 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:18,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:20:20,440 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 17 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:20,443 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:20:20,443 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:21,114 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:20:23,103 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 18 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:23,106 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:23,106 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:23,785 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:20:25,802 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 19 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:25,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:25,805 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:26,474 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:20:28,458 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 20 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:28,461 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:28,462 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:29,142 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:20:31,356 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 21 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:31,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:31,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:32,032 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:20:34,093 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 22 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:34,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:34,096 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:34,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:20:36,995 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 23 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:36,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:36,998 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:37,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:20:39,756 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 24 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:39,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:39,759 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:40,422 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:20:42,464 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 25 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:42,467 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:42,467 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:43,151 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:20:45,215 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 26 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:45,218 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:45,218 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:45,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:20:47,999 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 27 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:48,002 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:48,002 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:48,672 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:20:50,740 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 28 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:50,743 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:50,743 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:51,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:20:53,555 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 29 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:53,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:53,558 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:54,249 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:20:56,226 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 30 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:56,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:56,229 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:56,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:20:59,224 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 31 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:20:59,227 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:20:59,227 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:20:59,891 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:21:01,947 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 32 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:01,950 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:01,951 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:02,636 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:21:04,841 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 33 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:04,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:04,843 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:05,511 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:21:07,146 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 34 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:07,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:21:07,149 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:07,855 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:21:09,758 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 35 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:09,760 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:09,760 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:10,439 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:21:12,589 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 36 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:12,592 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:12,592 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:13,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:21:15,384 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 37 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:15,387 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:21:15,387 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:16,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:21:18,090 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 38 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:18,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:18,102 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:18,789 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:21:20,903 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 39 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:20,906 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:21:20,906 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:21,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:21:23,695 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 40 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:23,698 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:23,698 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:24,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:21:26,553 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 41 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:26,555 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:26,555 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:27,263 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:21:29,040 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 42 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:29,042 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:21:29,042 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:29,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:21:31,811 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 43 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:31,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:31,814 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:32,493 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:21:34,392 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 44 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:34,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:21:34,395 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:35,073 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:21:37,237 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 45 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:37,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:37,240 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:37,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:21:39,996 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 46 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:39,999 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:21:39,999 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:40,671 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:21:42,602 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 47 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:42,604 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:42,604 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:43,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:21:45,385 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 48 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:45,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:45,388 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:46,082 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:21:47,979 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 49 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:47,982 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:21:47,982 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:49,396 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 282792,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 138.80465292930603,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.126,  losses: {'train_loss': [0.27, 0.112, 0.109, 0.108, 0.107, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.108, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.107, 0.106, 0.105, 0.106, 0.106, 0.106], 'val_loss': [0.098, 0.087, 0.086, 0.086, 0.085, 0.085, 0.085, 0.085, 0.085, 0.093, 0.088, 0.084, 0.093, 0.093, 0.086, 0.09, 0.085, 0.087, 0.136, 0.09, 0.085, 0.085, 0.094, 0.086, 0.089, 0.093, 0.085, 0.117, 0.085, 0.094, 0.086, 0.086, 0.087, 0.086, 0.085, 0.085, 0.086, 0.086, 0.098, 0.087, 0.086, 0.085, 0.086, 0.085, 0.085, 0.089, 0.087, 0.085, 0.085, 0.086]}),  max_epochs_reached: True

2024-11-18 19:21:49,398 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.126
2024-11-18 19:21:49,409 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 19:21:49,414 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:109 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 
layer8: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :deconv1d out_channels:47 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:46 epochs:50
2024-11-18 19:21:49,429 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:21:49,430 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:21:52,063 :: INFO :: evodenss.train.trainers :: [0] -- [2.63s] TRAIN epoch 0 -- loss: tensor([0.1666], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:52,066 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.167
2024-11-18 19:21:52,066 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:52,825 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:21:54,978 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 1 -- loss: tensor([0.1216], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:54,981 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-18 19:21:54,981 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:55,711 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:21:57,712 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 2 -- loss: tensor([0.1180], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:21:57,715 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:21:57,715 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:21:58,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:22:00,927 :: INFO :: evodenss.train.trainers :: [0] -- [2.49s] TRAIN epoch 3 -- loss: tensor([0.1182], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:00,930 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-18 19:22:00,931 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:01,692 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:22:03,649 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 4 -- loss: tensor([0.1164], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:03,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-18 19:22:03,651 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:04,412 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:22:06,321 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 5 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:06,324 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:22:06,324 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:07,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:22:09,086 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 6 -- loss: tensor([0.1171], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:09,088 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:22:09,088 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:09,810 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:22:11,772 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 7 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:11,774 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-18 19:22:11,774 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:12,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:22:14,512 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 8 -- loss: tensor([0.1140], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:14,515 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:22:14,515 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:15,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:22:17,217 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 9 -- loss: tensor([0.1214], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:17,220 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.121
2024-11-18 19:22:17,220 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:18,040 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:22:19,992 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 10 -- loss: tensor([0.1135], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:19,995 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:22:19,996 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:20,784 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:22:23,206 :: INFO :: evodenss.train.trainers :: [0] -- [2.42s] TRAIN epoch 11 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:23,208 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:22:23,208 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:23,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:22:26,138 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 12 -- loss: tensor([0.1126], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:26,141 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:22:26,141 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:26,890 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:22:28,846 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 13 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:28,848 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:22:28,848 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:29,580 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:22:31,618 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 14 -- loss: tensor([0.1126], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:31,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:22:31,638 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:32,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:22:34,496 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 15 -- loss: tensor([0.1171], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:34,498 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-18 19:22:34,498 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:35,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:22:37,264 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 16 -- loss: tensor([0.1137], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:37,270 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:22:37,270 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:37,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:22:40,076 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 17 -- loss: tensor([0.1116], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:40,079 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:22:40,079 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:40,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:22:43,049 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 18 -- loss: tensor([0.1108], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:43,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:22:43,052 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:43,782 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:22:45,954 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 19 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:45,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:22:45,957 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:46,688 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:22:48,840 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 20 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:48,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:22:48,844 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:49,579 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:22:51,500 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 21 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:51,503 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:22:51,503 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:52,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:22:54,072 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 22 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:54,074 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:22:54,075 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:54,810 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:22:57,088 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 23 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:57,091 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:22:57,091 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:22:57,822 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:22:59,975 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 24 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:22:59,979 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:22:59,979 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:00,713 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:23:02,741 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 25 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:02,744 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:02,744 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:03,479 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:23:05,430 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 26 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:05,433 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:05,433 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:06,261 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:23:08,324 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 27 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:08,327 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:08,327 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:09,067 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:23:11,189 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 28 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:11,192 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:11,192 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:11,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:23:14,218 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 29 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:14,221 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:14,221 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:14,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:23:17,028 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 30 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:17,031 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:17,031 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:17,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:23:20,021 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 31 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:20,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:20,027 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:20,802 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:23:22,924 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 32 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:22,930 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:22,930 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:23,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:23:25,629 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 33 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:25,632 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:25,632 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:26,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:23:28,477 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 34 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:28,479 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:28,479 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:29,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:23:31,298 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 35 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:31,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:31,301 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:32,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:23:33,957 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 36 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:33,960 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:33,960 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:34,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:23:36,792 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 37 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:36,794 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:23:36,794 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:37,523 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:23:39,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 38 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:39,704 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:39,704 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:40,433 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:23:42,764 :: INFO :: evodenss.train.trainers :: [0] -- [2.33s] TRAIN epoch 39 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:42,767 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:42,767 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:43,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:23:45,499 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 40 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:45,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:45,502 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:46,236 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:23:48,344 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 41 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:48,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:48,347 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:49,069 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:23:51,018 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 42 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:51,020 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:51,021 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:51,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:23:53,750 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 43 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:53,754 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:53,754 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:54,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:23:56,543 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 44 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:56,546 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:56,546 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:23:57,298 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:23:59,316 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 45 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:23:59,319 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:23:59,319 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:00,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:24:02,162 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 46 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:02,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:24:02,170 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:02,958 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:24:05,780 :: INFO :: evodenss.train.trainers :: [0] -- [2.82s] TRAIN epoch 47 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:05,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:24:05,783 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:06,520 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:24:08,565 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 48 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:08,567 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:24:08,567 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:09,308 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:24:11,221 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 49 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:11,224 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:24:11,224 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:12,789 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 414217,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 143.37340426445007,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.17778,  losses: {'train_loss': [0.167, 0.122, 0.118, 0.118, 0.116, 0.115, 0.117, 0.115, 0.114, 0.121, 0.113, 0.113, 0.113, 0.113, 0.113, 0.117, 0.114, 0.112, 0.111, 0.111, 0.109, 0.108, 0.108, 0.108, 0.107, 0.108, 0.108, 0.107, 0.108, 0.108, 0.107, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.108, 0.107], 'val_loss': [0.13, 0.107, 0.109, 0.107, 0.106, 0.11, 0.107, 0.104, 0.108, 0.11, 0.105, 0.104, 0.113, 0.105, 0.106, 0.108, 0.105, 0.109, 0.103, 0.102, 0.103, 0.103, 0.113, 0.102, 0.102, 0.104, 0.102, 0.098, 0.106, 0.112, 0.103, 0.099, 0.103, 0.112, 0.109, 0.099, 0.099, 0.121, 0.13, 0.105, 0.107, 0.108, 0.104, 0.102, 0.11, 0.102, 0.116, 0.104, 0.101, 0.105]}),  max_epochs_reached: True

2024-11-18 19:24:12,793 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.17778
2024-11-18 19:24:12,800 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-18 19:24:12,803 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:12 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0004943668927052497 batch_size:34 epochs:50
2024-11-18 19:24:12,817 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:24:12,818 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:24:14,646 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 0 -- loss: tensor([0.2700], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:14,650 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.27
2024-11-18 19:24:14,650 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:15,370 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:24:17,257 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 1 -- loss: tensor([0.1144], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:17,260 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:24:17,260 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:17,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:24:19,912 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 2 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:19,914 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:24:19,915 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:20,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:24:22,904 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 3 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:22,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:24:22,907 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:23,583 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:24:25,788 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 4 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:25,800 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:24:25,800 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:26,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:24:28,773 :: INFO :: evodenss.train.trainers :: [0] -- [2.28s] TRAIN epoch 5 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:28,775 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:24:28,775 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:29,435 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:24:31,590 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 6 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:31,593 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:24:31,593 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:32,268 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:24:34,393 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 7 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:34,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:24:34,396 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:35,136 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:24:37,242 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 8 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:37,245 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:37,245 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:37,900 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:24:40,029 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 9 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:40,032 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:40,032 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:40,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:24:42,669 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 10 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:42,672 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:42,672 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:43,352 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:24:45,145 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 11 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:45,148 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:45,148 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:45,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:24:47,879 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 12 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:47,882 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:47,882 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:48,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:24:50,605 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 13 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:50,608 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:50,608 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:51,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:24:53,421 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 14 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:53,423 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:53,423 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:54,110 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:24:56,166 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 15 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:56,170 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:56,170 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:56,841 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:24:59,152 :: INFO :: evodenss.train.trainers :: [0] -- [2.31s] TRAIN epoch 16 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:24:59,156 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:24:59,156 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:24:59,835 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:25:01,925 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 17 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:01,928 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:01,928 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:02,606 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:25:04,620 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 18 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:04,623 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:04,623 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:05,313 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:25:07,296 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 19 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:07,298 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:07,299 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:08,040 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:25:09,868 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 20 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:09,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:09,871 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:10,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:25:12,819 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 21 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:12,822 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:12,822 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:13,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:25:15,787 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 22 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:15,790 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:15,790 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:16,471 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:25:18,561 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 23 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:18,563 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:18,563 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:19,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:25:21,215 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 24 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:21,218 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:21,218 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:21,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:25:23,887 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 25 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:23,889 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:23,890 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:24,560 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:25:26,598 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 26 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:26,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:26,601 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:27,285 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:25:29,293 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 27 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:29,296 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:29,296 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:30,002 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:25:32,074 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 28 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:32,076 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:32,076 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:32,758 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:25:34,780 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 29 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:34,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:34,783 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:35,461 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:25:37,714 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 30 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:37,720 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:37,720 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:38,421 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:25:40,529 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 31 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:40,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:40,532 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:41,213 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:25:43,153 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 32 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:43,156 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:43,156 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:43,868 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:25:45,859 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 33 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:45,862 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:45,862 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:46,530 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:25:48,604 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 34 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:48,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:48,607 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:49,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:25:51,283 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 35 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:51,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:51,286 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:51,969 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:25:53,981 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 36 -- loss: tensor([0.1051], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:53,984 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:25:53,984 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:54,665 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:25:56,883 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 37 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:56,886 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:56,886 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:25:57,570 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:25:59,645 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 38 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:25:59,648 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:25:59,648 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:00,345 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:26:02,307 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 39 -- loss: tensor([0.1049], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:02,310 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:02,310 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:03,003 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:26:05,081 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 40 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:05,086 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:26:05,086 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:05,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:26:07,893 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 41 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:07,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:26:07,897 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:08,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:26:10,617 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 42 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:10,629 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:10,629 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:11,305 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:26:13,408 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 43 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:13,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:13,442 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:14,136 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:26:16,247 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 44 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:16,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:26:16,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:16,937 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:26:18,963 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 45 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:18,966 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:18,966 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:19,680 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:26:21,609 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 46 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:21,613 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:21,613 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:22,307 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:26:24,429 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 47 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:24,432 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:24,432 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:25,100 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:26:27,356 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 48 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:27,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:27,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:28,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:26:30,004 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 49 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:30,007 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:26:30,007 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:31,427 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 273839,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 138.62159371376038,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.13201,  losses: {'train_loss': [0.27, 0.114, 0.11, 0.108, 0.108, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.105, 0.105, 0.106, 0.105, 0.105, 0.106, 0.106, 0.106, 0.105, 0.105, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.105, 0.106, 0.105, 0.105, 0.105, 0.105, 0.105], 'val_loss': [0.099, 0.089, 0.086, 0.086, 0.085, 0.085, 0.085, 0.086, 0.093, 0.09, 0.085, 0.09, 0.088, 0.086, 0.085, 0.091, 0.085, 0.093, 0.085, 0.085, 0.089, 0.09, 0.085, 0.085, 0.085, 0.085, 0.089, 0.09, 0.085, 0.089, 0.091, 0.085, 0.091, 0.086, 0.085, 0.091, 0.085, 0.085, 0.088, 0.086, 0.086, 0.089, 0.085, 0.085, 0.085, 0.085, 0.088, 0.097, 0.085, 0.087]}),  max_epochs_reached: True

2024-11-18 19:26:31,430 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.13201
2024-11-18 19:26:31,437 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-18 19:26:31,440 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0006449537531992261 alpha:0.84286947922835 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-18 19:26:31,453 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:26:31,453 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:26:33,523 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 0 -- loss: tensor([0.1666], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:33,526 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.167
2024-11-18 19:26:33,526 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:34,215 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:26:36,378 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 1 -- loss: tensor([0.1139], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:36,384 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:26:36,384 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:37,071 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:26:39,155 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 2 -- loss: tensor([0.1115], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:39,158 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:26:39,158 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:39,832 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:26:41,907 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 3 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:41,910 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:26:41,910 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:42,579 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:26:44,823 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 4 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:44,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-18 19:26:44,826 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:45,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:26:47,669 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 5 -- loss: tensor([0.1131], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:47,672 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-18 19:26:47,672 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:48,361 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:26:50,572 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 6 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:50,575 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:26:50,575 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:51,243 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:26:53,407 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 7 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:53,410 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:26:53,410 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:54,087 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:26:56,332 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 8 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:56,334 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:26:56,334 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:57,015 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:26:58,750 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 9 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:26:58,753 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:26:58,753 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:26:59,434 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:27:01,539 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 10 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:01,542 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:01,542 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:02,249 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:27:04,272 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 11 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:04,274 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:04,274 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:04,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:27:07,070 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 12 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:07,073 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:07,073 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:07,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:27:09,660 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 13 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:09,663 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:09,663 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:10,327 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:27:12,184 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 14 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:12,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:12,187 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:12,862 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:27:15,007 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 15 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:15,010 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:15,010 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:15,699 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:27:17,900 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 16 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:17,911 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:17,912 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:18,611 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:27:20,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 17 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:20,704 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:20,704 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:21,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:27:23,318 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 18 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:23,321 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:23,321 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:24,029 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:27:26,023 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 19 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:26,034 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:26,034 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:26,742 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:27:28,862 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 20 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:28,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:28,873 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:29,531 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:27:31,731 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 21 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:31,734 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:27:31,734 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:32,413 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:27:34,501 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 22 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:34,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:34,504 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:35,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:27:37,414 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 23 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:37,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:37,417 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:38,097 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:27:40,108 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 24 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:40,117 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:40,118 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:40,861 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:27:43,102 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 25 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:43,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:43,104 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:43,795 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:27:45,682 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 26 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:45,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:45,685 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:46,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:27:48,447 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 27 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:48,450 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:48,450 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:49,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:27:51,202 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 28 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:51,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:51,205 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:51,881 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:27:53,951 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 29 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:53,954 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:53,954 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:54,632 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:27:56,700 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 30 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:56,703 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:56,703 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:27:57,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:27:59,387 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 31 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:27:59,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:27:59,390 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:00,061 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:28:02,057 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 32 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:02,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:02,060 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:02,739 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:28:04,975 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 33 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:04,977 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:04,977 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:05,667 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:28:07,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 34 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:07,709 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:07,709 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:08,385 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:28:10,351 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 35 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:10,354 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:10,354 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:11,029 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:28:13,039 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 36 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:13,042 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:13,042 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:13,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:28:15,815 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 37 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:15,817 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:15,817 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:16,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:28:18,720 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 38 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:18,726 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:18,726 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:19,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:28:21,318 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 39 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:21,320 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:21,320 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:22,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:28:24,098 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 40 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:24,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:24,102 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:24,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:28:27,017 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 41 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:27,020 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:28:27,020 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:27,693 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:28:29,729 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 42 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:29,732 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:28:29,732 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:30,421 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:28:32,548 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 43 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:32,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:32,551 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:33,221 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:28:35,428 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 44 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:35,432 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:35,432 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:36,112 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:28:38,203 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 45 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:38,206 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:38,206 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:38,893 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:28:40,952 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 46 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:40,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:40,955 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:41,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:28:43,726 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 47 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:43,729 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:43,729 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:44,418 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:28:46,523 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 48 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:46,526 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:46,527 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:47,208 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:28:49,404 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 49 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:49,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:28:49,407 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:50,813 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 281520,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 139.37099933624268,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.17539,  losses: {'train_loss': [0.167, 0.114, 0.112, 0.111, 0.112, 0.113, 0.109, 0.11, 0.108, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.115, 0.093, 0.094, 0.095, 0.092, 0.092, 0.092, 0.092, 0.092, 0.09, 0.094, 0.091, 0.091, 0.091, 0.089, 0.09, 0.09, 0.089, 0.089, 0.097, 0.09, 0.089, 0.086, 0.088, 0.086, 0.088, 0.086, 0.095, 0.092, 0.091, 0.094, 0.093, 0.091, 0.092, 0.099, 0.116, 0.094, 0.093, 0.119, 0.101, 0.115, 0.124, 0.11, 0.105, 0.115, 0.156, 0.117, 0.137, 0.15, 0.097]}),  max_epochs_reached: True

2024-11-18 19:28:50,816 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.17539
2024-11-18 19:28:50,819 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-18 19:28:50,822 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 0, id: 0
2024-11-18 19:28:50,824 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-18 19:28:50,828 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-18 19:28:50,834 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.126, 0.17778, 0.13201, 0.17539]
2024-11-18 19:28:53,852 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1716], device='cuda:0')
2024-11-18 19:28:53,855 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 6: 0.126
2024-11-18 19:28:53,858 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.126



2024-11-18 19:28:53,933 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 7
2024-11-18 19:28:53,936 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-18 19:28:53,951 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:28:53,956 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-18 19:28:53,967 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 19:28:53,971 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 19:28:53,975 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-18 19:28:53,978 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:28:53,985 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-18 19:28:53,988 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: True
2024-11-18 19:28:53,992 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-18 19:28:53,995 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:28:53,999 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 19:28:54,002 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-18 19:28:54,005 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:28:54,012 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-18 19:28:54,015 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-18 19:28:54,018 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-18 19:28:54,022 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-18 19:28:54,025 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-18 19:28:54,029 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-18 19:28:54,032 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-18 19:28:54,038 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-18 19:28:54,044 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-18 19:28:54,047 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-18 19:28:54,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:28:54,061 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:28:56,322 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 0 -- loss: tensor([0.2556], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:56,332 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.256
2024-11-18 19:28:56,332 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:57,017 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:28:58,920 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 1 -- loss: tensor([0.1136], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:28:58,928 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-18 19:28:58,928 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:28:59,620 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:29:01,657 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 2 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:01,659 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-18 19:29:01,660 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:02,349 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:29:04,444 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 3 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:04,447 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:29:04,447 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:05,067 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:29:07,085 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 4 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:07,088 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:29:07,088 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:07,760 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:29:09,960 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 5 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:09,963 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-18 19:29:09,963 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:10,664 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:29:12,680 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 6 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:12,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:29:12,683 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:13,367 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:29:15,459 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 7 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:15,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:29:15,462 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:16,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:29:18,322 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 8 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:18,332 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:18,332 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:19,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:29:21,041 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 9 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:21,044 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:21,044 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:21,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:29:23,795 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 10 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:23,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:29:23,797 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:24,491 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:29:26,524 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 11 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:26,526 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:26,526 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:27,216 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:29:29,302 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 12 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:29,305 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:29,306 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:30,044 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:29:32,269 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 13 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:32,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:32,272 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:32,937 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:29:35,083 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 14 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:35,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:35,085 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:35,764 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:29:37,870 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 15 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:37,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:37,876 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:38,568 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:29:40,545 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 16 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:40,548 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:40,548 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:41,233 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:29:43,464 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 17 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:43,467 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:43,467 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:44,164 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:29:46,267 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 18 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:46,271 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:29:46,271 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:46,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:29:49,016 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 19 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:49,019 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:49,019 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:49,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:29:51,738 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 20 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:51,740 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:29:51,740 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:52,449 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:29:54,451 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 21 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:54,454 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:29:54,454 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:55,192 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:29:57,405 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 22 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:29:57,408 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:29:57,408 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:29:58,088 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-18 19:30:00,165 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 23 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:00,168 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:00,168 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:00,856 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-18 19:30:02,943 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 24 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:02,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:02,946 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:03,628 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-18 19:30:05,863 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 25 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:05,866 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:05,866 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:06,560 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-18 19:30:08,826 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 26 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:08,829 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:08,829 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:09,503 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-18 19:30:11,493 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 27 -- loss: tensor([0.1051], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:11,496 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:11,496 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:12,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-18 19:30:14,149 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 28 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:14,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:14,152 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:14,833 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-18 19:30:17,045 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 29 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:17,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:17,060 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:17,738 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-18 19:30:19,988 :: INFO :: evodenss.train.trainers :: [0] -- [2.25s] TRAIN epoch 30 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:19,992 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:19,992 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:20,665 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-18 19:30:22,733 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 31 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:22,736 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:22,736 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:23,438 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-18 19:30:25,636 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 32 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:25,640 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:25,640 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:26,322 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-18 19:30:28,404 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 33 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:28,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:28,408 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:29,141 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-18 19:30:31,202 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 34 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:31,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:31,205 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:31,890 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-18 19:30:33,909 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 35 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:33,911 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:33,911 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:34,595 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-18 19:30:36,619 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 36 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:36,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:36,622 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:37,306 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-18 19:30:39,516 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 37 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:39,519 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:39,519 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:40,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-18 19:30:42,188 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 38 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:42,191 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:42,191 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:42,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-18 19:30:45,050 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 39 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:45,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:45,053 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:45,750 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-18 19:30:47,869 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 40 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:47,872 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:47,872 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:48,563 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-18 19:30:50,648 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 41 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:50,650 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:50,651 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:51,318 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-18 19:30:53,352 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 42 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:53,355 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:53,355 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:54,041 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-18 19:30:56,315 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 43 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:56,318 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:30:56,318 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:56,987 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-18 19:30:59,108 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 44 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:30:59,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:30:59,111 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:30:59,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-18 19:31:01,996 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 45 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:01,999 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:31:01,999 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:02,691 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-18 19:31:04,893 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 46 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:04,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:31:04,897 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:05,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-18 19:31:07,693 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 47 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:07,696 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:31:07,696 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:08,392 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-18 19:31:10,400 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 48 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:10,403 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-18 19:31:10,403 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:11,083 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-18 19:31:13,113 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 49 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:13,116 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:13,116 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:14,569 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 282792,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 140.51928091049194,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.13569,  losses: {'train_loss': [0.256, 0.114, 0.11, 0.109, 0.108, 0.108, 0.107, 0.107, 0.106, 0.106, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.105, 0.105, 0.106, 0.106, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.106, 0.105, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.105, 0.105, 0.105, 0.106], 'val_loss': [0.1, 0.087, 0.086, 0.087, 0.09, 0.086, 0.086, 0.086, 0.088, 0.096, 0.09, 0.086, 0.088, 0.085, 0.085, 0.087, 0.085, 0.086, 0.085, 0.087, 0.086, 0.085, 0.087, 0.095, 0.085, 0.085, 0.088, 0.091, 0.089, 0.088, 0.091, 0.091, 0.095, 0.089, 0.1, 0.086, 0.087, 0.085, 0.087, 0.085, 0.086, 0.086, 0.12, 0.098, 0.092, 0.089, 0.09, 0.085, 0.099, 0.095]}),  max_epochs_reached: True

2024-11-18 19:31:14,573 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.13569
2024-11-18 19:31:14,581 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-18 19:31:14,586 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:124 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 
layer7: :conv1d out_channels:47 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0008393550496114862 batch_size:34 epochs:50
2024-11-18 19:31:14,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-18 19:31:14,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-18 19:31:16,763 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 0 -- loss: tensor([0.4160], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:16,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.416
2024-11-18 19:31:16,766 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:17,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-18 19:31:19,363 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 1 -- loss: tensor([0.1338], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:19,368 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.134
2024-11-18 19:31:19,368 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:20,070 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-18 19:31:22,221 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 2 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:22,225 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-18 19:31:22,225 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:22,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-18 19:31:24,895 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 3 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:24,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-18 19:31:24,901 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:25,583 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-18 19:31:27,904 :: INFO :: evodenss.train.trainers :: [0] -- [2.32s] TRAIN epoch 4 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:27,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:31:27,907 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:28,586 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-18 19:31:30,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 5 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:30,707 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:31:30,707 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:31,372 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-18 19:31:33,612 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 6 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:33,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:31:33,631 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:34,328 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-18 19:31:36,262 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 7 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:36,267 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:36,267 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:36,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-18 19:31:39,186 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 8 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:39,189 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:31:39,189 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:39,858 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-18 19:31:41,945 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 9 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:41,950 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:41,950 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:42,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-18 19:31:44,652 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 10 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:44,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:31:44,655 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:45,349 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-18 19:31:47,475 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 11 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:47,480 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:47,480 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:48,176 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-18 19:31:50,277 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 12 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:50,281 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-18 19:31:50,281 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:50,984 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-18 19:31:53,156 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 13 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:53,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:53,161 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:53,915 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-18 19:31:56,136 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 14 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:56,143 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:56,143 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:56,830 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-18 19:31:58,912 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 15 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:31:58,916 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:31:58,916 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:31:59,608 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-18 19:32:01,564 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 16 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:01,568 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:01,568 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:32:02,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-18 19:32:04,384 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 17 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:04,391 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:04,391 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:32:05,103 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-18 19:32:07,142 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 18 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:07,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:07,146 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:32:07,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-18 19:32:09,792 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 19 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:09,798 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:09,798 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:32:10,478 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-18 19:32:12,716 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 20 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:12,721 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:12,721 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:32:13,400 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-18 19:32:15,479 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 21 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:15,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:15,483 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-18 19:32:16,170 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-18 19:32:18,354 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 22 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-18 19:32:18,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-18 19:32:18,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:30,385 :: INFO :: __main__ :: [0] -- Loading previous checkpoint
2024-11-19 15:23:31,090 :: INFO :: __main__ :: [0] -- Dataset partition sizes:
2024-11-19 15:23:31,093 :: INFO :: __main__ :: [0] -- DatasetType.EVO_TEST size -- 379
2024-11-19 15:23:31,096 :: INFO :: __main__ :: [0] -- DatasetType.VALIDATION size -- 379
2024-11-19 15:23:31,099 :: INFO :: __main__ :: [0] -- DatasetType.DOWNSTREAM_TRAIN size -- 3028
2024-11-19 15:23:31,102 :: INFO :: __main__ :: [0] -- DatasetType.TEST size -- 498
2024-11-19 15:23:31,104 :: INFO :: __main__ :: [0] -- Starting evolution for run 0
2024-11-19 15:23:31,107 :: INFO :: __main__ :: [0] -- Using 2 GPUs
2024-11-19 15:23:31,110 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 7
2024-11-19 15:23:31,112 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-19 15:23:31,128 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:23:31,132 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 15:23:31,135 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:23:31,139 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:23:31,142 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 15:23:31,145 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:23:31,152 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 15:23:31,156 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: True
2024-11-19 15:23:31,159 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:23:31,163 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 15:23:31,167 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-19 15:23:31,170 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 15:23:31,174 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:23:31,180 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:23:31,184 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-19 15:23:31,187 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:23:31,191 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 15:23:31,194 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-19 15:23:31,198 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 15:23:31,201 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:23:31,206 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-19 15:23:31,213 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-19 15:23:31,218 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-19 15:23:32,912 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:23:32,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:23:37,105 :: INFO :: evodenss.train.trainers :: [0] -- [3.82s] TRAIN epoch 0 -- loss: tensor([0.2752], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:37,108 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.275
2024-11-19 15:23:37,108 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:37,649 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:23:39,684 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 1 -- loss: tensor([0.1143], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:39,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:23:39,687 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:40,167 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:23:41,848 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 2 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:41,851 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:23:41,851 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:42,377 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:23:43,997 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 3 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:44,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:23:44,000 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:44,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:23:46,332 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 4 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:46,335 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:23:46,335 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:46,870 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:23:48,488 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 5 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:48,491 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:23:48,491 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:49,035 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:23:51,143 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 6 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:51,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:23:51,146 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:51,690 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:23:53,513 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 7 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:53,516 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:23:53,517 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:54,057 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:23:56,141 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 8 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:56,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:23:56,145 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:56,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:23:58,491 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 9 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:23:58,495 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:23:58,495 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:23:59,038 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:24:00,836 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 10 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:00,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:00,839 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:01,382 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:24:02,983 :: INFO :: evodenss.train.trainers :: [0] -- [1.6s] TRAIN epoch 11 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:02,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:02,986 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:03,512 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:24:05,303 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 12 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:05,306 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:05,306 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:05,849 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:24:07,572 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 13 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:07,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:07,575 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:08,130 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:24:09,981 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 14 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:09,984 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:09,984 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:10,539 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:24:12,168 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 15 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:12,171 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:12,171 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:12,712 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:24:14,348 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 16 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:14,351 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:24:14,351 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:14,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:24:16,854 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 17 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:16,857 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:16,857 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:17,416 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:24:19,026 :: INFO :: evodenss.train.trainers :: [0] -- [1.61s] TRAIN epoch 18 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:19,029 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:24:19,029 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:19,561 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:24:21,153 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 19 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:21,156 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:21,156 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:21,714 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:24:23,355 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 20 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:23,366 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:23,366 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:23,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:24:25,867 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 21 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:25,869 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:25,869 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:26,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:24:27,835 :: INFO :: evodenss.train.trainers :: [0] -- [1.42s] TRAIN epoch 22 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:27,838 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:27,838 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:28,320 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:24:29,929 :: INFO :: evodenss.train.trainers :: [0] -- [1.61s] TRAIN epoch 23 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:29,932 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:29,932 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:30,465 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:24:32,226 :: INFO :: evodenss.train.trainers :: [0] -- [1.76s] TRAIN epoch 24 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:32,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:32,229 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:32,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:24:34,438 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 25 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:34,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:34,440 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:34,967 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:24:36,573 :: INFO :: evodenss.train.trainers :: [0] -- [1.6s] TRAIN epoch 26 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:36,576 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:36,576 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:37,136 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:24:38,882 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 27 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:38,885 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:38,885 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:39,448 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:24:41,258 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 28 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:41,260 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:24:41,260 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:41,813 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:24:43,454 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 29 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:43,457 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:24:43,457 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:44,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:24:45,811 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 30 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:45,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:45,814 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:46,365 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:24:48,091 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 31 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:48,094 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:48,094 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:48,625 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:24:50,345 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 32 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:50,348 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:50,348 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:50,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:24:52,579 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 33 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:52,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:24:52,584 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:53,154 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:24:54,845 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 34 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:54,848 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:24:54,848 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:55,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:24:56,938 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 35 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:56,941 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:24:56,941 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:57,414 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:24:59,223 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 36 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:24:59,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:24:59,226 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:24:59,718 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:25:01,325 :: INFO :: evodenss.train.trainers :: [0] -- [1.61s] TRAIN epoch 37 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:01,328 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:01,328 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:01,818 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:25:03,405 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 38 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:03,408 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:03,408 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:03,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:25:05,542 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 39 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:05,545 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:05,545 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:06,094 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:25:07,745 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 40 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:07,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:07,748 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:08,275 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:25:09,922 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 41 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:09,925 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:09,925 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:10,468 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:25:12,248 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 42 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:12,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:12,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:12,785 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:25:14,498 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 43 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:14,501 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:14,501 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:15,051 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:25:16,640 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 44 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:16,642 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:16,642 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:17,190 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:25:18,919 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 45 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:18,922 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:18,922 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:19,473 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:25:21,057 :: INFO :: evodenss.train.trainers :: [0] -- [1.58s] TRAIN epoch 46 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:21,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:21,060 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:21,592 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:25:23,167 :: INFO :: evodenss.train.trainers :: [0] -- [1.57s] TRAIN epoch 47 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:23,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:23,169 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:23,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:25:25,415 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 48 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:25,418 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:25,418 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:25,963 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:25:27,664 :: INFO :: evodenss.train.trainers :: [0] -- [1.7s] TRAIN epoch 49 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:27,667 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:25:27,667 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:28,785 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 282792,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 117.56618404388428,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.12337,  losses: {'train_loss': [0.275, 0.114, 0.11, 0.109, 0.108, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.105, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105], 'val_loss': [0.101, 0.088, 0.086, 0.085, 0.085, 0.09, 0.085, 0.09, 0.088, 0.096, 0.092, 0.089, 0.086, 0.09, 0.085, 0.085, 0.086, 0.087, 0.088, 0.087, 0.085, 0.085, 0.085, 0.085, 0.086, 0.084, 0.086, 0.087, 0.084, 0.087, 0.085, 0.085, 0.085, 0.085, 0.087, 0.086, 0.085, 0.087, 0.085, 0.085, 0.085, 0.086, 0.086, 0.085, 0.086, 0.085, 0.085, 0.085, 0.085, 0.085]}),  max_epochs_reached: True

2024-11-19 15:25:28,789 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.12337
2024-11-19 15:25:28,797 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-19 15:25:28,800 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:124 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 
layer7: :conv1d out_channels:47 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0008393550496114862 batch_size:34 epochs:50
2024-11-19 15:25:28,815 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:25:28,815 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:25:30,526 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 0 -- loss: tensor([0.4583], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:30,529 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.458
2024-11-19 15:25:30,529 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:31,112 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:25:32,781 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 1 -- loss: tensor([0.1544], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:32,784 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.154
2024-11-19 15:25:32,784 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:33,329 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:25:35,011 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 2 -- loss: tensor([0.1140], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:35,014 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:25:35,014 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:35,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:25:37,051 :: INFO :: evodenss.train.trainers :: [0] -- [1.5s] TRAIN epoch 3 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:37,054 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:25:37,054 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:37,612 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:25:39,363 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 4 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:39,366 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:25:39,366 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:39,924 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:25:41,680 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 5 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:41,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:25:41,683 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:42,165 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:25:43,952 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 6 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:43,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:25:43,955 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:44,503 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:25:46,129 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 7 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:46,132 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:25:46,132 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:46,666 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:25:48,389 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 8 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:48,392 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:48,392 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:48,899 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:25:50,553 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 9 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:50,556 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:50,556 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:51,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:25:52,806 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 10 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:52,809 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:52,809 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:53,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:25:55,161 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 11 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:55,164 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:55,164 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:55,691 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:25:57,609 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 12 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:57,612 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:57,612 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:25:58,158 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:25:59,679 :: INFO :: evodenss.train.trainers :: [0] -- [1.52s] TRAIN epoch 13 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:25:59,682 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:25:59,682 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:00,228 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:26:02,026 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 14 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:02,029 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:02,029 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:02,571 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:26:04,435 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 15 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:04,438 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:04,438 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:04,985 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:26:06,672 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 16 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:06,675 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:06,675 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:07,226 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:26:08,873 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 17 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:08,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:26:08,876 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:09,428 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:26:11,252 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 18 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:11,254 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:11,254 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:11,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:26:13,572 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 19 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:13,576 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:26:13,576 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:14,139 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:26:15,911 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 20 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:15,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:15,913 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:16,423 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:26:18,252 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 21 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:18,255 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:18,255 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:18,761 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:26:20,816 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 22 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:20,819 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:20,819 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:21,364 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:26:22,997 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 23 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:23,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:23,000 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:23,553 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:26:25,486 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 24 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:25,489 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:25,489 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:26,074 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:26:27,744 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 25 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:27,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:27,748 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:28,294 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:26:29,868 :: INFO :: evodenss.train.trainers :: [0] -- [1.57s] TRAIN epoch 26 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:29,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:29,871 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:30,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:26:32,006 :: INFO :: evodenss.train.trainers :: [0] -- [1.56s] TRAIN epoch 27 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:32,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:32,009 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:32,573 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:26:34,294 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 28 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:34,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:34,297 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:34,852 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:26:36,393 :: INFO :: evodenss.train.trainers :: [0] -- [1.54s] TRAIN epoch 29 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:36,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:36,396 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:36,943 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:26:38,676 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 30 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:38,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:38,679 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:39,255 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:26:41,271 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 31 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:41,274 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:26:41,274 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:41,819 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:26:43,597 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 32 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:43,600 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:43,600 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:44,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:26:45,778 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 33 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:45,781 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:45,781 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:46,345 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:26:47,836 :: INFO :: evodenss.train.trainers :: [0] -- [1.49s] TRAIN epoch 34 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:47,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:26:47,839 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:48,317 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:26:50,086 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 35 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:50,088 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:50,088 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:50,663 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:26:52,300 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 36 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:52,302 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:26:52,303 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:52,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:26:54,356 :: INFO :: evodenss.train.trainers :: [0] -- [1.56s] TRAIN epoch 37 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:54,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:26:54,359 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:54,931 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:26:56,648 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 38 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:56,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:26:56,651 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:57,196 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:26:59,175 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 39 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:26:59,178 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:26:59,178 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:26:59,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:27:01,551 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 40 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:01,554 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:27:01,554 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:02,098 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:27:03,955 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 41 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:03,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:27:03,957 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:04,492 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:27:06,228 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 42 -- loss: tensor([0.1051], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:06,230 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:27:06,230 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:06,775 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:27:08,365 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 43 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:08,368 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:27:08,368 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:08,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:27:10,505 :: INFO :: evodenss.train.trainers :: [0] -- [1.58s] TRAIN epoch 44 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:10,508 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:27:10,508 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:11,056 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:27:12,812 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 45 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:12,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:27:12,815 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:13,333 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:27:15,081 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 46 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:15,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:27:15,084 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:15,630 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:27:17,219 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 47 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:17,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:27:17,222 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:17,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:27:19,486 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 48 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:19,489 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:27:19,489 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:20,051 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:27:22,057 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 49 -- loss: tensor([0.1049], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:22,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:27:22,060 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:23,128 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 294018,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 114.32585167884827,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.25352,  losses: {'train_loss': [0.458, 0.154, 0.114, 0.109, 0.108, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.105, 0.106, 0.105, 0.105, 0.105, 0.106, 0.106, 0.106, 0.105, 0.105, 0.105, 0.106, 0.106, 0.105, 0.105, 0.105], 'val_loss': [0.183, 0.1, 0.085, 0.088, 0.086, 0.086, 0.086, 0.085, 0.087, 0.089, 0.085, 0.087, 0.085, 0.108, 0.129, 0.084, 0.087, 0.086, 0.091, 0.094, 0.084, 0.085, 0.085, 0.086, 0.091, 0.084, 0.085, 0.084, 0.084, 0.084, 0.089, 0.085, 0.089, 0.084, 0.085, 0.084, 0.085, 0.09, 0.084, 0.085, 0.086, 0.085, 0.089, 0.086, 0.086, 0.084, 0.084, 0.084, 0.088, 0.188]}),  max_epochs_reached: True

2024-11-19 15:27:23,139 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.25352
2024-11-19 15:27:23,146 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-19 15:27:23,150 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :deconv1d out_channels:51 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :deconv1d out_channels:125 kernel_size:4 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.004085298026577847 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-19 15:27:23,164 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:27:23,164 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:27:25,235 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 0 -- loss: tensor([0.3048], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:25,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.305
2024-11-19 15:27:25,237 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:25,771 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:27:27,613 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 1 -- loss: tensor([0.1799], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:27,616 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.18
2024-11-19 15:27:27,616 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:28,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:27:29,957 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 2 -- loss: tensor([0.1865], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:29,959 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.187
2024-11-19 15:27:29,959 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:30,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:27:32,224 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 3 -- loss: tensor([0.1518], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:32,227 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.152
2024-11-19 15:27:32,227 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:32,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:27:34,457 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 4 -- loss: tensor([0.1199], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:34,460 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-19 15:27:34,460 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:34,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:27:36,595 :: INFO :: evodenss.train.trainers :: [0] -- [1.6s] TRAIN epoch 5 -- loss: tensor([0.1240], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:36,597 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-19 15:27:36,597 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:37,167 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:27:38,890 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 6 -- loss: tensor([0.1119], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:38,893 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:27:38,893 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:39,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:27:41,036 :: INFO :: evodenss.train.trainers :: [0] -- [1.61s] TRAIN epoch 7 -- loss: tensor([0.1126], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:41,039 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:27:41,039 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:41,615 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:27:43,311 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 8 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:43,313 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:27:43,314 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:43,882 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:27:45,506 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 9 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:45,508 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:27:45,508 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:46,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:27:47,838 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 10 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:47,840 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:27:47,840 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:48,378 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:27:50,002 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 11 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:50,005 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:27:50,005 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:50,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:27:52,394 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 12 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:52,397 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:27:52,397 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:52,959 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:27:54,519 :: INFO :: evodenss.train.trainers :: [0] -- [1.56s] TRAIN epoch 13 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:54,524 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:27:54,524 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:55,097 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:27:56,838 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 14 -- loss: tensor([0.1133], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:56,841 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:27:56,841 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:57,384 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:27:59,011 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 15 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:27:59,014 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:27:59,014 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:27:59,575 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:28:01,384 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 16 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:01,386 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:01,386 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:01,940 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:28:03,584 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 17 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:03,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:03,587 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:04,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:28:06,061 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 18 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:06,063 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:06,064 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:06,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:28:08,566 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 19 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:08,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:08,569 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:09,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:28:10,739 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 20 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:10,742 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:10,742 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:11,274 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:28:13,059 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 21 -- loss: tensor([0.1128], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:13,062 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:28:13,062 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:13,624 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:28:15,110 :: INFO :: evodenss.train.trainers :: [0] -- [1.48s] TRAIN epoch 22 -- loss: tensor([0.1119], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:15,113 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:28:15,113 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:15,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:28:17,444 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 23 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:17,447 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:28:17,447 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:18,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:28:20,041 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 24 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:20,045 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:20,045 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:20,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:28:22,223 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 25 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:22,225 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:22,225 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:22,772 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:28:24,675 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 26 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:24,678 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:24,678 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:25,231 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:28:26,942 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 27 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:26,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:26,945 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:27,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:28:29,071 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 28 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:29,074 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:29,074 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:29,629 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:28:31,419 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 29 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:31,422 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:28:31,422 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:31,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:28:33,576 :: INFO :: evodenss.train.trainers :: [0] -- [1.58s] TRAIN epoch 30 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:33,579 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:33,579 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:34,079 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:28:35,854 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 31 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:35,856 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:35,856 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:36,412 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:28:38,051 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 32 -- loss: tensor([0.1139], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:38,054 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:28:38,054 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:38,614 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:28:40,346 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 33 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:40,349 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:40,349 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:40,921 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:28:42,576 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 34 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:42,579 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:42,579 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:43,135 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:28:44,933 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 35 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:44,936 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:44,936 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:45,491 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:28:47,287 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 36 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:47,290 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:28:47,290 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:47,875 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:28:49,465 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 37 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:49,468 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:49,468 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:50,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:28:51,652 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 38 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:51,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:28:51,655 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:52,211 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:28:53,878 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 39 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:53,880 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:28:53,880 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:54,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:28:56,089 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 40 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:56,091 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:28:56,091 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:56,646 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:28:58,397 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 41 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:28:58,400 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:28:58,400 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:28:58,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:29:00,691 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 42 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:00,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:29:00,694 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:01,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:29:02,774 :: INFO :: evodenss.train.trainers :: [0] -- [1.52s] TRAIN epoch 43 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:02,777 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:29:02,777 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:03,357 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:29:05,049 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 44 -- loss: tensor([0.1140], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:05,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:29:05,052 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:05,616 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:29:07,297 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 45 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:07,300 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:29:07,300 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:07,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:29:09,823 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 46 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:09,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:29:09,826 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:10,407 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:29:12,105 :: INFO :: evodenss.train.trainers :: [0] -- [1.7s] TRAIN epoch 47 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:12,108 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:29:12,108 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:12,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:29:14,387 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 48 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:14,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:29:14,390 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:14,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:29:16,499 :: INFO :: evodenss.train.trainers :: [0] -- [1.55s] TRAIN epoch 49 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:16,502 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:29:16,502 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:17,630 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 375271,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 114.47868251800537,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.96626,  losses: {'train_loss': [0.305, 0.18, 0.187, 0.152, 0.12, 0.124, 0.112, 0.113, 0.11, 0.111, 0.111, 0.11, 0.11, 0.11, 0.113, 0.113, 0.11, 0.11, 0.111, 0.11, 0.11, 0.113, 0.112, 0.112, 0.11, 0.11, 0.11, 0.111, 0.111, 0.109, 0.111, 0.111, 0.114, 0.111, 0.111, 0.11, 0.109, 0.11, 0.109, 0.11, 0.109, 0.111, 0.111, 0.11, 0.114, 0.109, 0.111, 0.11, 0.11, 0.111], 'val_loss': [0.164, 0.15, 0.099, 0.22, 0.507, 0.107, 0.096, 0.111, 0.143, 0.27, 0.132, 0.111, 0.157, 0.217, 0.106, 0.242, 0.132, 0.154, 0.554, 0.162, 0.529, 0.098, 0.096, 0.095, 0.101, 0.207, 0.152, 0.171, 0.103, 0.156, 0.209, 0.125, 0.109, 0.164, 0.207, 0.102, 0.163, 0.218, 0.117, 0.116, 0.095, 0.281, 0.091, 0.151, 0.106, 0.126, 0.106, 0.116, 0.176, 0.882]}),  max_epochs_reached: True

2024-11-19 15:29:17,633 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.96626
2024-11-19 15:29:17,641 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-19 15:29:17,645 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:27 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 
layer7: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :deconv1d out_channels:99 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:33 epochs:50
2024-11-19 15:29:17,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:29:17,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:29:19,481 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 0 -- loss: tensor([0.2853], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:19,484 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.285
2024-11-19 15:29:19,484 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:20,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:29:21,818 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 1 -- loss: tensor([0.1172], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:21,820 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-19 15:29:21,820 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:22,355 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:29:24,195 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 2 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:24,198 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:29:24,198 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:24,729 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:29:26,372 :: INFO :: evodenss.train.trainers :: [0] -- [1.64s] TRAIN epoch 3 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:26,375 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:29:26,375 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:26,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:29:28,462 :: INFO :: evodenss.train.trainers :: [0] -- [1.56s] TRAIN epoch 4 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:28,465 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:29:28,465 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:29,034 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:29:30,621 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 5 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:30,624 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:29:30,624 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:31,178 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:29:33,143 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 6 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:33,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:29:33,145 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:33,695 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:29:35,318 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 7 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:35,320 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:35,321 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:35,868 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:29:37,393 :: INFO :: evodenss.train.trainers :: [0] -- [1.52s] TRAIN epoch 8 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:37,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:37,395 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:37,950 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:29:39,568 :: INFO :: evodenss.train.trainers :: [0] -- [1.62s] TRAIN epoch 9 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:39,570 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:39,570 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:40,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:29:41,895 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 10 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:41,898 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:41,898 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:42,455 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:29:44,110 :: INFO :: evodenss.train.trainers :: [0] -- [1.65s] TRAIN epoch 11 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:44,113 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:44,113 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:44,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:29:46,322 :: INFO :: evodenss.train.trainers :: [0] -- [1.66s] TRAIN epoch 12 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:46,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:29:46,325 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:46,815 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:29:48,543 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 13 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:48,546 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:48,546 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:49,057 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:29:50,728 :: INFO :: evodenss.train.trainers :: [0] -- [1.67s] TRAIN epoch 14 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:50,731 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:50,731 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:51,276 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:29:52,743 :: INFO :: evodenss.train.trainers :: [0] -- [1.47s] TRAIN epoch 15 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:52,746 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:29:52,746 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:53,296 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:29:54,912 :: INFO :: evodenss.train.trainers :: [0] -- [1.61s] TRAIN epoch 16 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:54,915 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:54,915 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:55,482 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:29:57,077 :: INFO :: evodenss.train.trainers :: [0] -- [1.59s] TRAIN epoch 17 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:57,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:29:57,080 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:29:57,693 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:29:59,452 :: INFO :: evodenss.train.trainers :: [0] -- [1.76s] TRAIN epoch 18 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:29:59,455 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:29:59,455 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:00,002 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:30:01,835 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 19 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:01,838 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:01,838 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:02,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:30:04,111 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 20 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:04,113 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:04,113 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:04,664 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:30:06,403 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 21 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:06,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:06,405 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:06,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:30:09,046 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 22 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:09,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:09,048 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:09,609 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:30:11,510 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 23 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:11,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:11,513 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:12,014 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:30:13,865 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 24 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:13,867 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:13,868 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:14,406 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:30:16,125 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 25 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:16,127 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:16,127 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:16,697 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:30:18,397 :: INFO :: evodenss.train.trainers :: [0] -- [1.7s] TRAIN epoch 26 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:18,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:18,405 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:18,894 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:30:20,397 :: INFO :: evodenss.train.trainers :: [0] -- [1.5s] TRAIN epoch 27 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:20,400 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:20,400 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:20,881 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:30:22,638 :: INFO :: evodenss.train.trainers :: [0] -- [1.76s] TRAIN epoch 28 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:22,641 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:22,641 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:23,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:30:25,184 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 29 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:25,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:25,187 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:25,739 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:30:27,339 :: INFO :: evodenss.train.trainers :: [0] -- [1.6s] TRAIN epoch 30 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:27,342 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:27,342 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:27,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:30:29,677 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 31 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:29,679 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:29,679 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:30,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:30:31,925 :: INFO :: evodenss.train.trainers :: [0] -- [1.7s] TRAIN epoch 32 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:31,928 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:31,928 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:32,477 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:30:34,455 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 33 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:34,458 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:34,458 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:35,015 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:30:36,588 :: INFO :: evodenss.train.trainers :: [0] -- [1.57s] TRAIN epoch 34 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:36,591 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:36,591 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:37,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:30:38,720 :: INFO :: evodenss.train.trainers :: [0] -- [1.57s] TRAIN epoch 35 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:38,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:38,723 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:39,284 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:30:40,965 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 36 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:40,968 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:40,968 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:41,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:30:43,170 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 37 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:43,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:43,173 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:43,762 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:30:45,451 :: INFO :: evodenss.train.trainers :: [0] -- [1.69s] TRAIN epoch 38 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:45,453 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:45,454 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:46,018 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:30:47,549 :: INFO :: evodenss.train.trainers :: [0] -- [1.53s] TRAIN epoch 39 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:47,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:47,552 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:48,120 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:30:49,971 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 40 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:49,973 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:49,973 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:50,518 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:30:52,243 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 41 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:52,246 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:30:52,246 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:52,734 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:30:54,535 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 42 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:54,540 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:54,540 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:55,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:30:56,703 :: INFO :: evodenss.train.trainers :: [0] -- [1.61s] TRAIN epoch 43 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:56,705 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:56,705 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:57,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:30:58,921 :: INFO :: evodenss.train.trainers :: [0] -- [1.66s] TRAIN epoch 44 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:30:58,924 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:30:58,924 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:30:59,501 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:31:01,185 :: INFO :: evodenss.train.trainers :: [0] -- [1.68s] TRAIN epoch 45 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:01,188 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:01,188 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:01,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:31:03,792 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 46 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:03,794 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:03,795 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:04,351 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:31:06,097 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 47 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:06,100 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:06,100 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:06,651 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:31:08,280 :: INFO :: evodenss.train.trainers :: [0] -- [1.63s] TRAIN epoch 48 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:08,283 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:08,283 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:08,834 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:31:10,373 :: INFO :: evodenss.train.trainers :: [0] -- [1.54s] TRAIN epoch 49 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:10,376 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:10,376 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:11,499 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 262409,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 113.85270690917969,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.12364,  losses: {'train_loss': [0.285, 0.117, 0.112, 0.11, 0.109, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.106, 0.107, 0.106, 0.107, 0.106, 0.107, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.107, 0.106, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.107, 0.106], 'val_loss': [0.11, 0.092, 0.09, 0.091, 0.089, 0.093, 0.09, 0.091, 0.096, 0.09, 0.089, 0.089, 0.089, 0.089, 0.096, 0.091, 0.104, 0.092, 0.09, 0.09, 0.089, 0.089, 0.09, 0.09, 0.091, 0.089, 0.09, 0.09, 0.09, 0.09, 0.089, 0.09, 0.09, 0.093, 0.09, 0.089, 0.089, 0.093, 0.09, 0.092, 0.092, 0.092, 0.09, 0.092, 0.092, 0.091, 0.098, 0.091, 0.09, 0.09]}),  max_epochs_reached: True

2024-11-19 15:31:11,501 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.12364
2024-11-19 15:31:11,505 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-19 15:31:11,510 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 0, id: 0
2024-11-19 15:31:11,512 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-19 15:31:11,515 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-19 15:31:11,521 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.12337, 0.25352, 0.96626, 0.12364]
2024-11-19 15:31:16,459 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1712], device='cuda:0')
2024-11-19 15:31:16,462 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 7: 0.12337
2024-11-19 15:31:16,466 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.12337



2024-11-19 15:31:16,573 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 8
2024-11-19 15:31:16,576 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-19 15:31:16,590 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 15:31:16,593 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 15:31:16,597 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:31:16,600 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-19 15:31:16,603 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 15:31:16,606 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:31:16,612 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 15:31:16,615 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:31:16,619 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:31:16,622 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-19 15:31:16,625 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:31:16,630 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 15:31:16,633 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:31:16,639 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:31:16,643 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 15:31:16,647 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:31:16,650 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-19 15:31:16,653 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:31:16,657 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-19 15:31:16,660 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:31:16,667 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-19 15:31:16,673 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-19 15:31:16,677 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-19 15:31:16,691 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:31:16,691 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:31:18,479 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 0 -- loss: tensor([0.2585], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:18,482 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.258
2024-11-19 15:31:18,482 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:19,118 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:31:20,938 :: INFO :: evodenss.train.trainers :: [0] -- [1.82s] TRAIN epoch 1 -- loss: tensor([0.1150], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:20,941 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:31:20,942 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:21,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:31:23,376 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 2 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:23,379 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:31:23,379 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:24,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:31:25,915 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 3 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:25,918 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:31:25,918 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:26,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:31:28,785 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 4 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:28,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:31:28,788 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:29,428 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:31:31,261 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 5 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:31,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:31:31,264 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:31,905 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:31:33,628 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 6 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:33,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:33,631 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:34,271 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:31:36,081 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 7 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:36,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:36,084 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:36,701 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:31:38,544 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 8 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:38,546 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:38,546 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:39,207 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:31:40,933 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 9 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:40,935 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:40,935 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:41,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:31:43,695 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 10 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:43,698 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:43,698 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:44,341 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:31:46,140 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 11 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:46,143 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:46,143 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:46,765 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:31:48,520 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 12 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:48,523 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:48,523 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:49,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:31:50,888 :: INFO :: evodenss.train.trainers :: [0] -- [1.72s] TRAIN epoch 13 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:50,891 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:50,891 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:51,530 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:31:53,388 :: INFO :: evodenss.train.trainers :: [0] -- [1.86s] TRAIN epoch 14 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:53,391 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:53,391 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:54,026 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:31:56,226 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 15 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:56,229 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:31:56,229 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:56,813 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:31:58,691 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 16 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:31:58,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:31:58,695 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:31:59,332 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:32:00,998 :: INFO :: evodenss.train.trainers :: [0] -- [1.66s] TRAIN epoch 17 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:01,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:32:01,001 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:01,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:32:03,600 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 18 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:03,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:03,603 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:04,242 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:32:06,089 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 19 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:06,092 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:06,092 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:06,730 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:32:08,600 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 20 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:08,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:08,603 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:09,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:32:11,020 :: INFO :: evodenss.train.trainers :: [0] -- [1.73s] TRAIN epoch 21 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:11,023 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:11,023 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:11,680 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:32:13,812 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 22 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:13,815 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:13,815 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:14,449 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:32:16,236 :: INFO :: evodenss.train.trainers :: [0] -- [1.79s] TRAIN epoch 23 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:16,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:16,239 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:16,882 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:32:19,072 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 24 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:19,075 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:19,075 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:19,704 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:32:21,905 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 25 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:21,908 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:21,908 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:22,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:32:24,405 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 26 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:24,408 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:24,408 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:25,033 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:32:26,991 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 27 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:26,994 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:26,994 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:27,650 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:32:29,519 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 28 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:29,522 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:29,522 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:30,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:32:32,098 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 29 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:32,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:32,101 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:32,726 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:32:34,762 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 30 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:34,765 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:32:34,765 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:35,379 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:32:37,120 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 31 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:37,123 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:37,123 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:37,764 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:32:39,736 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 32 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:39,741 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:39,741 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:40,394 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:32:42,107 :: INFO :: evodenss.train.trainers :: [0] -- [1.71s] TRAIN epoch 33 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:42,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:42,111 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:42,734 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:32:44,532 :: INFO :: evodenss.train.trainers :: [0] -- [1.8s] TRAIN epoch 34 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:44,535 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:44,535 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:45,171 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:32:47,172 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 35 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:47,175 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:32:47,175 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:47,803 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:32:49,967 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 36 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:49,969 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:49,970 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:50,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:32:52,728 :: INFO :: evodenss.train.trainers :: [0] -- [2.14s] TRAIN epoch 37 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:52,731 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:52,731 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:53,354 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:32:55,557 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 38 -- loss: tensor([0.1053], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:55,560 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:32:55,560 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:56,178 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:32:57,916 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 39 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:32:57,927 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:32:57,927 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:32:58,581 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:33:00,805 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 40 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:00,808 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:00,808 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:01,439 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:33:03,216 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 41 -- loss: tensor([0.1052], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:03,219 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:33:03,219 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:03,816 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:33:05,664 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 42 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:05,667 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:05,667 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:06,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:33:08,463 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 43 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:08,465 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:08,466 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:09,089 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:33:11,044 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 44 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:11,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:33:11,053 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:11,668 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:33:13,774 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 45 -- loss: tensor([0.1054], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:13,777 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.105
2024-11-19 15:33:13,777 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:14,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:33:16,389 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 46 -- loss: tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:16,391 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:16,392 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:17,028 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:33:19,202 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 47 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:19,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:19,205 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:19,846 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:33:21,592 :: INFO :: evodenss.train.trainers :: [0] -- [1.74s] TRAIN epoch 48 -- loss: tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:21,595 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:21,595 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:22,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:33:24,149 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 49 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:24,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:33:24,152 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:25,416 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 282792,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 128.73796677589417,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.18751,  losses: {'train_loss': [0.258, 0.115, 0.111, 0.11, 0.109, 0.108, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.107, 0.106, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.106, 0.106, 0.105, 0.105, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.107, 0.086, 0.086, 0.088, 0.085, 0.086, 0.087, 0.086, 0.093, 0.085, 0.092, 0.086, 0.091, 0.088, 0.088, 0.091, 0.09, 0.089, 0.085, 0.087, 0.086, 0.086, 0.086, 0.092, 0.09, 0.087, 0.085, 0.102, 0.084, 0.084, 0.085, 0.085, 0.085, 0.091, 0.087, 0.084, 0.085, 0.085, 0.086, 0.086, 0.085, 0.09, 0.092, 0.084, 0.086, 0.086, 0.084, 0.087, 0.088, 0.103]}),  max_epochs_reached: True

2024-11-19 15:33:25,422 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.18751
2024-11-19 15:33:25,429 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-19 15:33:25,434 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 
layer7: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 
layer13: :fc act:selu out_features:200 bias:True input:11 learning:lars lr_weights:0.33659198982415356 lr_biases:0.007820505020089318 momentum:0.7503046655215385 weight_decay:1.1314872283856536e-06 batch_size:34 epochs:50
2024-11-19 15:33:25,447 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:33:25,447 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:33:27,820 :: INFO :: evodenss.train.trainers :: [0] -- [2.37s] TRAIN epoch 0 -- loss: tensor([0.9890], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:27,822 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.989
2024-11-19 15:33:27,822 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:28,493 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:33:30,460 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 1 -- loss: tensor([0.9591], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:30,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.959
2024-11-19 15:33:30,463 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:31,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:33:33,083 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 2 -- loss: tensor([0.9296], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:33,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.93
2024-11-19 15:33:33,085 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:33,742 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:33:35,892 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 3 -- loss: tensor([0.9041], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:35,895 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.904
2024-11-19 15:33:35,895 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:36,548 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:33:38,612 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 4 -- loss: tensor([0.8732], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:38,615 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.873
2024-11-19 15:33:38,615 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:39,263 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:33:41,284 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 5 -- loss: tensor([0.8447], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:41,288 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.845
2024-11-19 15:33:41,288 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:41,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:33:43,897 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 6 -- loss: tensor([0.8139], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:43,900 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.814
2024-11-19 15:33:43,901 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:44,557 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:33:46,406 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 7 -- loss: tensor([0.7879], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:46,409 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.788
2024-11-19 15:33:46,409 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:47,069 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:33:49,043 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 8 -- loss: tensor([0.7568], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:49,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.757
2024-11-19 15:33:49,053 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:49,647 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:33:51,747 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 9 -- loss: tensor([0.7320], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:51,750 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.732
2024-11-19 15:33:51,750 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:52,326 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:33:54,501 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 10 -- loss: tensor([0.7045], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:54,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.704
2024-11-19 15:33:54,504 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:55,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:33:56,995 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 11 -- loss: tensor([0.6798], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:56,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.68
2024-11-19 15:33:56,998 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:33:57,620 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:33:59,508 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 12 -- loss: tensor([0.6558], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:33:59,511 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.656
2024-11-19 15:33:59,511 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:00,139 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:34:02,130 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 13 -- loss: tensor([0.6336], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:02,133 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.634
2024-11-19 15:34:02,133 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:02,757 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:34:04,708 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 14 -- loss: tensor([0.6115], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:04,711 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.611
2024-11-19 15:34:04,711 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:05,330 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:34:07,169 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 15 -- loss: tensor([0.5929], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:07,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.593
2024-11-19 15:34:07,172 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:07,764 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:34:09,693 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 16 -- loss: tensor([0.5744], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:09,696 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.574
2024-11-19 15:34:09,696 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:10,338 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:34:12,178 :: INFO :: evodenss.train.trainers :: [0] -- [1.84s] TRAIN epoch 17 -- loss: tensor([0.5571], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:12,180 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.557
2024-11-19 15:34:12,180 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:12,831 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:34:14,797 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 18 -- loss: tensor([0.5404], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:14,799 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.54
2024-11-19 15:34:14,799 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:15,430 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:34:17,395 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 19 -- loss: tensor([0.5251], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:17,398 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.525
2024-11-19 15:34:17,398 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:18,030 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:34:19,808 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 20 -- loss: tensor([0.5099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:19,811 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.51
2024-11-19 15:34:19,811 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:20,484 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:34:22,335 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 21 -- loss: tensor([0.4965], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:22,338 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.497
2024-11-19 15:34:22,338 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:22,988 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:34:24,841 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 22 -- loss: tensor([0.4833], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:24,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.483
2024-11-19 15:34:24,843 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:25,512 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:34:27,452 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 23 -- loss: tensor([0.4694], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:27,455 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.469
2024-11-19 15:34:27,455 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:28,089 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:34:30,024 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 24 -- loss: tensor([0.4574], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:30,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.457
2024-11-19 15:34:30,027 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:30,681 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:34:32,462 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 25 -- loss: tensor([0.4460], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:32,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.446
2024-11-19 15:34:32,465 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:33,163 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:34:35,082 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 26 -- loss: tensor([0.4343], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:35,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.434
2024-11-19 15:34:35,085 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:35,706 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:34:37,668 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 27 -- loss: tensor([0.4241], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:37,671 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.424
2024-11-19 15:34:37,671 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:38,288 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:34:40,059 :: INFO :: evodenss.train.trainers :: [0] -- [1.77s] TRAIN epoch 28 -- loss: tensor([0.4142], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:40,061 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.414
2024-11-19 15:34:40,062 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:40,699 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:34:42,608 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 29 -- loss: tensor([0.4038], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:42,610 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.404
2024-11-19 15:34:42,610 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:43,228 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:34:45,125 :: INFO :: evodenss.train.trainers :: [0] -- [1.9s] TRAIN epoch 30 -- loss: tensor([0.3939], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:45,129 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.394
2024-11-19 15:34:45,129 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:45,751 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:34:47,721 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 31 -- loss: tensor([0.3850], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:47,724 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.385
2024-11-19 15:34:47,724 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:48,348 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:34:50,182 :: INFO :: evodenss.train.trainers :: [0] -- [1.83s] TRAIN epoch 32 -- loss: tensor([0.3761], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:50,185 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.376
2024-11-19 15:34:50,185 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:50,831 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:34:52,831 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 33 -- loss: tensor([0.3676], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:52,834 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.368
2024-11-19 15:34:52,834 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:53,421 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:34:55,434 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 34 -- loss: tensor([0.3600], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:55,437 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.36
2024-11-19 15:34:55,437 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:56,079 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:34:58,228 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 35 -- loss: tensor([0.3529], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:34:58,232 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.353
2024-11-19 15:34:58,232 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:34:58,881 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:35:00,995 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 36 -- loss: tensor([0.3459], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:00,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.346
2024-11-19 15:35:00,997 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:01,644 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:35:03,612 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 37 -- loss: tensor([0.3392], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:03,615 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.339
2024-11-19 15:35:03,615 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:04,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:35:06,414 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 38 -- loss: tensor([0.3320], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:06,416 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.332
2024-11-19 15:35:06,416 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:07,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:35:09,037 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 39 -- loss: tensor([0.3259], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:09,040 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.326
2024-11-19 15:35:09,040 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:09,718 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:35:11,749 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 40 -- loss: tensor([0.3198], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:11,752 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.32
2024-11-19 15:35:11,752 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:12,400 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:35:14,397 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 41 -- loss: tensor([0.3147], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:14,400 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.315
2024-11-19 15:35:14,400 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:15,003 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:35:16,787 :: INFO :: evodenss.train.trainers :: [0] -- [1.78s] TRAIN epoch 42 -- loss: tensor([0.3088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:16,790 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.309
2024-11-19 15:35:16,790 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:17,364 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:35:19,315 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 43 -- loss: tensor([0.3034], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:19,318 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.303
2024-11-19 15:35:19,318 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:20,007 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:35:21,937 :: INFO :: evodenss.train.trainers :: [0] -- [1.93s] TRAIN epoch 44 -- loss: tensor([0.2986], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:21,940 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.299
2024-11-19 15:35:21,940 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:22,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:35:24,547 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 45 -- loss: tensor([0.2933], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:24,550 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.293
2024-11-19 15:35:24,550 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:25,202 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:35:27,402 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 46 -- loss: tensor([0.2886], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:27,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.289
2024-11-19 15:35:27,405 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:28,063 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:35:30,093 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 47 -- loss: tensor([0.2838], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:30,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.284
2024-11-19 15:35:30,096 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:30,745 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:35:32,706 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 48 -- loss: tensor([0.2796], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:32,708 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.28
2024-11-19 15:35:32,709 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:33,367 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:35:35,546 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 49 -- loss: tensor([0.2748], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:35,548 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.275
2024-11-19 15:35:35,548 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:36,814 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 281520,  n_layers: 13,  n_layers_projector: -1,  training_time_spent: 131.37914085388184,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 3.77535,  losses: {'train_loss': [0.989, 0.959, 0.93, 0.904, 0.873, 0.845, 0.814, 0.788, 0.757, 0.732, 0.704, 0.68, 0.656, 0.634, 0.611, 0.593, 0.574, 0.557, 0.54, 0.525, 0.51, 0.497, 0.483, 0.469, 0.457, 0.446, 0.434, 0.424, 0.414, 0.404, 0.394, 0.385, 0.376, 0.368, 0.36, 0.353, 0.346, 0.339, 0.332, 0.326, 0.32, 0.315, 0.309, 0.303, 0.299, 0.293, 0.289, 0.284, 0.28, 0.275], 'val_loss': [0.68, 0.66, 0.648, 0.642, 0.637, 0.62, 0.615, 0.605, 0.597, 0.586, 0.578, 0.559, 0.549, 0.533, 0.518, 0.504, 0.489, 0.478, 0.464, 0.451, 0.437, 0.423, 0.411, 0.396, 0.384, 0.374, 0.363, 0.35, 0.339, 0.33, 0.32, 0.311, 0.301, 0.293, 0.285, 0.278, 0.272, 0.266, 0.259, 0.252, 0.247, 0.241, 0.236, 0.231, 0.226, 0.221, 0.217, 0.213, 0.209, 0.204]}),  max_epochs_reached: True

2024-11-19 15:35:36,819 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 3.77535
2024-11-19 15:35:36,827 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-19 15:35:36,831 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:7 epochs:50
2024-11-19 15:35:36,846 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:35:36,846 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:35:41,349 :: INFO :: evodenss.train.trainers :: [0] -- [4.5s] TRAIN epoch 0 -- loss: tensor([0.1318], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:41,352 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.132
2024-11-19 15:35:41,352 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:42,015 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:35:46,472 :: INFO :: evodenss.train.trainers :: [0] -- [4.46s] TRAIN epoch 1 -- loss: tensor([0.1201], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:46,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-19 15:35:46,475 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:47,106 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:35:51,888 :: INFO :: evodenss.train.trainers :: [0] -- [4.78s] TRAIN epoch 2 -- loss: tensor([0.1151], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:51,891 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:35:51,891 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:52,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:35:57,014 :: INFO :: evodenss.train.trainers :: [0] -- [4.47s] TRAIN epoch 3 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:35:57,017 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:35:57,017 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:35:57,671 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:36:02,181 :: INFO :: evodenss.train.trainers :: [0] -- [4.51s] TRAIN epoch 4 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:02,183 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:36:02,183 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:02,855 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:36:06,998 :: INFO :: evodenss.train.trainers :: [0] -- [4.14s] TRAIN epoch 5 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:07,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:36:07,001 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:07,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:36:11,818 :: INFO :: evodenss.train.trainers :: [0] -- [4.15s] TRAIN epoch 6 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:11,821 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:11,821 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:12,496 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:36:17,090 :: INFO :: evodenss.train.trainers :: [0] -- [4.59s] TRAIN epoch 7 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:17,093 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:17,093 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:17,779 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:36:22,159 :: INFO :: evodenss.train.trainers :: [0] -- [4.38s] TRAIN epoch 8 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:22,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:22,161 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:22,798 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:36:27,261 :: INFO :: evodenss.train.trainers :: [0] -- [4.46s] TRAIN epoch 9 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:27,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:27,264 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:27,906 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:36:32,334 :: INFO :: evodenss.train.trainers :: [0] -- [4.43s] TRAIN epoch 10 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:32,336 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:32,336 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:32,972 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:36:37,158 :: INFO :: evodenss.train.trainers :: [0] -- [4.18s] TRAIN epoch 11 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:37,161 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:37,162 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:37,852 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:36:42,292 :: INFO :: evodenss.train.trainers :: [0] -- [4.44s] TRAIN epoch 12 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:42,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:42,295 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:42,992 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:36:47,552 :: INFO :: evodenss.train.trainers :: [0] -- [4.56s] TRAIN epoch 13 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:47,555 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:36:47,556 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:48,233 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:36:52,585 :: INFO :: evodenss.train.trainers :: [0] -- [4.35s] TRAIN epoch 14 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:52,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:52,588 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:53,263 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:36:57,659 :: INFO :: evodenss.train.trainers :: [0] -- [4.39s] TRAIN epoch 15 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:36:57,662 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:36:57,662 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:36:58,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:37:02,581 :: INFO :: evodenss.train.trainers :: [0] -- [4.23s] TRAIN epoch 16 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:02,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:02,584 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:03,273 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:37:07,491 :: INFO :: evodenss.train.trainers :: [0] -- [4.22s] TRAIN epoch 17 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:07,494 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:07,494 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:08,192 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:37:12,433 :: INFO :: evodenss.train.trainers :: [0] -- [4.24s] TRAIN epoch 18 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:12,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:12,436 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:13,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:37:17,329 :: INFO :: evodenss.train.trainers :: [0] -- [4.23s] TRAIN epoch 19 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:17,333 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:17,333 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:18,045 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:37:22,359 :: INFO :: evodenss.train.trainers :: [0] -- [4.31s] TRAIN epoch 20 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:22,362 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:37:22,362 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:23,040 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:37:27,288 :: INFO :: evodenss.train.trainers :: [0] -- [4.25s] TRAIN epoch 21 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:27,291 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:27,291 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:27,986 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:37:32,295 :: INFO :: evodenss.train.trainers :: [0] -- [4.31s] TRAIN epoch 22 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:32,298 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:32,298 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:32,979 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:37:37,239 :: INFO :: evodenss.train.trainers :: [0] -- [4.26s] TRAIN epoch 23 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:37,242 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:37:37,242 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:37,918 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:37:42,209 :: INFO :: evodenss.train.trainers :: [0] -- [4.29s] TRAIN epoch 24 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:42,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:42,212 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:42,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:37:47,183 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 25 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:47,186 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:37:47,186 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:47,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:37:52,132 :: INFO :: evodenss.train.trainers :: [0] -- [4.26s] TRAIN epoch 26 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:52,135 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:52,135 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:52,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:37:57,079 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 27 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:37:57,082 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:37:57,082 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:37:57,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:38:02,045 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 28 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:02,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:38:02,048 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:02,740 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:38:07,045 :: INFO :: evodenss.train.trainers :: [0] -- [4.3s] TRAIN epoch 29 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:07,048 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:38:07,048 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:07,725 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:38:12,143 :: INFO :: evodenss.train.trainers :: [0] -- [4.42s] TRAIN epoch 30 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:12,146 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:38:12,146 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:12,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:38:17,412 :: INFO :: evodenss.train.trainers :: [0] -- [4.57s] TRAIN epoch 31 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:17,419 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:38:17,420 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:18,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:38:22,378 :: INFO :: evodenss.train.trainers :: [0] -- [4.27s] TRAIN epoch 32 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:22,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:38:22,381 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:23,057 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:38:27,271 :: INFO :: evodenss.train.trainers :: [0] -- [4.21s] TRAIN epoch 33 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:27,274 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:38:27,274 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:27,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:38:32,367 :: INFO :: evodenss.train.trainers :: [0] -- [4.41s] TRAIN epoch 34 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:32,370 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:38:32,370 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:33,042 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:38:37,387 :: INFO :: evodenss.train.trainers :: [0] -- [4.34s] TRAIN epoch 35 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:37,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:38:37,390 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:38,088 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:38:42,437 :: INFO :: evodenss.train.trainers :: [0] -- [4.35s] TRAIN epoch 36 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:42,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:38:42,440 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:43,141 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:38:47,433 :: INFO :: evodenss.train.trainers :: [0] -- [4.29s] TRAIN epoch 37 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:47,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:38:47,436 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:48,124 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:38:52,584 :: INFO :: evodenss.train.trainers :: [0] -- [4.46s] TRAIN epoch 38 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:52,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:38:52,587 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:53,245 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:38:57,455 :: INFO :: evodenss.train.trainers :: [0] -- [4.21s] TRAIN epoch 39 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:38:57,458 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:38:57,458 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:38:58,942 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 331750,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 202.10915565490723,  n_epochs: 40,  total_epochs_trained: 40,  accuracy: None,  fitness: 0.12897,  losses: {'train_loss': [0.132, 0.12, 0.115, 0.112, 0.111, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.11, 0.109, 0.109, 0.108, 0.109, 0.108, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.109, 0.108, 0.109, 0.109], 'val_loss': [0.124, 0.108, 0.095, 0.117, 0.099, 0.173, 0.088, 0.092, 0.109, 0.096, 0.097, 0.1, 0.102, 0.096, 0.096, 0.108, 0.085, 0.101, 0.088, 0.093, 0.09, 0.106, 0.105, 0.086, 0.09, 0.086, 0.099, 0.104, 0.093, 0.087, 0.095, 0.096, 0.107, 0.112, 0.086, 0.117, 0.101, 0.085, 0.089, 0.108]}),  max_epochs_reached: False

2024-11-19 15:38:58,945 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.12897
2024-11-19 15:38:58,955 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-19 15:38:58,959 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:39 kernel_size:3 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 
layer7: :deconv1d out_channels:51 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.00022025587573835107 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50
2024-11-19 15:38:58,974 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:38:58,974 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:39:01,232 :: INFO :: evodenss.train.trainers :: [0] -- [2.26s] TRAIN epoch 0 -- loss: tensor([0.1811], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:01,235 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.181
2024-11-19 15:39:01,235 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:01,915 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:39:03,922 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 1 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:03,924 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:39:03,924 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:04,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:39:06,497 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 2 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:06,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:39:06,500 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:07,232 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:39:09,993 :: INFO :: evodenss.train.trainers :: [0] -- [2.76s] TRAIN epoch 3 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:09,996 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:39:09,996 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:10,673 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:39:12,789 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 4 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:12,792 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:39:12,792 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:13,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:39:15,618 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 5 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:15,623 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:39:15,623 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:16,291 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:39:18,204 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 6 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:18,207 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:18,207 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:18,862 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:39:21,154 :: INFO :: evodenss.train.trainers :: [0] -- [2.29s] TRAIN epoch 7 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:21,157 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:21,157 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:21,800 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:39:23,930 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 8 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:23,933 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:23,933 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:24,586 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:39:26,821 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 9 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:26,824 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:26,824 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:27,478 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:39:29,390 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 10 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:29,393 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:29,393 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:30,126 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:39:32,184 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 11 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:32,187 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:32,187 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:32,881 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:39:34,826 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 12 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:34,829 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:34,829 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:35,482 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:39:37,446 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 13 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:37,448 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:37,449 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:38,123 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:39:40,012 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 14 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:40,015 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:39:40,015 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:40,678 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:39:42,604 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 15 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:42,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:42,607 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:43,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:39:45,399 :: INFO :: evodenss.train.trainers :: [0] -- [2.13s] TRAIN epoch 16 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:45,401 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:45,401 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:46,052 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:39:48,079 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 17 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:48,082 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:48,082 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:48,752 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:39:50,788 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 18 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:50,790 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:50,791 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:51,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:39:53,566 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 19 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:53,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:53,569 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:54,231 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:39:56,283 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 20 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:56,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:56,286 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:56,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:39:59,225 :: INFO :: evodenss.train.trainers :: [0] -- [2.27s] TRAIN epoch 21 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:39:59,228 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:39:59,228 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:39:59,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:40:01,950 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 22 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:01,952 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:01,952 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:02,605 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:40:04,560 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 23 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:04,563 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:04,563 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:05,227 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:40:07,340 :: INFO :: evodenss.train.trainers :: [0] -- [2.11s] TRAIN epoch 24 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:07,343 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:07,343 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:08,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:40:10,178 :: INFO :: evodenss.train.trainers :: [0] -- [2.15s] TRAIN epoch 25 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:10,181 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:10,181 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:10,860 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:40:12,937 :: INFO :: evodenss.train.trainers :: [0] -- [2.08s] TRAIN epoch 26 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:12,950 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:12,950 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:13,653 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:40:15,852 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 27 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:15,855 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:15,855 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:16,517 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:40:18,493 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 28 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:18,497 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:18,497 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:19,155 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:40:21,162 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 29 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:21,165 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:21,165 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:21,865 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:40:23,961 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 30 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:23,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:23,964 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:24,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:40:26,786 :: INFO :: evodenss.train.trainers :: [0] -- [2.16s] TRAIN epoch 31 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:26,789 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:26,789 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:27,451 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:40:29,571 :: INFO :: evodenss.train.trainers :: [0] -- [2.12s] TRAIN epoch 32 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:29,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:29,574 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:30,224 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:40:32,452 :: INFO :: evodenss.train.trainers :: [0] -- [2.23s] TRAIN epoch 33 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:32,455 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:32,455 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:33,120 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:40:35,101 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 34 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:35,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:35,104 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:35,749 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:40:37,847 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 35 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:37,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:37,850 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:38,492 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:40:40,525 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 36 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:40,528 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:40,528 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:41,189 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:40:43,177 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 37 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:43,180 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:43,180 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:43,898 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:40:45,852 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 38 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:45,854 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:45,854 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:46,523 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:40:48,714 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 39 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:48,717 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:48,717 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:49,376 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:40:51,369 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 40 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:51,373 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:51,373 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:52,036 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:40:54,082 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 41 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:54,085 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:54,085 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:54,743 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:40:56,656 :: INFO :: evodenss.train.trainers :: [0] -- [1.91s] TRAIN epoch 42 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:56,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:56,659 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:40:57,318 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:40:59,392 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 43 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:40:59,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:40:59,396 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:00,047 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:41:01,894 :: INFO :: evodenss.train.trainers :: [0] -- [1.85s] TRAIN epoch 44 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:01,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:41:01,897 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:02,545 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:41:04,771 :: INFO :: evodenss.train.trainers :: [0] -- [2.22s] TRAIN epoch 45 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:04,774 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:41:04,774 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:05,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:41:07,652 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 46 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:07,654 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:41:07,654 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:08,308 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:41:10,283 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 47 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:10,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:41:10,286 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:10,947 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:41:13,137 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 48 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:13,140 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:41:13,140 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:13,789 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:41:15,788 :: INFO :: evodenss.train.trainers :: [0] -- [2.0s] TRAIN epoch 49 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:15,791 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:41:15,791 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:17,144 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 318019,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 138.18324542045593,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.16033,  losses: {'train_loss': [0.181, 0.112, 0.11, 0.109, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.13, 0.098, 0.093, 0.091, 0.089, 0.09, 0.089, 0.089, 0.089, 0.088, 0.089, 0.09, 0.088, 0.089, 0.09, 0.089, 0.09, 0.089, 0.091, 0.088, 0.09, 0.088, 0.09, 0.089, 0.088, 0.088, 0.088, 0.088, 0.088, 0.088, 0.09, 0.089, 0.089, 0.088, 0.087, 0.088, 0.09, 0.088, 0.088, 0.088, 0.09, 0.103, 0.088, 0.091, 0.089, 0.088, 0.092, 0.088, 0.091, 0.089]}),  max_epochs_reached: True

2024-11-19 15:41:17,147 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.16033
2024-11-19 15:41:17,150 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-19 15:41:17,154 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 2, id: 2
2024-11-19 15:41:17,157 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-19 15:41:17,160 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-19 15:41:17,171 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.18751, 3.77535, 0.12897, 0.16033]
2024-11-19 15:41:20,369 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1955], device='cuda:0')
2024-11-19 15:41:20,372 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 8: 0.12897
2024-11-19 15:41:20,376 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.12337



2024-11-19 15:41:20,461 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 9
2024-11-19 15:41:20,465 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-19 15:41:20,479 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:41:20,483 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 15:41:20,486 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:41:20,490 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-19 15:41:20,494 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:41:20,500 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 15:41:20,504 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:41:20,507 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:41:20,510 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:41:20,517 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 15:41:20,522 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:41:20,529 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:41:20,532 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 15:41:20,536 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-19 15:41:20,539 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:41:20,543 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:41:20,546 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:41:20,550 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 15:41:20,554 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:41:20,562 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-19 15:41:20,569 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-19 15:41:20,572 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:7 epochs:50
2024-11-19 15:41:20,586 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:41:20,586 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:41:25,116 :: INFO :: evodenss.train.trainers :: [0] -- [4.53s] TRAIN epoch 0 -- loss: tensor([0.1317], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:25,119 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.132
2024-11-19 15:41:25,119 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:25,804 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:41:30,170 :: INFO :: evodenss.train.trainers :: [0] -- [4.36s] TRAIN epoch 1 -- loss: tensor([0.1145], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:30,173 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:41:30,173 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:30,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:41:35,368 :: INFO :: evodenss.train.trainers :: [0] -- [4.47s] TRAIN epoch 2 -- loss: tensor([0.1131], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:35,371 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:41:35,371 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:36,066 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:41:40,549 :: INFO :: evodenss.train.trainers :: [0] -- [4.48s] TRAIN epoch 3 -- loss: tensor([0.1116], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:40,552 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:41:40,552 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:41,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:41:45,720 :: INFO :: evodenss.train.trainers :: [0] -- [4.48s] TRAIN epoch 4 -- loss: tensor([0.1147], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:45,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:41:45,723 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:46,412 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:41:51,066 :: INFO :: evodenss.train.trainers :: [0] -- [4.65s] TRAIN epoch 5 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:51,069 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:41:51,069 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:51,745 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:41:56,023 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 6 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:41:56,026 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:41:56,027 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:41:56,724 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:42:01,246 :: INFO :: evodenss.train.trainers :: [0] -- [4.52s] TRAIN epoch 7 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:01,248 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:01,248 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:01,948 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:42:06,432 :: INFO :: evodenss.train.trainers :: [0] -- [4.48s] TRAIN epoch 8 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:06,435 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:06,435 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:07,117 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:42:11,645 :: INFO :: evodenss.train.trainers :: [0] -- [4.53s] TRAIN epoch 9 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:11,647 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:11,648 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:12,354 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:42:16,753 :: INFO :: evodenss.train.trainers :: [0] -- [4.4s] TRAIN epoch 10 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:16,756 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:16,756 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:17,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:42:21,875 :: INFO :: evodenss.train.trainers :: [0] -- [4.41s] TRAIN epoch 11 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:21,877 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:21,878 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:22,561 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:42:26,886 :: INFO :: evodenss.train.trainers :: [0] -- [4.32s] TRAIN epoch 12 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:26,889 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:26,889 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:27,570 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:42:31,990 :: INFO :: evodenss.train.trainers :: [0] -- [4.42s] TRAIN epoch 13 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:31,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:42:31,993 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:32,683 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:42:36,930 :: INFO :: evodenss.train.trainers :: [0] -- [4.24s] TRAIN epoch 14 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:36,933 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:36,933 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:37,627 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:42:42,089 :: INFO :: evodenss.train.trainers :: [0] -- [4.46s] TRAIN epoch 15 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:42,092 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:42,092 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:42,775 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:42:47,081 :: INFO :: evodenss.train.trainers :: [0] -- [4.3s] TRAIN epoch 16 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:47,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:47,084 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:47,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:42:52,204 :: INFO :: evodenss.train.trainers :: [0] -- [4.43s] TRAIN epoch 17 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:52,207 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:42:52,207 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:52,903 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:42:57,309 :: INFO :: evodenss.train.trainers :: [0] -- [4.4s] TRAIN epoch 18 -- loss: tensor([0.1133], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:42:57,312 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:42:57,313 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:42:58,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:43:02,306 :: INFO :: evodenss.train.trainers :: [0] -- [4.3s] TRAIN epoch 19 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:02,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:43:02,309 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:02,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:43:07,420 :: INFO :: evodenss.train.trainers :: [0] -- [4.42s] TRAIN epoch 20 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:07,423 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:43:07,423 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:08,138 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:43:12,395 :: INFO :: evodenss.train.trainers :: [0] -- [4.26s] TRAIN epoch 21 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:12,398 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:43:12,398 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:13,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:43:17,370 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 22 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:17,373 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:43:17,373 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:18,065 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:43:22,456 :: INFO :: evodenss.train.trainers :: [0] -- [4.39s] TRAIN epoch 23 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:22,459 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:43:22,459 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:23,142 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:43:27,432 :: INFO :: evodenss.train.trainers :: [0] -- [4.29s] TRAIN epoch 24 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:27,435 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:43:27,435 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:28,116 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:43:32,553 :: INFO :: evodenss.train.trainers :: [0] -- [4.44s] TRAIN epoch 25 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:32,556 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:43:32,556 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:33,253 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:43:37,567 :: INFO :: evodenss.train.trainers :: [0] -- [4.31s] TRAIN epoch 26 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:37,570 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:43:37,570 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:38,272 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:43:42,555 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 27 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:42,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:43:42,558 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:43,259 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:43:47,811 :: INFO :: evodenss.train.trainers :: [0] -- [4.55s] TRAIN epoch 28 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:47,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:43:47,814 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:48,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:43:53,041 :: INFO :: evodenss.train.trainers :: [0] -- [4.54s] TRAIN epoch 29 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:53,044 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:43:53,044 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:53,743 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:43:57,982 :: INFO :: evodenss.train.trainers :: [0] -- [4.24s] TRAIN epoch 30 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:43:57,985 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:43:57,985 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:43:58,693 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:44:03,177 :: INFO :: evodenss.train.trainers :: [0] -- [4.48s] TRAIN epoch 31 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:03,180 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:44:03,180 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:03,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:44:08,156 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 32 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:08,158 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:44:08,159 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:08,862 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:44:13,089 :: INFO :: evodenss.train.trainers :: [0] -- [4.23s] TRAIN epoch 33 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:13,092 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:44:13,092 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:13,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:44:18,142 :: INFO :: evodenss.train.trainers :: [0] -- [4.36s] TRAIN epoch 34 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:18,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:44:18,145 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:18,810 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:44:23,169 :: INFO :: evodenss.train.trainers :: [0] -- [4.36s] TRAIN epoch 35 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:23,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:44:23,172 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:23,863 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:44:28,163 :: INFO :: evodenss.train.trainers :: [0] -- [4.3s] TRAIN epoch 36 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:28,165 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:44:28,165 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:28,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:44:33,292 :: INFO :: evodenss.train.trainers :: [0] -- [4.45s] TRAIN epoch 37 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:33,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:44:33,295 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:33,988 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:44:38,471 :: INFO :: evodenss.train.trainers :: [0] -- [4.48s] TRAIN epoch 38 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:38,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:44:38,475 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:39,158 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:44:43,464 :: INFO :: evodenss.train.trainers :: [0] -- [4.3s] TRAIN epoch 39 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:43,468 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:44:43,468 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:44,948 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 331750,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 204.37405443191528,  n_epochs: 40,  total_epochs_trained: 40,  accuracy: None,  fitness: 0.11614,  losses: {'train_loss': [0.132, 0.115, 0.113, 0.112, 0.115, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.109, 0.109, 0.113, 0.109, 0.109, 0.111, 0.108, 0.11, 0.108, 0.108, 0.109, 0.108, 0.109, 0.108, 0.109, 0.109, 0.109, 0.108, 0.108, 0.109, 0.108, 0.109, 0.109, 0.108], 'val_loss': [0.092, 0.092, 0.101, 0.126, 0.092, 0.097, 0.097, 0.089, 0.1, 0.092, 0.091, 0.086, 0.085, 0.088, 0.089, 0.088, 0.094, 0.11, 0.103, 0.096, 0.101, 0.097, 0.09, 0.09, 0.087, 0.096, 0.101, 0.098, 0.089, 0.092, 0.097, 0.087, 0.099, 0.088, 0.097, 0.087, 0.092, 0.093, 0.09, 0.094]}),  max_epochs_reached: False

2024-11-19 15:44:44,953 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.11614
2024-11-19 15:44:44,960 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-19 15:44:44,964 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:91 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.0009547108081147019 batch_size:7 epochs:50
2024-11-19 15:44:44,978 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:44:44,978 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:44:50,262 :: INFO :: evodenss.train.trainers :: [0] -- [5.28s] TRAIN epoch 0 -- loss: tensor([0.1312], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:50,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-19 15:44:50,265 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:50,987 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:44:56,067 :: INFO :: evodenss.train.trainers :: [0] -- [5.08s] TRAIN epoch 1 -- loss: tensor([0.1124], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:44:56,070 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:44:56,070 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:44:56,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:45:01,843 :: INFO :: evodenss.train.trainers :: [0] -- [5.04s] TRAIN epoch 2 -- loss: tensor([0.1119], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:01,846 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:45:01,846 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:02,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:45:07,629 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 3 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:07,632 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:45:07,632 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:08,326 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:45:13,416 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 4 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:13,419 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:45:13,419 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:14,142 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:45:19,213 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 5 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:19,216 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:45:19,216 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:19,888 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:45:25,078 :: INFO :: evodenss.train.trainers :: [0] -- [5.19s] TRAIN epoch 6 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:25,081 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:25,081 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:25,768 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:45:30,839 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 7 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:30,842 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:30,842 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:31,549 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:45:36,683 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 8 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:36,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:36,686 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:37,386 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:45:42,491 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 9 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:42,494 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:42,494 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:43,200 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:45:48,162 :: INFO :: evodenss.train.trainers :: [0] -- [4.96s] TRAIN epoch 10 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:48,165 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:48,166 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:48,880 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:45:53,996 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 11 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:53,998 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:53,998 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:45:54,695 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:45:59,847 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 12 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:45:59,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:45:59,850 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:00,564 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:46:05,599 :: INFO :: evodenss.train.trainers :: [0] -- [5.03s] TRAIN epoch 13 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:05,602 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:46:05,602 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:06,303 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:46:11,573 :: INFO :: evodenss.train.trainers :: [0] -- [5.27s] TRAIN epoch 14 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:11,576 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:46:11,576 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:12,286 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:46:17,439 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 15 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:17,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:46:17,442 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:18,150 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:46:23,247 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 16 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:23,250 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:46:23,250 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:23,935 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:46:28,939 :: INFO :: evodenss.train.trainers :: [0] -- [5.0s] TRAIN epoch 17 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:28,942 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:46:28,943 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:29,634 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:46:34,741 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 18 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:34,744 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:46:34,744 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:35,448 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:46:40,436 :: INFO :: evodenss.train.trainers :: [0] -- [4.99s] TRAIN epoch 19 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:40,439 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:46:40,439 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:41,144 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:46:46,074 :: INFO :: evodenss.train.trainers :: [0] -- [4.93s] TRAIN epoch 20 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:46,077 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:46:46,077 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:46,805 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:46:51,841 :: INFO :: evodenss.train.trainers :: [0] -- [5.03s] TRAIN epoch 21 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:51,844 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:46:51,844 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:52,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:46:57,611 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 22 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:46:57,614 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:46:57,614 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:46:58,315 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:47:03,324 :: INFO :: evodenss.train.trainers :: [0] -- [5.01s] TRAIN epoch 23 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:03,327 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:03,327 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:04,031 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:47:09,144 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 24 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:09,147 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:09,147 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:09,869 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:47:14,952 :: INFO :: evodenss.train.trainers :: [0] -- [5.08s] TRAIN epoch 25 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:14,955 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:14,955 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:15,656 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:47:20,773 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 26 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:20,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:47:20,776 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:21,474 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:47:26,574 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 27 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:26,577 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:26,577 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:27,287 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:47:32,340 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 28 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:32,343 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:32,343 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:33,053 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:47:38,108 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 29 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:38,110 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:47:38,110 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:38,796 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:47:43,838 :: INFO :: evodenss.train.trainers :: [0] -- [5.04s] TRAIN epoch 30 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:43,841 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:43,841 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:44,565 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:47:49,776 :: INFO :: evodenss.train.trainers :: [0] -- [5.21s] TRAIN epoch 31 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:49,779 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:49,779 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:50,471 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:47:55,511 :: INFO :: evodenss.train.trainers :: [0] -- [5.04s] TRAIN epoch 32 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:47:55,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:47:55,514 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:47:56,232 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:48:01,296 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 33 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:01,298 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:48:01,298 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:02,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:48:07,015 :: INFO :: evodenss.train.trainers :: [0] -- [5.0s] TRAIN epoch 34 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:07,017 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:48:07,017 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:08,545 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 334325,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 203.5795168876648,  n_epochs: 35,  total_epochs_trained: 35,  accuracy: None,  fitness: 0.10763,  losses: {'train_loss': [0.131, 0.112, 0.112, 0.111, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.108, 0.109, 0.109, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.109, 0.108, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108], 'val_loss': [0.089, 0.097, 0.086, 0.091, 0.086, 0.087, 0.112, 0.086, 0.086, 0.109, 0.088, 0.088, 0.087, 0.087, 0.088, 0.086, 0.086, 0.088, 0.086, 0.086, 0.088, 0.087, 0.087, 0.088, 0.086, 0.088, 0.086, 0.087, 0.087, 0.087, 0.087, 0.089, 0.088, 0.087, 0.088]}),  max_epochs_reached: False

2024-11-19 15:48:08,548 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.10763
2024-11-19 15:48:08,556 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-19 15:48:08,560 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:90 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 
layer8: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:11 
layer14: :fc act:selu out_features:200 bias:True input:12 learning:gradient_descent lr:0.0006449537531992261 momentum:0.7210708023882153 weight_decay:0.0009547108081147019 nesterov:False batch_size:7 epochs:50
2024-11-19 15:48:08,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:48:08,574 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:48:12,967 :: INFO :: evodenss.train.trainers :: [0] -- [4.39s] TRAIN epoch 0 -- loss: tensor([0.4161], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:12,970 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.416
2024-11-19 15:48:12,971 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:13,665 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:48:17,798 :: INFO :: evodenss.train.trainers :: [0] -- [4.13s] TRAIN epoch 1 -- loss: tensor([0.1742], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:17,800 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.174
2024-11-19 15:48:17,801 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:18,489 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:48:22,653 :: INFO :: evodenss.train.trainers :: [0] -- [4.16s] TRAIN epoch 2 -- loss: tensor([0.1401], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:22,656 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.14
2024-11-19 15:48:22,656 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:23,351 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:48:27,557 :: INFO :: evodenss.train.trainers :: [0] -- [4.2s] TRAIN epoch 3 -- loss: tensor([0.1307], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:27,560 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-19 15:48:27,560 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:28,254 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:48:32,461 :: INFO :: evodenss.train.trainers :: [0] -- [4.21s] TRAIN epoch 4 -- loss: tensor([0.1267], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:32,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.127
2024-11-19 15:48:32,464 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:33,177 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:48:37,359 :: INFO :: evodenss.train.trainers :: [0] -- [4.18s] TRAIN epoch 5 -- loss: tensor([0.1242], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:37,366 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.124
2024-11-19 15:48:37,366 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:38,068 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:48:42,145 :: INFO :: evodenss.train.trainers :: [0] -- [4.07s] TRAIN epoch 6 -- loss: tensor([0.1221], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:42,148 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-19 15:48:42,148 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:42,845 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:48:47,018 :: INFO :: evodenss.train.trainers :: [0] -- [4.17s] TRAIN epoch 7 -- loss: tensor([0.1204], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:47,021 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.12
2024-11-19 15:48:47,021 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:47,707 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:48:51,803 :: INFO :: evodenss.train.trainers :: [0] -- [4.09s] TRAIN epoch 8 -- loss: tensor([0.1195], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:51,806 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.119
2024-11-19 15:48:51,806 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:52,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:48:56,667 :: INFO :: evodenss.train.trainers :: [0] -- [4.16s] TRAIN epoch 9 -- loss: tensor([0.1185], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:48:56,670 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-19 15:48:56,670 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:48:57,355 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:49:01,546 :: INFO :: evodenss.train.trainers :: [0] -- [4.19s] TRAIN epoch 10 -- loss: tensor([0.1177], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:01,549 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-19 15:49:01,549 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:02,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:49:06,270 :: INFO :: evodenss.train.trainers :: [0] -- [4.03s] TRAIN epoch 11 -- loss: tensor([0.1172], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:06,273 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.117
2024-11-19 15:49:06,273 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:06,940 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:49:11,078 :: INFO :: evodenss.train.trainers :: [0] -- [4.14s] TRAIN epoch 12 -- loss: tensor([0.1163], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:11,082 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-19 15:49:11,082 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:11,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:49:15,961 :: INFO :: evodenss.train.trainers :: [0] -- [4.18s] TRAIN epoch 13 -- loss: tensor([0.1161], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:15,964 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-19 15:49:15,964 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:16,654 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:49:20,954 :: INFO :: evodenss.train.trainers :: [0] -- [4.3s] TRAIN epoch 14 -- loss: tensor([0.1154], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:20,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:49:20,957 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:21,654 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:49:25,828 :: INFO :: evodenss.train.trainers :: [0] -- [4.17s] TRAIN epoch 15 -- loss: tensor([0.1152], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:25,831 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:49:25,831 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:26,537 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:49:30,620 :: INFO :: evodenss.train.trainers :: [0] -- [4.08s] TRAIN epoch 16 -- loss: tensor([0.1145], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:30,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.115
2024-11-19 15:49:30,622 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:31,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:49:35,384 :: INFO :: evodenss.train.trainers :: [0] -- [4.09s] TRAIN epoch 17 -- loss: tensor([0.1142], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:35,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:49:35,388 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:36,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:49:40,306 :: INFO :: evodenss.train.trainers :: [0] -- [4.22s] TRAIN epoch 18 -- loss: tensor([0.1140], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:40,308 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:49:40,309 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:40,982 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:49:45,254 :: INFO :: evodenss.train.trainers :: [0] -- [4.27s] TRAIN epoch 19 -- loss: tensor([0.1136], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:45,257 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.114
2024-11-19 15:49:45,257 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:45,939 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:49:50,068 :: INFO :: evodenss.train.trainers :: [0] -- [4.13s] TRAIN epoch 20 -- loss: tensor([0.1134], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:50,071 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:49:50,071 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:50,772 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:49:54,971 :: INFO :: evodenss.train.trainers :: [0] -- [4.2s] TRAIN epoch 21 -- loss: tensor([0.1130], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:54,974 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:49:54,974 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:49:55,655 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:49:59,916 :: INFO :: evodenss.train.trainers :: [0] -- [4.26s] TRAIN epoch 22 -- loss: tensor([0.1133], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:49:59,918 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:49:59,919 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:00,630 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:50:04,710 :: INFO :: evodenss.train.trainers :: [0] -- [4.08s] TRAIN epoch 23 -- loss: tensor([0.1127], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:04,713 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:50:04,713 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:05,412 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:50:09,476 :: INFO :: evodenss.train.trainers :: [0] -- [4.06s] TRAIN epoch 24 -- loss: tensor([0.1126], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:09,479 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:50:09,479 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:10,148 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:50:14,397 :: INFO :: evodenss.train.trainers :: [0] -- [4.25s] TRAIN epoch 25 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:14,400 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:50:14,400 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:15,090 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:50:19,154 :: INFO :: evodenss.train.trainers :: [0] -- [4.06s] TRAIN epoch 26 -- loss: tensor([0.1121], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:19,156 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:50:19,157 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:19,843 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:50:23,881 :: INFO :: evodenss.train.trainers :: [0] -- [4.04s] TRAIN epoch 27 -- loss: tensor([0.1121], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:23,884 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:50:23,884 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:24,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:50:28,623 :: INFO :: evodenss.train.trainers :: [0] -- [4.03s] TRAIN epoch 28 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:28,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:50:28,626 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:29,322 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:50:33,393 :: INFO :: evodenss.train.trainers :: [0] -- [4.07s] TRAIN epoch 29 -- loss: tensor([0.1117], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:33,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:50:33,396 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:34,070 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:50:38,217 :: INFO :: evodenss.train.trainers :: [0] -- [4.15s] TRAIN epoch 30 -- loss: tensor([0.1115], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:38,222 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:50:38,222 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:38,897 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:50:43,036 :: INFO :: evodenss.train.trainers :: [0] -- [4.14s] TRAIN epoch 31 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:43,039 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:50:43,039 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:43,709 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:50:47,939 :: INFO :: evodenss.train.trainers :: [0] -- [4.23s] TRAIN epoch 32 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:47,942 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:50:47,942 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:48,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:50:52,970 :: INFO :: evodenss.train.trainers :: [0] -- [4.34s] TRAIN epoch 33 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:52,973 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:50:52,973 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:53,666 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:50:57,825 :: INFO :: evodenss.train.trainers :: [0] -- [4.16s] TRAIN epoch 34 -- loss: tensor([0.1111], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:50:57,828 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:50:57,828 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:50:58,490 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:51:02,684 :: INFO :: evodenss.train.trainers :: [0] -- [4.19s] TRAIN epoch 35 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:02,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:51:02,687 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:03,359 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:51:07,807 :: INFO :: evodenss.train.trainers :: [0] -- [4.45s] TRAIN epoch 36 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:07,809 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:51:07,809 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:08,497 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:51:12,497 :: INFO :: evodenss.train.trainers :: [0] -- [4.0s] TRAIN epoch 37 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:12,500 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:51:12,500 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:13,192 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:51:17,341 :: INFO :: evodenss.train.trainers :: [0] -- [4.15s] TRAIN epoch 38 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:17,345 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:51:17,345 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:18,011 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:51:22,285 :: INFO :: evodenss.train.trainers :: [0] -- [4.27s] TRAIN epoch 39 -- loss: tensor([0.1105], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:22,288 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:51:22,288 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:22,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:51:27,179 :: INFO :: evodenss.train.trainers :: [0] -- [4.19s] TRAIN epoch 40 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:27,182 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:51:27,182 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:27,861 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:51:32,012 :: INFO :: evodenss.train.trainers :: [0] -- [4.15s] TRAIN epoch 41 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:32,015 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:51:32,015 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:33,500 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 272221,  n_layers: 14,  n_layers_projector: -1,  training_time_spent: 204.9372842311859,  n_epochs: 42,  total_epochs_trained: 42,  accuracy: None,  fitness: 1.56131,  losses: {'train_loss': [0.416, 0.174, 0.14, 0.131, 0.127, 0.124, 0.122, 0.12, 0.119, 0.118, 0.118, 0.117, 0.116, 0.116, 0.115, 0.115, 0.115, 0.114, 0.114, 0.114, 0.113, 0.113, 0.113, 0.113, 0.113, 0.113, 0.112, 0.112, 0.112, 0.112, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11], 'val_loss': [0.155, 0.122, 0.121, 0.121, 0.117, 0.115, 0.114, 0.113, 0.112, 0.11, 0.11, 0.11, 0.108, 0.108, 0.107, 0.106, 0.106, 0.106, 0.105, 0.104, 0.104, 0.105, 0.105, 0.104, 0.103, 0.103, 0.102, 0.103, 0.102, 0.102, 0.102, 0.102, 0.101, 0.101, 0.101, 0.101, 0.1, 0.101, 0.1, 0.101, 0.1, 0.101]}),  max_epochs_reached: False

2024-11-19 15:51:33,504 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 1.56131
2024-11-19 15:51:33,512 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-19 15:51:33,516 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:78 kernel_size:2 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:13 kernel_size:3 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:44 epochs:50
2024-11-19 15:51:33,533 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:51:33,534 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:51:35,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 0 -- loss: tensor([0.2340], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:35,705 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.234
2024-11-19 15:51:35,705 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:36,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:51:38,370 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 1 -- loss: tensor([0.1182], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:38,373 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.118
2024-11-19 15:51:38,373 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:39,066 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:51:41,242 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 2 -- loss: tensor([0.1116], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:41,245 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:51:41,245 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:41,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:51:44,253 :: INFO :: evodenss.train.trainers :: [0] -- [2.33s] TRAIN epoch 3 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:44,255 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:51:44,256 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:45,041 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:51:47,232 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 4 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:47,235 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:51:47,235 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:47,932 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:51:50,254 :: INFO :: evodenss.train.trainers :: [0] -- [2.32s] TRAIN epoch 5 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:50,257 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:51:50,257 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:51,033 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:51:53,343 :: INFO :: evodenss.train.trainers :: [0] -- [2.31s] TRAIN epoch 6 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:53,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:51:53,346 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:54,042 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:51:55,798 :: INFO :: evodenss.train.trainers :: [0] -- [1.75s] TRAIN epoch 7 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:55,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:51:55,801 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:56,497 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:51:58,555 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 8 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:51:58,558 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:51:58,558 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:51:59,261 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:52:01,333 :: INFO :: evodenss.train.trainers :: [0] -- [2.07s] TRAIN epoch 9 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:01,336 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:01,336 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:02,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:52:04,065 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 10 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:04,068 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:04,068 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:04,781 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:52:06,873 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 11 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:06,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:06,876 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:07,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:52:09,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 12 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:09,705 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:09,705 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:10,401 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:52:12,598 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 13 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:12,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:12,601 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:13,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:52:15,509 :: INFO :: evodenss.train.trainers :: [0] -- [2.21s] TRAIN epoch 14 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:15,512 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:15,512 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:16,220 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:52:18,253 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 15 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:18,255 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:52:18,255 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:18,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:52:20,995 :: INFO :: evodenss.train.trainers :: [0] -- [2.03s] TRAIN epoch 16 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:20,997 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:20,998 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:21,695 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:52:23,702 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 17 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:23,705 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:23,705 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:24,463 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:52:26,480 :: INFO :: evodenss.train.trainers :: [0] -- [2.01s] TRAIN epoch 18 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:26,483 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:26,483 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:27,171 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:52:29,167 :: INFO :: evodenss.train.trainers :: [0] -- [1.99s] TRAIN epoch 19 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:29,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:29,169 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:29,971 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:52:32,294 :: INFO :: evodenss.train.trainers :: [0] -- [2.32s] TRAIN epoch 20 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:32,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:32,297 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:32,988 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:52:34,945 :: INFO :: evodenss.train.trainers :: [0] -- [1.96s] TRAIN epoch 21 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:34,948 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:34,948 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:35,638 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:52:37,809 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 22 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:37,812 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:52:37,812 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:38,529 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:52:40,475 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 23 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:40,478 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:40,478 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:41,190 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:52:43,371 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 24 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:43,375 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:43,375 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:44,073 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:52:46,051 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 25 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:46,054 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:46,054 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:46,829 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:52:48,921 :: INFO :: evodenss.train.trainers :: [0] -- [2.09s] TRAIN epoch 26 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:48,931 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:48,931 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:49,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:52:51,660 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 27 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:51,663 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:51,663 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:52,354 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:52:54,392 :: INFO :: evodenss.train.trainers :: [0] -- [2.04s] TRAIN epoch 28 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:54,395 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:52:54,395 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:55,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:52:57,034 :: INFO :: evodenss.train.trainers :: [0] -- [1.95s] TRAIN epoch 29 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:57,037 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:57,037 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:52:57,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:52:59,708 :: INFO :: evodenss.train.trainers :: [0] -- [1.98s] TRAIN epoch 30 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:52:59,711 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:52:59,711 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:00,409 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:53:02,471 :: INFO :: evodenss.train.trainers :: [0] -- [2.06s] TRAIN epoch 31 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:02,474 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:02,474 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:03,170 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:53:05,060 :: INFO :: evodenss.train.trainers :: [0] -- [1.89s] TRAIN epoch 32 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:05,063 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:53:05,063 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:05,825 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:53:07,876 :: INFO :: evodenss.train.trainers :: [0] -- [2.05s] TRAIN epoch 33 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:07,879 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:07,879 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:08,566 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:53:10,591 :: INFO :: evodenss.train.trainers :: [0] -- [2.02s] TRAIN epoch 34 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:10,594 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:10,594 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:11,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 15:53:13,299 :: INFO :: evodenss.train.trainers :: [0] -- [1.97s] TRAIN epoch 35 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:13,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:53:13,301 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:14,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 15:53:16,282 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 36 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:16,285 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 15:53:16,285 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:16,978 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 15:53:19,286 :: INFO :: evodenss.train.trainers :: [0] -- [2.31s] TRAIN epoch 37 -- loss: tensor([0.1060], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:19,289 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:19,289 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:19,980 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 15:53:22,183 :: INFO :: evodenss.train.trainers :: [0] -- [2.2s] TRAIN epoch 38 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:22,186 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:22,186 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:22,877 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 15:53:24,761 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 39 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:24,764 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:24,764 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:25,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 15:53:27,371 :: INFO :: evodenss.train.trainers :: [0] -- [1.92s] TRAIN epoch 40 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:27,374 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:27,374 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:28,062 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 15:53:30,248 :: INFO :: evodenss.train.trainers :: [0] -- [2.18s] TRAIN epoch 41 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:30,251 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:30,251 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:30,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 15:53:32,818 :: INFO :: evodenss.train.trainers :: [0] -- [1.87s] TRAIN epoch 42 -- loss: tensor([0.1063], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:32,821 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:32,821 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:33,510 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 15:53:35,450 :: INFO :: evodenss.train.trainers :: [0] -- [1.94s] TRAIN epoch 43 -- loss: tensor([0.1062], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:35,456 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:35,456 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:36,152 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 15:53:37,963 :: INFO :: evodenss.train.trainers :: [0] -- [1.81s] TRAIN epoch 44 -- loss: tensor([0.1059], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:37,965 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:37,965 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:38,663 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 15:53:40,855 :: INFO :: evodenss.train.trainers :: [0] -- [2.19s] TRAIN epoch 45 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:40,858 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:40,858 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:41,545 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 15:53:43,786 :: INFO :: evodenss.train.trainers :: [0] -- [2.24s] TRAIN epoch 46 -- loss: tensor([0.1064], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:43,788 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:43,789 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:44,542 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 15:53:46,427 :: INFO :: evodenss.train.trainers :: [0] -- [1.88s] TRAIN epoch 47 -- loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:46,430 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:46,430 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:47,130 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 15:53:49,305 :: INFO :: evodenss.train.trainers :: [0] -- [2.17s] TRAIN epoch 48 -- loss: tensor([0.1058], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:49,308 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:49,308 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:50,014 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 15:53:52,114 :: INFO :: evodenss.train.trainers :: [0] -- [2.1s] TRAIN epoch 49 -- loss: tensor([0.1057], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:53:52,117 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 15:53:52,118 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:53:53,622 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 277442,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 140.10346221923828,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.13514,  losses: {'train_loss': [0.234, 0.118, 0.112, 0.11, 0.108, 0.108, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.111, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.108, 0.106, 0.107, 0.106, 0.107, 0.106, 0.107, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106], 'val_loss': [0.118, 0.092, 0.089, 0.089, 0.089, 0.094, 0.089, 0.088, 0.092, 0.105, 0.092, 0.09, 0.092, 0.095, 0.089, 0.09, 0.088, 0.097, 0.096, 0.097, 0.089, 0.096, 0.175, 0.1, 0.091, 0.089, 0.088, 0.089, 0.088, 0.099, 0.088, 0.092, 0.088, 0.089, 0.089, 0.088, 0.092, 0.091, 0.089, 0.094, 0.089, 0.092, 0.089, 0.098, 0.095, 0.09, 0.088, 0.091, 0.089, 0.089]}),  max_epochs_reached: True

2024-11-19 15:53:53,625 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.13514
2024-11-19 15:53:53,628 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-19 15:53:53,632 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 1, id: 1
2024-11-19 15:53:53,635 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-19 15:53:53,638 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-19 15:53:53,645 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.11614, 0.10763, 1.56131, 0.13514]
2024-11-19 15:53:57,173 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1742], device='cuda:0')
2024-11-19 15:53:57,176 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 9: 0.10763
2024-11-19 15:53:57,181 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.10763



2024-11-19 15:53:57,269 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 10
2024-11-19 15:53:57,272 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-19 15:53:57,289 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 15:53:57,294 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:53:57,298 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 15:53:57,302 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-19 15:53:57,306 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:53:57,313 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:53:57,317 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 14
2024-11-19 15:53:57,321 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:53:57,328 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: True
2024-11-19 15:53:57,332 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 15:53:57,336 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:53:57,340 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-19 15:53:57,343 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:53:57,350 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 15:53:57,354 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 15:53:57,358 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 15:53:57,361 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 15:53:57,365 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 14
2024-11-19 15:53:57,368 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 15:53:57,374 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-19 15:53:57,381 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-19 15:53:57,384 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:91 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.0009547108081147019 batch_size:7 epochs:50
2024-11-19 15:53:57,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:53:57,399 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:54:02,629 :: INFO :: evodenss.train.trainers :: [0] -- [5.23s] TRAIN epoch 0 -- loss: tensor([0.1312], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:02,632 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-19 15:54:02,632 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:03,325 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:54:08,262 :: INFO :: evodenss.train.trainers :: [0] -- [4.94s] TRAIN epoch 1 -- loss: tensor([0.1123], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:08,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:54:08,265 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:08,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:54:14,021 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 2 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:14,024 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:54:14,024 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:14,738 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:54:19,794 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 3 -- loss: tensor([0.1107], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:19,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:54:19,797 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:20,492 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:54:25,498 :: INFO :: evodenss.train.trainers :: [0] -- [5.0s] TRAIN epoch 4 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:25,501 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:54:25,501 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:26,216 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:54:31,371 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 5 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:31,374 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:54:31,374 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:32,047 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:54:37,216 :: INFO :: evodenss.train.trainers :: [0] -- [5.17s] TRAIN epoch 6 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:37,218 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:54:37,218 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:37,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:54:42,836 :: INFO :: evodenss.train.trainers :: [0] -- [4.92s] TRAIN epoch 7 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:42,840 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:54:42,840 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:43,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:54:48,758 :: INFO :: evodenss.train.trainers :: [0] -- [5.2s] TRAIN epoch 8 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:48,761 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:54:48,761 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:49,481 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:54:54,569 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 9 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:54:54,572 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:54:54,572 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:54:55,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:55:00,408 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 10 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:00,411 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:00,411 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:01,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:55:06,262 :: INFO :: evodenss.train.trainers :: [0] -- [5.14s] TRAIN epoch 11 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:06,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:55:06,265 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:06,954 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:55:12,047 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 12 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:12,050 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:55:12,050 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:12,756 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:55:17,966 :: INFO :: evodenss.train.trainers :: [0] -- [5.21s] TRAIN epoch 13 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:17,969 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:17,969 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:18,676 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:55:23,562 :: INFO :: evodenss.train.trainers :: [0] -- [4.88s] TRAIN epoch 14 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:23,565 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:55:23,565 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:24,262 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:55:29,320 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 15 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:29,324 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:29,324 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:30,005 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:55:34,978 :: INFO :: evodenss.train.trainers :: [0] -- [4.97s] TRAIN epoch 16 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:34,981 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:34,981 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:35,684 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:55:40,823 :: INFO :: evodenss.train.trainers :: [0] -- [5.14s] TRAIN epoch 17 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:40,826 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:40,826 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:41,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:55:46,682 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 18 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:46,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:46,685 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:47,384 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:55:52,544 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 19 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:52,547 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:55:52,547 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:53,258 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:55:58,329 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 20 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:55:58,331 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:55:58,331 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:55:59,040 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:56:04,104 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 21 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:04,107 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:04,108 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:04,799 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:56:09,918 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 22 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:09,921 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:56:09,921 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:10,636 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:56:16,061 :: INFO :: evodenss.train.trainers :: [0] -- [5.42s] TRAIN epoch 23 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:16,064 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:16,064 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:16,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:56:21,901 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 24 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:21,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:56:21,904 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:22,596 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:56:27,604 :: INFO :: evodenss.train.trainers :: [0] -- [5.01s] TRAIN epoch 25 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:27,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:27,607 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:28,326 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:56:33,512 :: INFO :: evodenss.train.trainers :: [0] -- [5.18s] TRAIN epoch 26 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:33,515 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:33,515 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:34,214 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 15:56:39,270 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 27 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:39,273 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:39,273 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:39,990 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 15:56:44,960 :: INFO :: evodenss.train.trainers :: [0] -- [4.97s] TRAIN epoch 28 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:44,963 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:44,963 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:45,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 15:56:50,683 :: INFO :: evodenss.train.trainers :: [0] -- [4.99s] TRAIN epoch 29 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:50,687 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:50,687 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:51,378 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 15:56:56,430 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 30 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:56:56,434 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:56:56,434 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:56:57,132 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 15:57:02,202 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 31 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:02,205 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:57:02,205 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:02,915 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 15:57:08,028 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 32 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:08,031 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:57:08,031 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:08,747 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 15:57:13,860 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 33 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:13,863 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:57:13,863 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:14,598 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 15:57:19,685 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 34 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:19,688 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:57:19,688 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:21,206 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 334325,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 203.8196406364441,  n_epochs: 35,  total_epochs_trained: 35,  accuracy: None,  fitness: 0.10707,  losses: {'train_loss': [0.131, 0.112, 0.111, 0.111, 0.109, 0.109, 0.108, 0.108, 0.109, 0.109, 0.108, 0.109, 0.109, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.109, 0.108, 0.109, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.109, 0.108, 0.108], 'val_loss': [0.09, 0.091, 0.088, 0.098, 0.09, 0.091, 0.087, 0.087, 0.089, 0.086, 0.089, 0.089, 0.088, 0.087, 0.087, 0.086, 0.086, 0.086, 0.088, 0.086, 0.087, 0.087, 0.087, 0.088, 0.087, 0.088, 0.086, 0.087, 0.087, 0.087, 0.087, 0.086, 0.088, 0.087, 0.087]}),  max_epochs_reached: False

2024-11-19 15:57:21,210 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.10707
2024-11-19 15:57:21,218 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-19 15:57:21,221 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000867475404773022 batch_size:7 epochs:50
2024-11-19 15:57:21,236 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 15:57:21,236 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 15:57:26,681 :: INFO :: evodenss.train.trainers :: [0] -- [5.44s] TRAIN epoch 0 -- loss: tensor([0.1296], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:26,684 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.13
2024-11-19 15:57:26,684 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:27,415 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 15:57:32,701 :: INFO :: evodenss.train.trainers :: [0] -- [5.28s] TRAIN epoch 1 -- loss: tensor([0.1128], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:32,704 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 15:57:32,704 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:33,420 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 15:57:38,620 :: INFO :: evodenss.train.trainers :: [0] -- [5.2s] TRAIN epoch 2 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:38,623 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 15:57:38,623 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:39,308 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 15:57:44,471 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 3 -- loss: tensor([0.1109], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:44,474 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 15:57:44,474 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:45,175 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 15:57:50,410 :: INFO :: evodenss.train.trainers :: [0] -- [5.23s] TRAIN epoch 4 -- loss: tensor([0.1100], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:50,417 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 15:57:50,417 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:51,125 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 15:57:56,179 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 5 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:57:56,182 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:57:56,182 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:57:56,892 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 15:58:02,130 :: INFO :: evodenss.train.trainers :: [0] -- [5.24s] TRAIN epoch 6 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:02,137 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:58:02,137 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:02,834 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 15:58:07,964 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 7 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:07,967 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:58:07,967 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:08,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 15:58:13,910 :: INFO :: evodenss.train.trainers :: [0] -- [5.22s] TRAIN epoch 8 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:13,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:58:13,913 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:14,634 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 15:58:19,755 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 9 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:19,758 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:58:19,758 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:20,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 15:58:25,675 :: INFO :: evodenss.train.trainers :: [0] -- [5.21s] TRAIN epoch 10 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:25,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:58:25,694 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:26,405 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 15:58:31,488 :: INFO :: evodenss.train.trainers :: [0] -- [5.08s] TRAIN epoch 11 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:31,491 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:58:31,491 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:32,172 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 15:58:37,344 :: INFO :: evodenss.train.trainers :: [0] -- [5.17s] TRAIN epoch 12 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:37,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:58:37,346 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:38,046 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 15:58:43,075 :: INFO :: evodenss.train.trainers :: [0] -- [5.03s] TRAIN epoch 13 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:43,077 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:58:43,077 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:43,765 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 15:58:48,954 :: INFO :: evodenss.train.trainers :: [0] -- [5.19s] TRAIN epoch 14 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:48,957 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:58:48,957 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:49,671 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 15:58:54,903 :: INFO :: evodenss.train.trainers :: [0] -- [5.23s] TRAIN epoch 15 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:58:54,906 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:58:54,906 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:58:55,608 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 15:59:00,691 :: INFO :: evodenss.train.trainers :: [0] -- [5.08s] TRAIN epoch 16 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:00,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:59:00,694 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:01,408 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 15:59:06,582 :: INFO :: evodenss.train.trainers :: [0] -- [5.17s] TRAIN epoch 17 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:06,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:06,584 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:07,279 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 15:59:12,440 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 18 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:12,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:12,442 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:13,145 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 15:59:18,221 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 19 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:18,224 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:18,224 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:18,932 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 15:59:24,115 :: INFO :: evodenss.train.trainers :: [0] -- [5.18s] TRAIN epoch 20 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:24,118 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:24,118 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:24,819 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 15:59:29,932 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 21 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:29,935 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 15:59:29,935 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:30,635 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 15:59:35,783 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 22 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:35,786 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:35,786 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:36,486 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 15:59:41,598 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 23 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:41,601 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:41,601 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:42,296 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 15:59:47,494 :: INFO :: evodenss.train.trainers :: [0] -- [5.2s] TRAIN epoch 24 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:47,496 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:47,497 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:48,219 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 15:59:53,443 :: INFO :: evodenss.train.trainers :: [0] -- [5.22s] TRAIN epoch 25 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:53,445 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:53,445 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:54,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 15:59:59,298 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 26 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 15:59:59,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 15:59:59,301 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 15:59:59,995 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 16:00:05,123 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 27 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:05,125 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:05,125 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:05,865 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 16:00:11,076 :: INFO :: evodenss.train.trainers :: [0] -- [5.21s] TRAIN epoch 28 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:11,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:11,080 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:11,801 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 16:00:16,981 :: INFO :: evodenss.train.trainers :: [0] -- [5.18s] TRAIN epoch 29 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:16,984 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:16,984 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:17,685 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 16:00:22,774 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 30 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:22,777 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:22,777 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:23,499 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 16:00:28,633 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 31 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:28,636 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:28,636 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:29,348 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 16:00:34,449 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 32 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:34,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:34,452 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:35,195 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 16:00:40,306 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 33 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:40,309 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:40,309 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:41,042 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 16:00:46,121 :: INFO :: evodenss.train.trainers :: [0] -- [5.08s] TRAIN epoch 34 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:46,124 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:00:46,124 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:47,655 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 344192,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 206.4308841228485,  n_epochs: 35,  total_epochs_trained: 35,  accuracy: None,  fitness: 0.10611,  losses: {'train_loss': [0.13, 0.113, 0.112, 0.111, 0.11, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108], 'val_loss': [0.098, 0.108, 0.088, 0.088, 0.087, 0.087, 0.09, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.087, 0.087, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.087, 0.086, 0.088, 0.086, 0.086, 0.086, 0.087, 0.087, 0.086, 0.086, 0.087, 0.086]}),  max_epochs_reached: False

2024-11-19 16:00:47,657 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.10611
2024-11-19 16:00:47,666 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-19 16:00:47,670 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:91 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:9 
layer12: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 
layer15: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:13 
layer16: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:14 
layer17: :fc act:selu out_features:200 bias:True input:15 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.0009547108081147019 batch_size:13 epochs:50
2024-11-19 16:00:47,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:00:47,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:00:51,159 :: INFO :: evodenss.train.trainers :: [0] -- [3.47s] TRAIN epoch 0 -- loss: tensor([0.1432], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:51,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.143
2024-11-19 16:00:51,162 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:51,864 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:00:55,066 :: INFO :: evodenss.train.trainers :: [0] -- [3.2s] TRAIN epoch 1 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:55,069 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 16:00:55,069 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:55,755 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:00:58,906 :: INFO :: evodenss.train.trainers :: [0] -- [3.15s] TRAIN epoch 2 -- loss: tensor([0.1106], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:00:58,908 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:00:58,908 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:00:59,599 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:01:02,573 :: INFO :: evodenss.train.trainers :: [0] -- [2.97s] TRAIN epoch 3 -- loss: tensor([0.1104], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:02,575 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:01:02,576 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:03,270 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:01:06,431 :: INFO :: evodenss.train.trainers :: [0] -- [3.16s] TRAIN epoch 4 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:06,434 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:01:06,434 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:07,129 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:01:10,193 :: INFO :: evodenss.train.trainers :: [0] -- [3.06s] TRAIN epoch 5 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:10,196 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:01:10,196 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:10,861 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:01:13,923 :: INFO :: evodenss.train.trainers :: [0] -- [3.06s] TRAIN epoch 6 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:13,926 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:01:13,926 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:14,592 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:01:17,745 :: INFO :: evodenss.train.trainers :: [0] -- [3.15s] TRAIN epoch 7 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:17,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:01:17,748 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:18,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:01:21,568 :: INFO :: evodenss.train.trainers :: [0] -- [3.13s] TRAIN epoch 8 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:21,572 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:01:21,572 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:22,241 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:01:25,362 :: INFO :: evodenss.train.trainers :: [0] -- [3.12s] TRAIN epoch 9 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:25,367 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:01:25,367 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:26,065 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:01:29,298 :: INFO :: evodenss.train.trainers :: [0] -- [3.23s] TRAIN epoch 10 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:29,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:01:29,301 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:30,011 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:01:33,101 :: INFO :: evodenss.train.trainers :: [0] -- [3.09s] TRAIN epoch 11 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:33,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:01:33,104 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:33,796 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:01:37,057 :: INFO :: evodenss.train.trainers :: [0] -- [3.26s] TRAIN epoch 12 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:37,061 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:01:37,061 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:37,722 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:01:41,099 :: INFO :: evodenss.train.trainers :: [0] -- [3.37s] TRAIN epoch 13 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:41,102 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:01:41,102 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:41,762 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:01:44,919 :: INFO :: evodenss.train.trainers :: [0] -- [3.15s] TRAIN epoch 14 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:44,922 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:01:44,922 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:45,614 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:01:48,815 :: INFO :: evodenss.train.trainers :: [0] -- [3.2s] TRAIN epoch 15 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:48,818 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:01:48,818 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:49,478 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:01:52,623 :: INFO :: evodenss.train.trainers :: [0] -- [3.14s] TRAIN epoch 16 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:52,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:01:52,626 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:53,310 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:01:56,548 :: INFO :: evodenss.train.trainers :: [0] -- [3.24s] TRAIN epoch 17 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:01:56,551 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:01:56,551 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:01:57,225 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:02:00,531 :: INFO :: evodenss.train.trainers :: [0] -- [3.3s] TRAIN epoch 18 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:00,541 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:00,541 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:01,231 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:02:04,554 :: INFO :: evodenss.train.trainers :: [0] -- [3.32s] TRAIN epoch 19 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:04,559 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:04,559 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:05,236 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:02:08,553 :: INFO :: evodenss.train.trainers :: [0] -- [3.31s] TRAIN epoch 20 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:08,556 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:02:08,556 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:09,235 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:02:12,330 :: INFO :: evodenss.train.trainers :: [0] -- [3.09s] TRAIN epoch 21 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:12,333 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:12,333 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:13,005 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:02:16,296 :: INFO :: evodenss.train.trainers :: [0] -- [3.29s] TRAIN epoch 22 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:16,298 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:16,298 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:16,991 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:02:20,302 :: INFO :: evodenss.train.trainers :: [0] -- [3.31s] TRAIN epoch 23 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:20,304 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:20,304 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:21,001 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 16:02:24,152 :: INFO :: evodenss.train.trainers :: [0] -- [3.15s] TRAIN epoch 24 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:24,155 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:24,155 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:24,848 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 16:02:27,904 :: INFO :: evodenss.train.trainers :: [0] -- [3.05s] TRAIN epoch 25 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:27,907 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:27,907 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:28,609 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 16:02:31,849 :: INFO :: evodenss.train.trainers :: [0] -- [3.24s] TRAIN epoch 26 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:31,853 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:31,854 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:32,526 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 16:02:35,903 :: INFO :: evodenss.train.trainers :: [0] -- [3.38s] TRAIN epoch 27 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:35,906 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:35,906 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:36,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 16:02:39,828 :: INFO :: evodenss.train.trainers :: [0] -- [3.24s] TRAIN epoch 28 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:39,831 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:39,831 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:40,519 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 16:02:43,695 :: INFO :: evodenss.train.trainers :: [0] -- [3.18s] TRAIN epoch 29 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:43,708 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:43,708 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:44,402 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 16:02:47,485 :: INFO :: evodenss.train.trainers :: [0] -- [3.08s] TRAIN epoch 30 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:47,488 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:47,488 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:48,185 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 16:02:51,326 :: INFO :: evodenss.train.trainers :: [0] -- [3.14s] TRAIN epoch 31 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:51,329 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:51,329 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:52,021 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 16:02:55,193 :: INFO :: evodenss.train.trainers :: [0] -- [3.17s] TRAIN epoch 32 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:55,196 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:55,196 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:55,891 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 16:02:59,030 :: INFO :: evodenss.train.trainers :: [0] -- [3.14s] TRAIN epoch 33 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:02:59,033 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:02:59,034 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:02:59,694 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 16:03:02,766 :: INFO :: evodenss.train.trainers :: [0] -- [3.07s] TRAIN epoch 34 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:02,772 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:02,772 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:03,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 16:03:06,677 :: INFO :: evodenss.train.trainers :: [0] -- [3.21s] TRAIN epoch 35 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:06,680 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:06,680 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:07,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 16:03:10,426 :: INFO :: evodenss.train.trainers :: [0] -- [3.04s] TRAIN epoch 36 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:10,429 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:10,429 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:11,116 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 16:03:14,342 :: INFO :: evodenss.train.trainers :: [0] -- [3.22s] TRAIN epoch 37 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:14,344 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:14,344 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:15,037 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 16:03:18,233 :: INFO :: evodenss.train.trainers :: [0] -- [3.19s] TRAIN epoch 38 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:18,236 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:18,236 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:18,921 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 39
2024-11-19 16:03:22,186 :: INFO :: evodenss.train.trainers :: [0] -- [3.26s] TRAIN epoch 39 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:22,188 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:22,189 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:22,839 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 40
2024-11-19 16:03:26,079 :: INFO :: evodenss.train.trainers :: [0] -- [3.24s] TRAIN epoch 40 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:26,081 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:26,081 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:26,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 41
2024-11-19 16:03:29,831 :: INFO :: evodenss.train.trainers :: [0] -- [3.07s] TRAIN epoch 41 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:29,834 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:29,834 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:30,528 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 42
2024-11-19 16:03:33,707 :: INFO :: evodenss.train.trainers :: [0] -- [3.18s] TRAIN epoch 42 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:33,710 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:33,710 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:34,388 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 43
2024-11-19 16:03:37,581 :: INFO :: evodenss.train.trainers :: [0] -- [3.19s] TRAIN epoch 43 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:37,584 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:37,584 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:38,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 44
2024-11-19 16:03:41,524 :: INFO :: evodenss.train.trainers :: [0] -- [3.26s] TRAIN epoch 44 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:41,527 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:41,527 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:42,234 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 45
2024-11-19 16:03:45,426 :: INFO :: evodenss.train.trainers :: [0] -- [3.19s] TRAIN epoch 45 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:45,429 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:45,429 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:46,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 46
2024-11-19 16:03:49,364 :: INFO :: evodenss.train.trainers :: [0] -- [3.24s] TRAIN epoch 46 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:49,366 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:49,366 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:50,027 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 47
2024-11-19 16:03:53,090 :: INFO :: evodenss.train.trainers :: [0] -- [3.06s] TRAIN epoch 47 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:53,101 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:53,101 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:53,777 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 48
2024-11-19 16:03:56,942 :: INFO :: evodenss.train.trainers :: [0] -- [3.16s] TRAIN epoch 48 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:03:56,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:03:56,945 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:03:57,615 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 49
2024-11-19 16:04:00,777 :: INFO :: evodenss.train.trainers :: [0] -- [3.16s] TRAIN epoch 49 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:00,780 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:04:00,780 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:02,208 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 339037,  n_layers: 17,  n_layers_projector: -1,  training_time_spent: 194.53554272651672,  n_epochs: 50,  total_epochs_trained: 50,  accuracy: None,  fitness: 0.10907,  losses: {'train_loss': [0.143, 0.112, 0.111, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.107, 0.108, 0.107, 0.107, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107], 'val_loss': [0.088, 0.088, 0.086, 0.086, 0.085, 0.089, 0.091, 0.086, 0.086, 0.086, 0.091, 0.086, 0.086, 0.086, 0.089, 0.086, 0.087, 0.087, 0.087, 0.09, 0.088, 0.086, 0.089, 0.087, 0.088, 0.087, 0.088, 0.09, 0.088, 0.087, 0.086, 0.086, 0.086, 0.085, 0.087, 0.086, 0.09, 0.086, 0.087, 0.086, 0.089, 0.085, 0.086, 0.092, 0.088, 0.087, 0.087, 0.09, 0.087, 0.086]}),  max_epochs_reached: True

2024-11-19 16:04:02,211 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.10907
2024-11-19 16:04:02,219 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-19 16:04:02,223 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:123 kernel_size:3 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:91 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :deconv1d out_channels:13 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :deconv1d out_channels:53 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:9 
layer12: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:10 
layer13: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 
layer15: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:13 
layer16: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:14 
layer17: :fc act:selu out_features:200 bias:True input:15 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.0009547108081147019 batch_size:5 epochs:50
2024-11-19 16:04:02,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:04:02,240 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:04:09,292 :: INFO :: evodenss.train.trainers :: [0] -- [7.05s] TRAIN epoch 0 -- loss: tensor([0.1306], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:09,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.131
2024-11-19 16:04:09,295 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:10,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:04:16,811 :: INFO :: evodenss.train.trainers :: [0] -- [6.71s] TRAIN epoch 1 -- loss: tensor([0.1122], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:16,813 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 16:04:16,814 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:17,617 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:04:24,358 :: INFO :: evodenss.train.trainers :: [0] -- [6.74s] TRAIN epoch 2 -- loss: tensor([0.1118], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:24,361 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 16:04:24,361 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:25,195 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:04:31,901 :: INFO :: evodenss.train.trainers :: [0] -- [6.7s] TRAIN epoch 3 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:31,904 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:04:31,904 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:32,711 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:04:39,380 :: INFO :: evodenss.train.trainers :: [0] -- [6.67s] TRAIN epoch 4 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:39,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:04:39,384 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:40,170 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:04:46,927 :: INFO :: evodenss.train.trainers :: [0] -- [6.76s] TRAIN epoch 5 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:46,930 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:04:46,930 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:47,730 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:04:54,443 :: INFO :: evodenss.train.trainers :: [0] -- [6.71s] TRAIN epoch 6 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:04:54,446 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:04:54,446 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:04:55,251 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:05:02,028 :: INFO :: evodenss.train.trainers :: [0] -- [6.78s] TRAIN epoch 7 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:02,031 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:05:02,031 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:02,853 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:05:09,585 :: INFO :: evodenss.train.trainers :: [0] -- [6.73s] TRAIN epoch 8 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:09,587 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:05:09,587 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:10,382 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:05:17,020 :: INFO :: evodenss.train.trainers :: [0] -- [6.64s] TRAIN epoch 9 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:17,022 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:05:17,022 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:17,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:05:24,501 :: INFO :: evodenss.train.trainers :: [0] -- [6.69s] TRAIN epoch 10 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:24,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:05:24,504 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:25,322 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:05:32,096 :: INFO :: evodenss.train.trainers :: [0] -- [6.77s] TRAIN epoch 11 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:32,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:05:32,099 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:32,909 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:05:39,653 :: INFO :: evodenss.train.trainers :: [0] -- [6.74s] TRAIN epoch 12 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:39,656 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:05:39,656 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:40,480 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:05:47,263 :: INFO :: evodenss.train.trainers :: [0] -- [6.78s] TRAIN epoch 13 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:47,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:05:47,266 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:48,058 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:05:54,989 :: INFO :: evodenss.train.trainers :: [0] -- [6.93s] TRAIN epoch 14 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:05:54,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:05:54,993 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:05:55,766 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:06:02,588 :: INFO :: evodenss.train.trainers :: [0] -- [6.82s] TRAIN epoch 15 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:02,591 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:06:02,591 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:03,373 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:06:10,094 :: INFO :: evodenss.train.trainers :: [0] -- [6.72s] TRAIN epoch 16 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:10,096 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:06:10,096 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:10,873 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:06:17,776 :: INFO :: evodenss.train.trainers :: [0] -- [6.9s] TRAIN epoch 17 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:17,778 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:06:17,778 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:18,590 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:06:25,446 :: INFO :: evodenss.train.trainers :: [0] -- [6.85s] TRAIN epoch 18 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:25,448 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:06:25,448 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:26,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:06:33,074 :: INFO :: evodenss.train.trainers :: [0] -- [6.82s] TRAIN epoch 19 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:33,076 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:06:33,076 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:33,850 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:06:40,644 :: INFO :: evodenss.train.trainers :: [0] -- [6.79s] TRAIN epoch 20 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:40,647 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:06:40,647 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:41,449 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:06:48,279 :: INFO :: evodenss.train.trainers :: [0] -- [6.83s] TRAIN epoch 21 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:48,282 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:06:48,282 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:49,057 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:06:55,780 :: INFO :: evodenss.train.trainers :: [0] -- [6.72s] TRAIN epoch 22 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:06:55,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:06:55,783 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:06:56,594 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:07:03,307 :: INFO :: evodenss.train.trainers :: [0] -- [6.71s] TRAIN epoch 23 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:03,310 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:07:03,310 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:04,097 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 16:07:10,825 :: INFO :: evodenss.train.trainers :: [0] -- [6.73s] TRAIN epoch 24 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:10,828 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:07:10,828 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:11,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 16:07:18,445 :: INFO :: evodenss.train.trainers :: [0] -- [6.81s] TRAIN epoch 25 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:18,448 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:07:18,448 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:19,243 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 16:07:26,007 :: INFO :: evodenss.train.trainers :: [0] -- [6.76s] TRAIN epoch 26 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:26,009 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:07:26,009 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:27,763 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 335966,  n_layers: 17,  n_layers_projector: -1,  training_time_spent: 205.53752303123474,  n_epochs: 27,  total_epochs_trained: 27,  accuracy: None,  fitness: 0.11026,  losses: {'train_loss': [0.131, 0.112, 0.112, 0.111, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.109, 0.109, 0.108, 0.108, 0.109, 0.109, 0.108, 0.109], 'val_loss': [0.091, 0.1, 0.089, 0.09, 0.089, 0.103, 0.089, 0.091, 0.096, 0.092, 0.093, 0.092, 0.088, 0.088, 0.087, 0.091, 0.088, 0.087, 0.089, 0.089, 0.088, 0.088, 0.092, 0.089, 0.088, 0.09, 0.09]}),  max_epochs_reached: False

2024-11-19 16:07:27,766 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.11026
2024-11-19 16:07:27,770 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-19 16:07:27,773 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 1, id: 1
2024-11-19 16:07:27,777 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-19 16:07:27,780 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-19 16:07:27,787 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.10707, 0.10611, 0.10907, 0.11026]
2024-11-19 16:07:31,071 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1678], device='cuda:0')
2024-11-19 16:07:31,074 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 10: 0.10611
2024-11-19 16:07:31,080 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.10611



2024-11-19 16:07:31,172 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 11
2024-11-19 16:07:31,176 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-19 16:07:31,193 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 16:07:31,197 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 16:07:31,201 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 16:07:31,205 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-19 16:07:31,211 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 16:07:31,215 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-19 16:07:31,219 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 16:07:31,223 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 16:07:31,227 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 15
2024-11-19 16:07:31,230 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 16:07:31,238 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have an extra layer at Module 0: features; Position: 4. Reused?: False
2024-11-19 16:07:31,242 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 16:07:31,246 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-19 16:07:31,249 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 16:07:31,253 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-19 16:07:31,257 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 16:07:31,261 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 13
2024-11-19 16:07:31,265 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 14
2024-11-19 16:07:31,272 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 16:07:31,278 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 16:07:31,282 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 16:07:31,286 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-19 16:07:31,290 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 16:07:31,294 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 7
2024-11-19 16:07:31,297 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 16:07:31,301 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 16:07:31,306 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 16:07:31,310 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-19 16:07:31,314 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 16:07:31,320 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-19 16:07:31,328 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-19 16:07:31,332 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 
layer6: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 
layer10: :deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 
layer11: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 
layer12: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 
layer13: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 
layer14: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 
layer15: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 
layer16: :fc act:selu out_features:200 bias:True input:14 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000867475404773022 batch_size:7 epochs:50
2024-11-19 16:07:31,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:07:31,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:07:36,393 :: INFO :: evodenss.train.trainers :: [0] -- [5.04s] TRAIN epoch 0 -- loss: tensor([0.1301], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:36,396 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.13
2024-11-19 16:07:36,396 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:37,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:07:42,164 :: INFO :: evodenss.train.trainers :: [0] -- [5.05s] TRAIN epoch 1 -- loss: tensor([0.1129], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:42,167 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.113
2024-11-19 16:07:42,167 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:42,874 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:07:48,036 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 2 -- loss: tensor([0.1115], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:48,039 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 16:07:48,039 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:48,747 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:07:53,745 :: INFO :: evodenss.train.trainers :: [0] -- [5.0s] TRAIN epoch 3 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:53,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:07:53,748 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:07:54,492 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:07:59,659 :: INFO :: evodenss.train.trainers :: [0] -- [5.17s] TRAIN epoch 4 -- loss: tensor([0.1114], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:07:59,662 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:07:59,662 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:00,383 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:08:05,602 :: INFO :: evodenss.train.trainers :: [0] -- [5.22s] TRAIN epoch 5 -- loss: tensor([0.1110], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:05,605 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:08:05,605 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:06,341 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:08:11,415 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 6 -- loss: tensor([0.1099], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:11,418 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:11,418 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:12,140 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:08:17,207 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 7 -- loss: tensor([0.1101], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:17,210 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:17,210 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:17,894 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:08:22,997 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 8 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:23,000 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:23,000 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:23,709 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:08:28,767 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 9 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:28,770 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:08:28,770 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:29,475 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:08:34,643 :: INFO :: evodenss.train.trainers :: [0] -- [5.17s] TRAIN epoch 10 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:34,646 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:08:34,646 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:35,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:08:40,490 :: INFO :: evodenss.train.trainers :: [0] -- [5.13s] TRAIN epoch 11 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:40,493 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:40,493 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:41,237 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:08:46,349 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 12 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:46,352 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:46,352 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:47,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:08:52,125 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 13 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:52,131 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:52,131 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:52,862 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:08:58,052 :: INFO :: evodenss.train.trainers :: [0] -- [5.19s] TRAIN epoch 14 -- loss: tensor([0.1096], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:08:58,055 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:08:58,055 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:08:58,759 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:09:03,860 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 15 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:03,863 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:03,863 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:04,569 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:09:09,671 :: INFO :: evodenss.train.trainers :: [0] -- [5.1s] TRAIN epoch 16 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:09,674 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:09,674 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:10,370 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:09:15,431 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 17 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:15,433 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:15,433 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:16,147 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:09:21,272 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 18 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:21,275 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:21,275 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:21,992 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:09:27,420 :: INFO :: evodenss.train.trainers :: [0] -- [5.43s] TRAIN epoch 19 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:27,423 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:27,423 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:28,127 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:09:33,170 :: INFO :: evodenss.train.trainers :: [0] -- [5.04s] TRAIN epoch 20 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:33,173 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:33,173 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:33,896 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:09:38,889 :: INFO :: evodenss.train.trainers :: [0] -- [4.99s] TRAIN epoch 21 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:38,898 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:38,898 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:39,625 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:09:44,690 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 22 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:44,693 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:44,693 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:45,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:09:50,340 :: INFO :: evodenss.train.trainers :: [0] -- [4.96s] TRAIN epoch 23 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:50,343 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:50,343 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:51,060 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 16:09:56,344 :: INFO :: evodenss.train.trainers :: [0] -- [5.28s] TRAIN epoch 24 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:09:56,347 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:09:56,347 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:09:57,043 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 16:10:02,134 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 25 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:02,137 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:02,137 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:02,849 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 16:10:08,013 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 26 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:08,016 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:08,016 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:08,763 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 16:10:13,792 :: INFO :: evodenss.train.trainers :: [0] -- [5.03s] TRAIN epoch 27 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:13,795 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:13,795 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:14,523 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 16:10:19,589 :: INFO :: evodenss.train.trainers :: [0] -- [5.06s] TRAIN epoch 28 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:19,592 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:19,592 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:20,293 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 16:10:25,455 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 29 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:25,458 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:25,458 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:26,156 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 16:10:31,243 :: INFO :: evodenss.train.trainers :: [0] -- [5.09s] TRAIN epoch 30 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:31,246 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:31,246 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:31,963 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 16:10:37,031 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 31 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:37,034 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:37,034 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:37,765 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 16:10:42,915 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 32 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:42,918 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:42,918 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:43,627 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 16:10:48,875 :: INFO :: evodenss.train.trainers :: [0] -- [5.25s] TRAIN epoch 33 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:48,878 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:48,878 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:49,599 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 16:10:54,779 :: INFO :: evodenss.train.trainers :: [0] -- [5.18s] TRAIN epoch 34 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:10:54,783 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:10:54,783 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:10:56,354 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 0: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 344192,  n_layers: 16,  n_layers_projector: -1,  training_time_spent: 205.01944303512573,  n_epochs: 35,  total_epochs_trained: 35,  accuracy: None,  fitness: 0.11045,  losses: {'train_loss': [0.13, 0.113, 0.112, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.109, 0.109, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109], 'val_loss': [0.09, 0.095, 0.091, 0.091, 0.086, 0.087, 0.087, 0.086, 0.086, 0.087, 0.086, 0.086, 0.087, 0.086, 0.087, 0.091, 0.086, 0.086, 0.088, 0.088, 0.087, 0.086, 0.088, 0.089, 0.089, 0.089, 0.09, 0.088, 0.09, 0.086, 0.087, 0.086, 0.087, 0.09, 0.089]}),  max_epochs_reached: False

2024-11-19 16:10:56,356 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 0 fitness: 0.11045
2024-11-19 16:10:56,365 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 1 for 200 secs
2024-11-19 16:10:56,369 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:109 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:9 
layer12: :conv1d out_channels:92 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:12 
layer15: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:13 
layer16: :deconv1d out_channels:93 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:True bias:True input:14 
layer17: :fc act:selu out_features:200 bias:True input:15 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000351494593068316 batch_size:7 epochs:50
2024-11-19 16:10:56,385 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:10:56,385 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:11:02,407 :: INFO :: evodenss.train.trainers :: [0] -- [6.02s] TRAIN epoch 0 -- loss: tensor([3.7540], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:02,409 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 3.754
2024-11-19 16:11:02,409 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:03,178 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:11:09,036 :: INFO :: evodenss.train.trainers :: [0] -- [5.86s] TRAIN epoch 1 -- loss: tensor([4.0200], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:09,039 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 4.02
2024-11-19 16:11:09,039 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:09,776 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:11:15,515 :: INFO :: evodenss.train.trainers :: [0] -- [5.74s] TRAIN epoch 2 -- loss: tensor([0.9984], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:15,518 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.998
2024-11-19 16:11:15,518 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:16,265 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:11:22,257 :: INFO :: evodenss.train.trainers :: [0] -- [5.99s] TRAIN epoch 3 -- loss: tensor([0.1675], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:22,261 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.167
2024-11-19 16:11:22,261 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:22,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:11:28,655 :: INFO :: evodenss.train.trainers :: [0] -- [5.66s] TRAIN epoch 4 -- loss: tensor([0.1323], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:28,658 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.132
2024-11-19 16:11:28,658 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:29,390 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:11:35,280 :: INFO :: evodenss.train.trainers :: [0] -- [5.89s] TRAIN epoch 5 -- loss: tensor([0.1217], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:35,282 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.122
2024-11-19 16:11:35,283 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:36,014 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:11:41,712 :: INFO :: evodenss.train.trainers :: [0] -- [5.7s] TRAIN epoch 6 -- loss: tensor([0.1158], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:41,715 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.116
2024-11-19 16:11:41,715 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:42,431 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:11:48,101 :: INFO :: evodenss.train.trainers :: [0] -- [5.67s] TRAIN epoch 7 -- loss: tensor([0.1125], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:48,104 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 16:11:48,104 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:48,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:11:54,510 :: INFO :: evodenss.train.trainers :: [0] -- [5.69s] TRAIN epoch 8 -- loss: tensor([0.1113], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:11:54,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:11:54,513 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:11:55,227 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:12:00,875 :: INFO :: evodenss.train.trainers :: [0] -- [5.65s] TRAIN epoch 9 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:00,878 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:12:00,878 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:01,608 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:12:07,427 :: INFO :: evodenss.train.trainers :: [0] -- [5.82s] TRAIN epoch 10 -- loss: tensor([0.1097], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:07,429 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:12:07,429 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:08,162 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:12:13,916 :: INFO :: evodenss.train.trainers :: [0] -- [5.75s] TRAIN epoch 11 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:13,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:13,919 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:14,646 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:12:20,378 :: INFO :: evodenss.train.trainers :: [0] -- [5.73s] TRAIN epoch 12 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:20,381 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:20,381 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:21,125 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:12:26,861 :: INFO :: evodenss.train.trainers :: [0] -- [5.73s] TRAIN epoch 13 -- loss: tensor([0.1094], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:26,864 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:26,864 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:27,595 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:12:33,364 :: INFO :: evodenss.train.trainers :: [0] -- [5.77s] TRAIN epoch 14 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:33,367 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:33,367 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:34,083 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:12:39,766 :: INFO :: evodenss.train.trainers :: [0] -- [5.68s] TRAIN epoch 15 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:39,769 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:39,769 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:40,536 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:12:46,237 :: INFO :: evodenss.train.trainers :: [0] -- [5.7s] TRAIN epoch 16 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:46,239 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:46,239 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:46,970 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:12:52,720 :: INFO :: evodenss.train.trainers :: [0] -- [5.75s] TRAIN epoch 17 -- loss: tensor([0.1093], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:52,720 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:52,720 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:12:53,462 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:12:59,545 :: INFO :: evodenss.train.trainers :: [0] -- [6.08s] TRAIN epoch 18 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:12:59,546 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:12:59,546 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:00,280 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:13:06,080 :: INFO :: evodenss.train.trainers :: [0] -- [5.8s] TRAIN epoch 19 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:06,080 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:06,080 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:06,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:13:12,531 :: INFO :: evodenss.train.trainers :: [0] -- [5.72s] TRAIN epoch 20 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:12,532 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:12,532 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:13,277 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:13:18,944 :: INFO :: evodenss.train.trainers :: [0] -- [5.67s] TRAIN epoch 21 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:18,945 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:18,945 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:19,681 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:13:25,297 :: INFO :: evodenss.train.trainers :: [0] -- [5.61s] TRAIN epoch 22 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:25,297 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:25,297 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:26,034 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:13:31,913 :: INFO :: evodenss.train.trainers :: [0] -- [5.88s] TRAIN epoch 23 -- loss: tensor([0.1087], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:31,913 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:31,913 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:32,660 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 16:13:38,443 :: INFO :: evodenss.train.trainers :: [0] -- [5.78s] TRAIN epoch 24 -- loss: tensor([0.1089], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:38,444 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:38,444 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:39,160 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 16:13:45,024 :: INFO :: evodenss.train.trainers :: [0] -- [5.86s] TRAIN epoch 25 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:45,024 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:45,024 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:45,786 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 16:13:51,718 :: INFO :: evodenss.train.trainers :: [0] -- [5.93s] TRAIN epoch 26 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:51,719 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:13:51,719 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:52,452 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 16:13:58,345 :: INFO :: evodenss.train.trainers :: [0] -- [5.89s] TRAIN epoch 27 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:13:58,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:13:58,346 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:13:59,099 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 16:14:04,797 :: INFO :: evodenss.train.trainers :: [0] -- [5.7s] TRAIN epoch 28 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:04,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:14:04,797 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:05,530 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 16:14:11,346 :: INFO :: evodenss.train.trainers :: [0] -- [5.81s] TRAIN epoch 29 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:11,346 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:14:11,346 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:12,081 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 16:14:17,901 :: INFO :: evodenss.train.trainers :: [0] -- [5.82s] TRAIN epoch 30 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:17,901 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:14:17,901 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:19,602 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 1: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 7809621,  n_layers: 17,  n_layers_projector: -1,  training_time_spent: 203.23032927513123,  n_epochs: 31,  total_epochs_trained: 31,  accuracy: None,  fitness: 0.13683,  losses: {'train_loss': [3.754, 4.02, 0.998, 0.167, 0.132, 0.122, 0.116, 0.112, 0.111, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.108, 0.108, 0.108], 'val_loss': [4.145, 2.006, 0.181, 0.104, 0.116, 0.097, 0.091, 0.088, 0.087, 0.087, 0.088, 0.086, 0.087, 0.086, 0.086, 0.086, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086]}),  max_epochs_reached: False

2024-11-19 16:14:19,603 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 1 fitness: 0.13683
2024-11-19 16:14:19,608 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 2 for 200 secs
2024-11-19 16:14:19,609 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:21 kernel_size:4 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 
layer9: :deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 
layer10: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 
layer11: :conv1d out_channels:91 kernel_size:1 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:9 
layer12: :conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 
layer15: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:13 
layer16: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:14 
layer17: :fc act:selu out_features:200 bias:True input:15 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.00031369919221085326 batch_size:7 epochs:50
2024-11-19 16:14:19,621 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:14:19,622 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:14:25,384 :: INFO :: evodenss.train.trainers :: [0] -- [5.76s] TRAIN epoch 0 -- loss: tensor([0.1353], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:25,385 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.135
2024-11-19 16:14:25,385 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:26,166 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:14:31,402 :: INFO :: evodenss.train.trainers :: [0] -- [5.23s] TRAIN epoch 1 -- loss: tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:31,402 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.111
2024-11-19 16:14:31,402 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:32,132 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:14:37,464 :: INFO :: evodenss.train.trainers :: [0] -- [5.33s] TRAIN epoch 2 -- loss: tensor([0.1098], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:37,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:14:37,464 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:38,180 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:14:43,434 :: INFO :: evodenss.train.trainers :: [0] -- [5.25s] TRAIN epoch 3 -- loss: tensor([0.1095], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:43,435 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:14:43,435 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:44,171 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:14:49,428 :: INFO :: evodenss.train.trainers :: [0] -- [5.25s] TRAIN epoch 4 -- loss: tensor([0.1091], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:49,428 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:14:49,428 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:50,153 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:14:55,270 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 5 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:14:55,270 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:14:55,271 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:14:55,993 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:15:01,200 :: INFO :: evodenss.train.trainers :: [0] -- [5.21s] TRAIN epoch 6 -- loss: tensor([0.1086], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:01,200 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:15:01,200 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:01,943 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:15:07,085 :: INFO :: evodenss.train.trainers :: [0] -- [5.14s] TRAIN epoch 7 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:07,086 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:15:07,086 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:07,808 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:15:12,922 :: INFO :: evodenss.train.trainers :: [0] -- [5.11s] TRAIN epoch 8 -- loss: tensor([0.1083], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:12,922 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:12,922 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:13,662 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:15:18,866 :: INFO :: evodenss.train.trainers :: [0] -- [5.2s] TRAIN epoch 9 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:18,866 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:18,866 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:19,597 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:15:24,748 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 10 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:24,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:24,748 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:25,471 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:15:30,674 :: INFO :: evodenss.train.trainers :: [0] -- [5.2s] TRAIN epoch 11 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:30,675 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:30,675 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:31,436 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:15:36,761 :: INFO :: evodenss.train.trainers :: [0] -- [5.32s] TRAIN epoch 12 -- loss: tensor([0.1080], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:36,762 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:36,762 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:37,495 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:15:42,917 :: INFO :: evodenss.train.trainers :: [0] -- [5.42s] TRAIN epoch 13 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:42,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:42,917 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:43,652 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:15:48,810 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 14 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:48,810 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:48,810 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:49,555 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:15:54,710 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 15 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:15:54,710 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:15:54,710 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:15:55,442 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:16:00,600 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 16 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:00,600 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:00,600 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:01,350 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:16:06,573 :: INFO :: evodenss.train.trainers :: [0] -- [5.22s] TRAIN epoch 17 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:06,573 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:06,573 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:07,331 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:16:12,583 :: INFO :: evodenss.train.trainers :: [0] -- [5.25s] TRAIN epoch 18 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:12,583 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:12,583 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:13,314 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:16:18,595 :: INFO :: evodenss.train.trainers :: [0] -- [5.28s] TRAIN epoch 19 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:18,595 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:18,595 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:19,301 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:16:24,376 :: INFO :: evodenss.train.trainers :: [0] -- [5.07s] TRAIN epoch 20 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:24,376 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:24,376 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:25,111 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:16:30,414 :: INFO :: evodenss.train.trainers :: [0] -- [5.3s] TRAIN epoch 21 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:30,415 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:16:30,415 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:31,121 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:16:36,312 :: INFO :: evodenss.train.trainers :: [0] -- [5.19s] TRAIN epoch 22 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:36,313 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:36,313 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:37,070 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:16:42,227 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 23 -- loss: tensor([0.1081], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:42,228 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:42,228 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:42,953 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 16:16:48,113 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 24 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:48,114 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:48,114 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:48,851 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 16:16:54,025 :: INFO :: evodenss.train.trainers :: [0] -- [5.17s] TRAIN epoch 25 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:54,026 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:54,026 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:16:54,780 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 16:16:59,992 :: INFO :: evodenss.train.trainers :: [0] -- [5.21s] TRAIN epoch 26 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:16:59,992 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:16:59,992 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:00,708 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 16:17:05,829 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 27 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:05,829 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:17:05,829 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:06,582 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 16:17:11,804 :: INFO :: evodenss.train.trainers :: [0] -- [5.22s] TRAIN epoch 28 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:11,804 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:17:11,804 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:12,530 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 16:17:17,686 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 29 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:17,686 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:17:17,686 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:18,424 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 16:17:23,578 :: INFO :: evodenss.train.trainers :: [0] -- [5.15s] TRAIN epoch 30 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:23,578 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:17:23,578 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:24,307 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 16:17:29,464 :: INFO :: evodenss.train.trainers :: [0] -- [5.16s] TRAIN epoch 31 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:29,464 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:17:29,465 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:30,209 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 16:17:35,328 :: INFO :: evodenss.train.trainers :: [0] -- [5.12s] TRAIN epoch 32 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:35,328 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:17:35,329 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:36,076 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 16:17:41,217 :: INFO :: evodenss.train.trainers :: [0] -- [5.14s] TRAIN epoch 33 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:41,217 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:17:41,217 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:42,780 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 2: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 308377,  n_layers: 17,  n_layers_projector: -1,  training_time_spent: 203.16846370697021,  n_epochs: 34,  total_epochs_trained: 34,  accuracy: None,  fitness: 0.11536,  losses: {'train_loss': [0.135, 0.111, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.107, 0.108, 0.108], 'val_loss': [0.092, 0.087, 0.087, 0.086, 0.086, 0.087, 0.087, 0.086, 0.086, 0.087, 0.087, 0.087, 0.087, 0.086, 0.089, 0.087, 0.089, 0.087, 0.087, 0.086, 0.091, 0.086, 0.091, 0.086, 0.086, 0.086, 0.086, 0.088, 0.088, 0.087, 0.087, 0.086, 0.086, 0.087]}),  max_epochs_reached: False

2024-11-19 16:17:42,780 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 2 fitness: 0.11536
2024-11-19 16:17:42,784 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 3 for 200 secs
2024-11-19 16:17:42,785 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:35 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:adam lr:0.00011891338217255042 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000867475404773022 batch_size:7 epochs:50
2024-11-19 16:17:42,796 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:17:42,797 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:17:47,456 :: INFO :: evodenss.train.trainers :: [0] -- [4.66s] TRAIN epoch 0 -- loss: tensor([0.1591], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:47,456 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.159
2024-11-19 16:17:47,456 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:48,177 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:17:52,699 :: INFO :: evodenss.train.trainers :: [0] -- [4.52s] TRAIN epoch 1 -- loss: tensor([0.1102], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:52,699 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:17:52,699 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:53,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:17:57,916 :: INFO :: evodenss.train.trainers :: [0] -- [4.47s] TRAIN epoch 2 -- loss: tensor([0.1090], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:17:57,917 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:17:57,917 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:17:58,620 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:18:03,009 :: INFO :: evodenss.train.trainers :: [0] -- [4.39s] TRAIN epoch 3 -- loss: tensor([0.1084], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:03,010 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:03,010 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:03,720 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:18:08,135 :: INFO :: evodenss.train.trainers :: [0] -- [4.41s] TRAIN epoch 4 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:08,136 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:08,136 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:08,856 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:18:13,242 :: INFO :: evodenss.train.trainers :: [0] -- [4.38s] TRAIN epoch 5 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:13,242 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:13,242 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:13,946 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:18:18,708 :: INFO :: evodenss.train.trainers :: [0] -- [4.76s] TRAIN epoch 6 -- loss: tensor([0.1078], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:18,709 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:18,709 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:19,425 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:18:23,703 :: INFO :: evodenss.train.trainers :: [0] -- [4.28s] TRAIN epoch 7 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:23,703 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:23,703 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:24,414 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:18:29,023 :: INFO :: evodenss.train.trainers :: [0] -- [4.61s] TRAIN epoch 8 -- loss: tensor([0.1077], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:29,023 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:29,023 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:29,769 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:18:34,224 :: INFO :: evodenss.train.trainers :: [0] -- [4.45s] TRAIN epoch 9 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:34,224 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:18:34,224 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:34,934 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:18:39,425 :: INFO :: evodenss.train.trainers :: [0] -- [4.49s] TRAIN epoch 10 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:39,425 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:18:39,425 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:40,153 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:18:44,519 :: INFO :: evodenss.train.trainers :: [0] -- [4.36s] TRAIN epoch 11 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:44,520 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:18:44,520 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:45,243 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:18:49,652 :: INFO :: evodenss.train.trainers :: [0] -- [4.41s] TRAIN epoch 12 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:49,653 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:18:49,653 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:50,353 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:18:54,904 :: INFO :: evodenss.train.trainers :: [0] -- [4.55s] TRAIN epoch 13 -- loss: tensor([0.1074], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:18:54,905 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:18:54,905 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:18:55,623 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:19:00,098 :: INFO :: evodenss.train.trainers :: [0] -- [4.47s] TRAIN epoch 14 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:00,098 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:00,098 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:00,814 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:19:05,427 :: INFO :: evodenss.train.trainers :: [0] -- [4.61s] TRAIN epoch 15 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:05,427 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:05,428 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:06,126 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:19:10,513 :: INFO :: evodenss.train.trainers :: [0] -- [4.39s] TRAIN epoch 16 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:10,513 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:10,513 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:11,214 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:19:15,533 :: INFO :: evodenss.train.trainers :: [0] -- [4.32s] TRAIN epoch 17 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:15,533 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:15,533 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:16,248 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:19:20,578 :: INFO :: evodenss.train.trainers :: [0] -- [4.33s] TRAIN epoch 18 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:20,578 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:20,578 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:21,295 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:19:25,723 :: INFO :: evodenss.train.trainers :: [0] -- [4.43s] TRAIN epoch 19 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:25,723 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:25,723 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:26,421 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:19:30,836 :: INFO :: evodenss.train.trainers :: [0] -- [4.41s] TRAIN epoch 20 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:30,836 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:30,836 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:31,567 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:19:36,168 :: INFO :: evodenss.train.trainers :: [0] -- [4.6s] TRAIN epoch 21 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:36,169 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:36,169 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:36,892 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:19:41,402 :: INFO :: evodenss.train.trainers :: [0] -- [4.51s] TRAIN epoch 22 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:41,402 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:41,402 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:42,124 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:19:46,489 :: INFO :: evodenss.train.trainers :: [0] -- [4.36s] TRAIN epoch 23 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:46,490 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:46,490 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:47,193 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 24
2024-11-19 16:19:51,858 :: INFO :: evodenss.train.trainers :: [0] -- [4.66s] TRAIN epoch 24 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:51,858 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:51,859 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:52,588 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 25
2024-11-19 16:19:57,024 :: INFO :: evodenss.train.trainers :: [0] -- [4.43s] TRAIN epoch 25 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:19:57,024 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:19:57,024 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:19:57,748 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 26
2024-11-19 16:20:02,171 :: INFO :: evodenss.train.trainers :: [0] -- [4.42s] TRAIN epoch 26 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:02,171 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:02,171 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:02,893 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 27
2024-11-19 16:20:07,252 :: INFO :: evodenss.train.trainers :: [0] -- [4.36s] TRAIN epoch 27 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:07,252 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:07,252 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:07,947 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 28
2024-11-19 16:20:12,459 :: INFO :: evodenss.train.trainers :: [0] -- [4.51s] TRAIN epoch 28 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:12,459 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:12,459 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:13,176 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 29
2024-11-19 16:20:17,631 :: INFO :: evodenss.train.trainers :: [0] -- [4.45s] TRAIN epoch 29 -- loss: tensor([0.1068], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:17,631 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:17,631 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:18,331 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 30
2024-11-19 16:20:22,732 :: INFO :: evodenss.train.trainers :: [0] -- [4.4s] TRAIN epoch 30 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:22,732 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:22,732 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:23,444 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 31
2024-11-19 16:20:27,781 :: INFO :: evodenss.train.trainers :: [0] -- [4.34s] TRAIN epoch 31 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:27,781 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:27,781 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:28,472 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 32
2024-11-19 16:20:33,012 :: INFO :: evodenss.train.trainers :: [0] -- [4.54s] TRAIN epoch 32 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:33,012 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:33,012 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:33,727 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 33
2024-11-19 16:20:38,245 :: INFO :: evodenss.train.trainers :: [0] -- [4.52s] TRAIN epoch 33 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:38,246 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:38,246 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:38,962 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 34
2024-11-19 16:20:43,384 :: INFO :: evodenss.train.trainers :: [0] -- [4.42s] TRAIN epoch 34 -- loss: tensor([0.1069], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:43,384 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:43,384 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:44,089 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 35
2024-11-19 16:20:48,462 :: INFO :: evodenss.train.trainers :: [0] -- [4.37s] TRAIN epoch 35 -- loss: tensor([0.1067], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:48,463 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:48,463 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:49,185 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 36
2024-11-19 16:20:53,577 :: INFO :: evodenss.train.trainers :: [0] -- [4.39s] TRAIN epoch 36 -- loss: tensor([0.1066], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:53,577 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:20:53,577 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:54,287 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 37
2024-11-19 16:20:58,641 :: INFO :: evodenss.train.trainers :: [0] -- [4.35s] TRAIN epoch 37 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:20:58,642 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 16:20:58,642 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:20:59,358 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 38
2024-11-19 16:21:03,870 :: INFO :: evodenss.train.trainers :: [0] -- [4.51s] TRAIN epoch 38 -- loss: tensor([0.1065], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:03,871 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.106
2024-11-19 16:21:03,871 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:05,389 :: INFO :: evodenss.evolution.individual :: [0] -- Evaluation results for individual 3: EvaluationMetrics(is_valid_solution: True,  n_trainable_parameters: 305213,  n_layers: 15,  n_layers_projector: -1,  training_time_spent: 202.60181307792664,  n_epochs: 39,  total_epochs_trained: 39,  accuracy: None,  fitness: 0.10666,  losses: {'train_loss': [0.159, 0.11, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106], 'val_loss': [0.09, 0.087, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086]}),  max_epochs_reached: False

2024-11-19 16:21:05,390 :: INFO :: evodenss.evolution.engine :: [0] -- Individual 3 fitness: 0.10666
2024-11-19 16:21:05,390 :: INFO :: evodenss.evolution.engine :: [0] -- Selecting the fittest individual
2024-11-19 16:21:05,390 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Parent: idx: 3, id: 3
2024-11-19 16:21:05,390 :: INFO :: evodenss.evolution.operators.selection :: [0] -- Training times: [200, 200, 200, 200]
2024-11-19 16:21:05,390 :: INFO :: evodenss.evolution.operators.selection :: [0] -- ids: [0, 1, 2, 3]
2024-11-19 16:21:05,394 :: INFO :: evodenss.evolution.engine :: [0] -- Fitnesses: [0.11045, 0.13683, 0.11536, 0.10666]
2024-11-19 16:21:08,602 :: INFO :: evodenss.evolution.engine :: [0] -- Generation best test fitness: tensor([0.1721], device='cuda:0')
2024-11-19 16:21:08,603 :: INFO :: evodenss.evolution.engine :: [0] -- Best fitness of generation 11: 0.10666
2024-11-19 16:21:08,603 :: INFO :: evodenss.evolution.engine :: [0] -- Best overall fitness: 0.10611



2024-11-19 16:21:08,698 :: INFO :: evodenss.evolution.engine :: [0] -- Performing generation: 12
2024-11-19 16:21:08,698 :: INFO :: evodenss.evolution.engine :: [0] -- Applying mutation operators
2024-11-19 16:21:08,712 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 16:21:08,713 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 5
2024-11-19 16:21:08,713 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 6
2024-11-19 16:21:08,714 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 16:21:08,715 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 16:21:08,715 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-19 16:21:08,716 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 1 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 16:21:08,720 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 16:21:08,720 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a layer removed from Module 0: features; Position: 4
2024-11-19 16:21:08,721 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 16:21:08,721 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 16:21:08,722 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 16:21:08,723 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Module 0 Position: 10
2024-11-19 16:21:08,723 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 2 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 16:21:08,727 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 4
2024-11-19 16:21:08,728 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 8
2024-11-19 16:21:08,729 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 9
2024-11-19 16:21:08,730 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 11
2024-11-19 16:21:08,730 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Module 0 Position: 12
2024-11-19 16:21:08,731 :: INFO :: evodenss.evolution.operators.mutation_tracker :: [0] -- Individual 3 is going to have a DSGE mutation on Non-topological component: learning
2024-11-19 16:21:08,734 :: INFO :: evodenss.evolution.engine :: [0] -- mutation has been performed
2024-11-19 16:21:08,738 :: INFO :: evodenss.evolution.individual :: [0] -- -----> Starting evaluation for individual 0 for 200 secs
2024-11-19 16:21:08,738 :: INFO :: evodenss.networks.evaluators :: [0] -- layer0: 
layer1: :punctual_mlp input:-1 
layer2: :punctual_mlp input:-1 
layer3: :punctual_mlp input:-1 
layer4: :punctual_mlp input:-1 
layer5: :deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 
layer6: :conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 
layer7: :deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 
layer8: :conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 
layer9: :deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 
layer10: :conv1d out_channels:35 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 
layer11: :conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 
layer12: :conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 
layer13: :conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 
layer14: :conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 
layer15: :fc act:selu out_features:200 bias:True input:13 learning:adam lr:0.00011891338217255042 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000867475404773022 batch_size:7 epochs:50
2024-11-19 16:21:08,750 :: DEBUG :: evodenss.train.trainers :: [0] -- Initiating supervised training
2024-11-19 16:21:08,750 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 0
2024-11-19 16:21:13,262 :: INFO :: evodenss.train.trainers :: [0] -- [4.51s] TRAIN epoch 0 -- loss: tensor([0.1572], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:13,262 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.157
2024-11-19 16:21:13,262 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:13,975 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 1
2024-11-19 16:21:18,440 :: INFO :: evodenss.train.trainers :: [0] -- [4.46s] TRAIN epoch 1 -- loss: tensor([0.1119], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:18,440 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.112
2024-11-19 16:21:18,440 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:19,149 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 2
2024-11-19 16:21:23,607 :: INFO :: evodenss.train.trainers :: [0] -- [4.46s] TRAIN epoch 2 -- loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:23,607 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.11
2024-11-19 16:21:23,607 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:24,337 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 3
2024-11-19 16:21:29,064 :: INFO :: evodenss.train.trainers :: [0] -- [4.73s] TRAIN epoch 3 -- loss: tensor([0.1092], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:29,065 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:21:29,065 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:29,745 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 4
2024-11-19 16:21:34,267 :: INFO :: evodenss.train.trainers :: [0] -- [4.52s] TRAIN epoch 4 -- loss: tensor([0.1088], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:34,268 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.109
2024-11-19 16:21:34,268 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:34,983 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 5
2024-11-19 16:21:39,912 :: INFO :: evodenss.train.trainers :: [0] -- [4.93s] TRAIN epoch 5 -- loss: tensor([0.1085], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:39,912 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:21:39,912 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:40,635 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 6
2024-11-19 16:21:45,164 :: INFO :: evodenss.train.trainers :: [0] -- [4.53s] TRAIN epoch 6 -- loss: tensor([0.1082], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:45,165 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:21:45,165 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:45,872 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 7
2024-11-19 16:21:50,538 :: INFO :: evodenss.train.trainers :: [0] -- [4.66s] TRAIN epoch 7 -- loss: tensor([0.1079], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:50,538 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:21:50,538 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:51,264 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 8
2024-11-19 16:21:55,876 :: INFO :: evodenss.train.trainers :: [0] -- [4.61s] TRAIN epoch 8 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:21:55,876 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:21:55,876 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:21:56,603 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 9
2024-11-19 16:22:01,083 :: INFO :: evodenss.train.trainers :: [0] -- [4.48s] TRAIN epoch 9 -- loss: tensor([0.1076], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:01,084 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.108
2024-11-19 16:22:01,084 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:01,795 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 10
2024-11-19 16:22:06,215 :: INFO :: evodenss.train.trainers :: [0] -- [4.42s] TRAIN epoch 10 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:06,215 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:06,215 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:06,935 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 11
2024-11-19 16:22:11,341 :: INFO :: evodenss.train.trainers :: [0] -- [4.4s] TRAIN epoch 11 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:11,341 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:11,341 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:12,059 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 12
2024-11-19 16:22:16,611 :: INFO :: evodenss.train.trainers :: [0] -- [4.55s] TRAIN epoch 12 -- loss: tensor([0.1075], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:16,611 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:16,611 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:17,329 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 13
2024-11-19 16:22:21,919 :: INFO :: evodenss.train.trainers :: [0] -- [4.59s] TRAIN epoch 13 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:21,919 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:21,919 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:22,626 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 14
2024-11-19 16:22:27,040 :: INFO :: evodenss.train.trainers :: [0] -- [4.41s] TRAIN epoch 14 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:27,040 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:27,040 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:27,744 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 15
2024-11-19 16:22:32,345 :: INFO :: evodenss.train.trainers :: [0] -- [4.6s] TRAIN epoch 15 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:32,345 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:32,345 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:33,082 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 16
2024-11-19 16:22:37,644 :: INFO :: evodenss.train.trainers :: [0] -- [4.56s] TRAIN epoch 16 -- loss: tensor([0.1073], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:37,644 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:37,644 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:38,357 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 17
2024-11-19 16:22:43,075 :: INFO :: evodenss.train.trainers :: [0] -- [4.72s] TRAIN epoch 17 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:43,075 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:43,075 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:43,768 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 18
2024-11-19 16:22:48,323 :: INFO :: evodenss.train.trainers :: [0] -- [4.55s] TRAIN epoch 18 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:48,323 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:48,323 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:49,051 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 19
2024-11-19 16:22:53,817 :: INFO :: evodenss.train.trainers :: [0] -- [4.76s] TRAIN epoch 19 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:53,817 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:53,817 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:54,544 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 20
2024-11-19 16:22:59,131 :: INFO :: evodenss.train.trainers :: [0] -- [4.58s] TRAIN epoch 20 -- loss: tensor([0.1072], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:22:59,131 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:22:59,131 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:22:59,837 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 21
2024-11-19 16:23:04,503 :: INFO :: evodenss.train.trainers :: [0] -- [4.66s] TRAIN epoch 21 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:23:04,503 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:23:04,503 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:23:05,212 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 22
2024-11-19 16:23:09,807 :: INFO :: evodenss.train.trainers :: [0] -- [4.59s] TRAIN epoch 22 -- loss: tensor([0.1070], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:23:09,807 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:23:09,807 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
2024-11-19 16:23:10,504 :: DEBUG :: evodenss.train.trainers :: [0] -- Starting Downstream Epoch 23
2024-11-19 16:23:15,007 :: INFO :: evodenss.train.trainers :: [0] -- [4.5s] TRAIN epoch 23 -- loss: tensor([0.1071], device='cuda:0', grad_fn=<AddBackward0>)
2024-11-19 16:23:15,007 :: DEBUG :: evodenss.train.trainers :: [0] -- Loss: 0.107
2024-11-19 16:23:15,007 :: DEBUG :: evodenss.train.trainers :: [0] -- =============================================================
