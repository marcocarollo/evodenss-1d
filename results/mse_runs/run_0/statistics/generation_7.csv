id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 layer:fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50	50	200	True	0.12337		282792	15	-1	117.56618404388428	{'train_loss': [0.275, 0.114, 0.11, 0.109, 0.108, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.106, 0.106, 0.106, 0.106, 0.105, 0.105, 0.105, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105, 0.106, 0.105], 'val_loss': [0.101, 0.088, 0.086, 0.085, 0.085, 0.09, 0.085, 0.09, 0.088, 0.096, 0.092, 0.089, 0.086, 0.09, 0.085, 0.085, 0.086, 0.087, 0.088, 0.087, 0.085, 0.085, 0.085, 0.085, 0.086, 0.084, 0.086, 0.087, 0.084, 0.087, 0.085, 0.085, 0.085, 0.085, 0.087, 0.086, 0.085, 0.087, 0.085, 0.085, 0.085, 0.086, 0.086, 0.085, 0.086, 0.085, 0.085, 0.085, 0.085, 0.085]}	50	50	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:124 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:47 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 layer:fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0008393550496114862 batch_size:34 epochs:50	50	200	True	0.25352		294018	16	-1	114.32585167884827	{'train_loss': [0.458, 0.154, 0.114, 0.109, 0.108, 0.107, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.105, 0.106, 0.105, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.105, 0.106, 0.105, 0.105, 0.105, 0.106, 0.106, 0.106, 0.105, 0.105, 0.105, 0.106, 0.106, 0.105, 0.105, 0.105], 'val_loss': [0.183, 0.1, 0.085, 0.088, 0.086, 0.086, 0.086, 0.085, 0.087, 0.089, 0.085, 0.087, 0.085, 0.108, 0.129, 0.084, 0.087, 0.086, 0.091, 0.094, 0.084, 0.085, 0.085, 0.086, 0.091, 0.084, 0.085, 0.084, 0.084, 0.084, 0.089, 0.085, 0.089, 0.084, 0.085, 0.084, 0.085, 0.09, 0.084, 0.085, 0.086, 0.085, 0.089, 0.086, 0.086, 0.084, 0.084, 0.084, 0.088, 0.188]}	50	50	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:deconv1d out_channels:51 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:deconv1d out_channels:125 kernel_size:4 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 layer:fc act:selu out_features:200 bias:True input:13 learning:rmsprop lr:0.004085298026577847 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:34 epochs:50	50	200	True	0.96626		375271	15	-1	114.47868251800537	{'train_loss': [0.305, 0.18, 0.187, 0.152, 0.12, 0.124, 0.112, 0.113, 0.11, 0.111, 0.111, 0.11, 0.11, 0.11, 0.113, 0.113, 0.11, 0.11, 0.111, 0.11, 0.11, 0.113, 0.112, 0.112, 0.11, 0.11, 0.11, 0.111, 0.111, 0.109, 0.111, 0.111, 0.114, 0.111, 0.111, 0.11, 0.109, 0.11, 0.109, 0.11, 0.109, 0.111, 0.111, 0.11, 0.114, 0.109, 0.111, 0.11, 0.11, 0.111], 'val_loss': [0.164, 0.15, 0.099, 0.22, 0.507, 0.107, 0.096, 0.111, 0.143, 0.27, 0.132, 0.111, 0.157, 0.217, 0.106, 0.242, 0.132, 0.154, 0.554, 0.162, 0.529, 0.098, 0.096, 0.095, 0.101, 0.207, 0.152, 0.171, 0.103, 0.156, 0.209, 0.125, 0.109, 0.164, 0.207, 0.102, 0.163, 0.218, 0.117, 0.116, 0.095, 0.281, 0.091, 0.151, 0.106, 0.126, 0.106, 0.116, 0.176, 0.882]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:27 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:conv1d out_channels:35 kernel_size:4 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:30 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:81 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 layer:conv1d out_channels:119 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:deconv1d out_channels:99 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:12 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 layer:fc act:selu out_features:200 bias:True input:14 learning:rmsprop lr:0.0006449537531992261 alpha:0.8357924228993512 weight_decay:0.0009547108081147019 batch_size:33 epochs:50	50	200	True	0.12364		262409	16	-1	113.85270690917969	{'train_loss': [0.285, 0.117, 0.112, 0.11, 0.109, 0.108, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.106, 0.107, 0.106, 0.107, 0.106, 0.107, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.107, 0.106, 0.107, 0.107, 0.107, 0.106, 0.107, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.106, 0.106, 0.106, 0.106, 0.106, 0.107, 0.107, 0.106], 'val_loss': [0.11, 0.092, 0.09, 0.091, 0.089, 0.093, 0.09, 0.091, 0.096, 0.09, 0.089, 0.089, 0.089, 0.089, 0.096, 0.091, 0.104, 0.092, 0.09, 0.09, 0.089, 0.089, 0.09, 0.09, 0.091, 0.089, 0.09, 0.09, 0.09, 0.09, 0.089, 0.09, 0.09, 0.093, 0.09, 0.089, 0.089, 0.093, 0.09, 0.092, 0.092, 0.092, 0.09, 0.092, 0.092, 0.091, 0.098, 0.091, 0.09, 0.09]}	50	50	True
