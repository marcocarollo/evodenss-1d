id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:7 layer:deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 layer:conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:11 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:12 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:13 layer:fc act:selu out_features:200 bias:True input:14 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000867475404773022 batch_size:7 epochs:50	35	200	True	0.11045		344192	16	-1	205.01944303512573	{'train_loss': [0.13, 0.113, 0.112, 0.111, 0.111, 0.111, 0.11, 0.11, 0.11, 0.109, 0.109, 0.11, 0.11, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109], 'val_loss': [0.09, 0.095, 0.091, 0.091, 0.086, 0.087, 0.087, 0.086, 0.086, 0.087, 0.086, 0.086, 0.087, 0.086, 0.087, 0.091, 0.086, 0.086, 0.088, 0.088, 0.087, 0.086, 0.088, 0.089, 0.089, 0.089, 0.09, 0.088, 0.09, 0.086, 0.087, 0.086, 0.087, 0.09, 0.089]}	35	35	False
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:109 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:9 layer:conv1d out_channels:92 kernel_size:5 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:12 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:13 layer:deconv1d out_channels:93 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:True bias:True input:14 layer:fc act:selu out_features:200 bias:True input:15 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000351494593068316 batch_size:7 epochs:50	31	200	True	0.13683		7809621	17	-1	203.23032927513123	{'train_loss': [3.754, 4.02, 0.998, 0.167, 0.132, 0.122, 0.116, 0.112, 0.111, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.109, 0.108, 0.109, 0.108, 0.108, 0.108], 'val_loss': [4.145, 2.006, 0.181, 0.104, 0.116, 0.097, 0.091, 0.088, 0.087, 0.087, 0.088, 0.086, 0.087, 0.086, 0.086, 0.086, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086]}	31	31	False
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:21 kernel_size:4 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:40 kernel_size:2 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:91 kernel_size:1 stride:1 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:9 layer:conv1d out_channels:92 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:12 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:13 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:14 layer:fc act:selu out_features:200 bias:True input:15 learning:adam lr:0.0006449537531992261 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.00031369919221085326 batch_size:7 epochs:50	34	200	True	0.11536		308377	17	-1	203.16846370697021	{'train_loss': [0.135, 0.111, 0.11, 0.11, 0.109, 0.109, 0.109, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.107, 0.108, 0.108], 'val_loss': [0.092, 0.087, 0.087, 0.086, 0.086, 0.087, 0.087, 0.086, 0.086, 0.087, 0.087, 0.087, 0.087, 0.086, 0.089, 0.087, 0.089, 0.087, 0.087, 0.086, 0.091, 0.086, 0.091, 0.086, 0.086, 0.086, 0.086, 0.088, 0.088, 0.087, 0.087, 0.086, 0.086, 0.087]}	34	34	False
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:91 kernel_size:2 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:89 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:13 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:81 kernel_size:3 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:35 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:49 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:11 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:True input:12 layer:fc act:selu out_features:200 bias:True input:13 learning:adam lr:0.00011891338217255042 beta1:0.8231263215285294 beta2:0.8240598239796088 weight_decay:0.000867475404773022 batch_size:7 epochs:50	39	200	True	0.10666		305213	15	-1	202.60181307792664	{'train_loss': [0.159, 0.11, 0.109, 0.108, 0.108, 0.108, 0.108, 0.108, 0.108, 0.107, 0.108, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.107, 0.106, 0.106], 'val_loss': [0.09, 0.087, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.087, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086, 0.086]}	39	39	False
