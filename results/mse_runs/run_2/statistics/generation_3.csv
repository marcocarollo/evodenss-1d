id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:deconv1d out_channels:33 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.07893729429292703 alpha:0.5852124145979745 weight_decay:7.800959383075579e-05 batch_size:12 epochs:35	35	150	True	3.57923		402990	14	-1	127.67518067359924	{'train_loss': [0.45, 0.303, 0.255, 0.251, 0.251, 0.263, 0.294, 0.265, 0.281, 0.254, 0.24, 0.254, 0.25, 0.248, 0.243, 0.252, 0.261, 0.263, 0.274, 0.327, 0.282, 0.234, 0.289, 0.258, 0.244, 0.265, 0.26, 0.262, 0.276, 0.25, 0.253, 0.267, 0.342, 0.263, 0.255], 'val_loss': [0.888, 0.147, 0.124, 0.095, 0.23, 0.232, 0.172, 0.245, 1.859, 0.212, 0.329, 0.102, 0.115, 0.218, 0.121, 0.43, 0.708, 82.471, 0.194, 0.931, 0.168, 0.16, 2.951, 0.298, 3.308, 0.098, 0.734, 0.442, 1.678, 0.135, 0.629, 0.43, 0.145, 0.098, 1.317]}	35	35	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:33 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:rmsprop lr:0.07893729429292703 alpha:0.9805250256505911 weight_decay:7.800959383075579e-05 batch_size:12 epochs:35	35	150	True	61.45627		362382	12	-1	120.8274188041687	{'train_loss': [17.837, 20.62, 5.971, 8.069, 6.791, 6.87, 11.427, 10.664, 2.145, 6.874, 6.894, 6.258, 8.003, 7.053, 11.828, 11.513, 4.461, 0.485, 14.969, 7.904, 14.334, 5.631, 0.653, 13.682, 1.567, 15.281, 7.738, 6.941, 6.699, 8.054, 6.86, 7.706, 12.252, 0.882, 15.081], 'val_loss': [8.389, 5.737, 5.708, 5.734, 5.667, 4.837, 111.865, 5.113, 0.434, 5.737, 22.546, 5.843, 6.23, 6.489, 5.737, 5.72, 3.537, 0.104, 5.737, 5.737, 27.174, 1.868, 0.105, 2.112, 5.737, 5.737, 5.737, 4.881, 5.741, 5.588, 17.993, 6.656, 3.734, 0.211, 0.312]}	35	35	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:deconv1d out_channels:33 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.07893729429292703 alpha:0.5852124145979745 weight_decay:3.1588168152812126e-05 batch_size:12 epochs:35	35	150	True	3.40186		386910	13	-1	119.42196035385132	{'train_loss': [0.685, 0.305, 0.283, 0.249, 0.254, 0.252, 0.252, 0.255, 0.249, 0.268, 0.257, 0.246, 0.242, 0.242, 0.258, 0.262, 0.275, 0.248, 0.254, 0.25, 0.289, 0.253, 0.256, 0.24, 0.242, 0.262, 0.257, 0.272, 0.248, 0.24, 0.254, 0.25, 0.266, 0.263, 0.256], 'val_loss': [1.631, 0.159, 0.204, 0.697, 0.219, 2.483, 1.589, 0.451, 2.577, 0.092, 1.203, 0.162, 0.166, 0.215, 0.664, 0.11, 1.925, 0.148, 0.142, 0.124, 0.658, 0.166, 0.518, 0.39, 0.239, 1.026, 0.11, 0.126, 0.105, 0.114, 1.413, 0.132, 0.111, 0.225, 0.432]}	35	35	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:deconv1d out_channels:33 kernel_size:1 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:79 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:deconv1d out_channels:27 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.06120275202059677 alpha:0.5852124145979745 weight_decay:7.800959383075579e-05 batch_size:12 epochs:35	35	150	True	1.11238		384239	13	-1	119.60880541801453	{'train_loss': [0.492, 0.188, 0.165, 0.165, 0.177, 0.197, 0.164, 0.173, 0.166, 0.161, 0.168, 0.158, 0.158, 0.163, 0.175, 0.175, 0.173, 0.162, 0.168, 0.162, 0.162, 0.174, 0.183, 0.158, 0.161, 0.168, 0.176, 0.17, 0.168, 0.17, 0.16, 0.165, 0.163, 0.171, 0.166], 'val_loss': [0.461, 0.167, 1.086, 10.818, 0.357, 0.102, 0.101, 0.103, 0.123, 0.088, 0.547, 0.215, 0.288, 0.156, 0.091, 0.103, 0.093, 0.089, 0.199, 0.1, 0.14, 0.201, 0.322, 0.118, 0.095, 0.57, 0.871, 0.299, 0.37, 0.268, 0.292, 0.315, 0.173, 0.102, 0.269]}	35	35	True
