id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	32822.92188		452251	14	-1	222.69907474517822	{'train_loss': [405134.906, 331729.438, 315197.906, 300363.25, 288518.156, 280520.094, 274579.656, 270068.562, 267515.938, 264648.688, 263406.5, 261818.859, 260260.75, 259143.469, 257974.812, 256834.375, 255952.75, 256046.844, 254148.203, 253406.188, 252840.0, 252129.406, 251854.562, 250903.156, 250281.062, 250231.656, 248535.234, 248827.891, 248673.641, 247890.656, 247233.422, 247125.844, 246264.125, 245395.594, 245618.766, 245777.219, 244980.359, 243943.609, 243642.891, 243657.062, 244260.75, 242789.688, 242556.547, 242603.594, 242079.953, 240559.641, 241857.734, 241176.641, 240658.203, 240603.141, 239628.906, 239474.375, 239609.781, 238356.438, 239068.547, 238929.844, 238473.078, 238204.5, 237936.812, 237512.25, 236984.328, 236429.062, 237687.0, 236128.094, 235928.953, 237097.172, 236082.75, 235851.938, 235590.922, 235937.359, 235224.219, 234645.219, 234964.531, 235649.453, 234382.328, 233840.312, 233717.641, 234566.984, 234020.672, 233878.75, 233513.047, 232674.453, 233372.672, 233486.938, 232849.047, 232805.703, 232660.359, 232744.609, 231369.938, 231582.312, 230911.656, 232398.859, 231651.906, 230786.625, 231330.891, 231210.078, 231636.141, 230946.828, 230305.234, 231265.844], 'val_loss': [3187.662, 3011.778, 2867.958, 2787.403, 2736.055, 2698.998, 2633.39, 2594.563, 2573.558, 2560.535, 2557.229, 2540.114, 2513.349, 2514.472, 2509.231, 2486.141, 2499.446, 2477.081, 2496.91, 2456.406, 2462.79, 2458.035, 2450.899, 2430.003, 2452.899, 2444.88, 2410.263, 2417.459, 2421.186, 2420.441, 2409.25, 2416.722, 2392.827, 2401.923, 2409.881, 2406.156, 2403.536, 2389.767, 2393.316, 2384.906, 2396.604, 2375.949, 2377.256, 2386.982, 2391.782, 2372.872, 2365.766, 2383.8, 2373.525, 2358.5, 2369.44, 2355.14, 2359.778, 2364.214, 2373.874, 2361.374, 2349.438, 2360.765, 2369.784, 2374.418, 2361.594, 2343.987, 2359.105, 2364.594, 2354.504, 2351.882, 2351.328, 2350.956, 2344.305, 2352.522, 2369.436, 2350.937, 2365.882, 2357.747, 2363.446, 2349.285, 2350.933, 2327.775, 2358.933, 2338.683, 2373.897, 2332.404, 2325.628, 2349.524, 2334.038, 2327.214, 2310.768, 2333.383, 2327.765, 2335.619, 2331.146, 2323.526, 2346.327, 2333.049, 2335.728, 2309.451, 2321.358, 2318.959, 2332.984, 2317.967]}	100	100	True
