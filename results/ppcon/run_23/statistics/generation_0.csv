id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	4016.15869		452251	14	-1	183.8055398464203	{'train_loss': [335686.781, 176653.781, 155163.422, 142751.0, 135063.422, 129110.109, 124411.07, 120794.977, 115972.117, 113710.812, 110452.297, 107382.305, 104764.484, 103872.867, 102740.164, 100156.109, 99964.555, 97900.641, 97669.938, 96596.555, 95479.719, 94339.07, 94051.992, 91881.086, 92628.711, 91937.695, 91403.695, 89818.867, 89614.148, 89369.859, 88142.484, 87874.148, 87562.219, 87425.516, 87315.141, 86809.57, 86567.086, 86008.992, 85334.352, 85403.867, 84675.062, 84704.156, 84491.758, 83741.227, 84458.164, 82975.031, 83847.18, 83018.531, 83411.203, 83008.703, 82282.766, 83119.086, 81677.148, 82020.359, 81076.203, 81225.266, 81399.266, 81163.562, 80615.062, 81348.141, 79414.008, 79831.156, 79512.195, 79528.695, 79390.625, 79048.117, 78856.898, 78866.867, 78942.109, 78492.867, 79371.539, 77830.164, 78482.344, 78989.031, 78526.789, 76767.742, 77482.648, 77059.93, 78291.531, 77401.781, 77266.477, 76856.227, 77076.625, 76394.125, 76815.078, 76887.852, 76239.844, 76102.023, 75640.109, 76101.406, 75628.633, 76610.312, 75589.945, 75186.328, 75168.672, 76105.078, 74687.727, 75888.555, 74573.844, 75424.93], 'val_loss': [4573.522, 1762.332, 1892.86, 1728.924, 1667.586, 1598.531, 1585.108, 1534.686, 1467.32, 1509.355, 1473.678, 1448.499, 1432.665, 1477.111, 1307.044, 1333.012, 1337.616, 1307.582, 1308.332, 1197.055, 1320.323, 1205.195, 1185.745, 1259.847, 1265.846, 1263.328, 1170.235, 1176.239, 1181.066, 1165.57, 1147.978, 1151.089, 1115.744, 1101.102, 1149.716, 1091.463, 1111.047, 1210.178, 1129.225, 1097.725, 1119.199, 1123.712, 1082.883, 1027.12, 1074.477, 1085.781, 1052.325, 1078.647, 1076.332, 1083.443, 1037.697, 1074.51, 1051.965, 1017.291, 1061.245, 1019.728, 1068.422, 1042.018, 1168.51, 1073.808, 1017.372, 1085.421, 994.329, 987.765, 1005.562, 997.763, 1060.814, 1088.034, 1076.036, 1010.937, 1076.303, 994.611, 1058.2, 995.915, 958.655, 1017.87, 985.299, 987.212, 1035.387, 1035.005, 999.627, 964.394, 1015.619, 1035.901, 979.036, 1005.452, 1030.497, 1042.858, 987.87, 1006.355, 977.809, 1016.991, 995.974, 990.135, 957.71, 957.672, 1020.26, 965.417, 969.339, 938.127]}	100	100	True
