id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	32458.43164		452251	14	-1	222.07205605506897	{'train_loss': [401386.031, 331352.219, 310219.906, 296894.5, 287867.0, 282093.5, 277701.719, 273229.906, 270145.25, 268119.969, 265520.062, 264728.5, 262888.75, 261429.062, 260964.516, 259339.125, 257568.781, 257386.438, 256061.719, 256086.469, 255368.375, 253344.188, 252989.016, 252507.031, 251135.109, 250964.906, 250211.078, 250145.391, 249703.875, 248772.016, 247767.641, 247158.5, 246814.359, 246549.188, 246288.578, 245448.438, 244794.516, 244140.484, 243603.438, 243281.5, 243520.594, 242631.594, 242229.094, 242207.141, 241378.078, 241826.922, 240665.438, 240307.016, 239520.094, 239646.75, 238877.203, 239179.688, 238738.203, 238719.594, 238157.734, 238528.938, 237390.844, 237572.297, 237452.828, 236770.266, 236502.812, 236183.609, 236440.234, 235138.047, 235807.484, 234608.109, 234788.219, 233369.281, 233968.594, 233615.062, 233564.828, 234082.922, 234210.062, 233537.578, 233385.406, 232222.5, 231842.25, 231966.328, 232073.812, 232180.359, 231945.578, 231095.812, 230542.75, 231402.516, 231113.844, 230559.156, 230039.141, 229275.797, 230563.594, 229660.344, 230110.516, 229913.297, 228865.016, 228819.156, 229463.859, 228784.812, 227624.734, 228453.641, 228813.469, 227747.562], 'val_loss': [3191.583, 3020.248, 2858.05, 2819.847, 2716.572, 2687.725, 2622.51, 2615.486, 2574.569, 2549.272, 2536.266, 2521.752, 2515.02, 2491.599, 2518.779, 2496.341, 2480.298, 2468.637, 2464.614, 2436.352, 2438.791, 2436.972, 2437.535, 2424.053, 2423.153, 2422.048, 2429.863, 2407.691, 2402.798, 2406.731, 2412.491, 2404.922, 2406.08, 2381.248, 2399.421, 2401.527, 2401.107, 2415.313, 2388.258, 2375.93, 2369.896, 2392.566, 2379.992, 2389.744, 2373.337, 2371.205, 2373.629, 2340.861, 2360.526, 2368.085, 2344.512, 2356.42, 2351.636, 2330.31, 2345.013, 2335.533, 2362.803, 2341.271, 2336.72, 2342.356, 2320.114, 2335.876, 2326.413, 2324.443, 2314.133, 2322.835, 2313.155, 2286.713, 2292.08, 2295.221, 2300.383, 2330.905, 2290.494, 2297.161, 2284.515, 2296.167, 2298.016, 2281.434, 2296.515, 2303.929, 2282.249, 2287.324, 2299.063, 2279.367, 2291.027, 2281.713, 2283.039, 2293.743, 2267.77, 2272.488, 2276.522, 2273.304, 2278.713, 2268.868, 2262.613, 2260.092, 2278.764, 2265.539, 2262.925, 2255.527]}	100	100	True
