id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	25836.96289		452251	14	-1	220.85430479049683	{'train_loss': [424405.906, 350723.312, 323878.625, 304128.562, 294926.812, 289027.25, 284578.562, 266175.812, 252861.281, 246133.75, 241279.625, 237725.844, 235817.219, 233045.25, 231355.5, 229212.109, 228292.734, 226967.984, 225497.922, 224494.125, 224418.906, 223622.625, 221743.547, 221014.406, 221160.156, 219362.797, 219503.984, 219360.062, 219144.969, 216779.203, 217151.922, 216715.375, 216557.516, 215493.328, 215466.094, 214372.156, 214154.906, 213560.094, 213459.625, 212654.844, 212109.266, 212098.297, 211690.328, 211651.953, 210601.172, 211112.453, 210689.969, 209942.859, 209526.766, 209851.828, 208682.812, 208796.719, 208304.422, 208596.156, 207904.656, 207273.391, 207943.203, 206878.578, 207683.047, 205966.938, 206692.516, 206459.969, 206096.625, 205023.828, 205654.328, 205116.828, 204966.281, 204565.469, 204705.469, 204157.172, 203544.578, 204501.469, 203821.562, 203138.438, 203772.266, 202215.609, 202952.266, 202296.469, 201823.109, 202007.797, 201773.672, 201137.25, 201579.859, 201324.453, 201252.047, 200828.312, 200706.688, 200510.875, 200283.062, 199664.031, 200036.797, 199724.078, 199768.453, 198873.188, 199701.016, 198374.969, 198365.812, 197147.953, 197682.719, 198313.359], 'val_loss': [3571.541, 3338.174, 3146.777, 3101.23, 3072.739, 3049.981, 2939.828, 2701.614, 2608.16, 2562.729, 2513.929, 2480.364, 2488.613, 2458.69, 2460.65, 2466.811, 2446.75, 2430.994, 2423.589, 2427.37, 2432.014, 2408.433, 2421.129, 2392.238, 2415.217, 2394.983, 2402.386, 2385.561, 2412.562, 2363.734, 2395.687, 2355.119, 2341.397, 2338.644, 2365.461, 2353.886, 2352.217, 2334.682, 2346.903, 2335.463, 2349.441, 2332.39, 2313.427, 2319.635, 2347.462, 2322.159, 2335.519, 2301.995, 2328.947, 2310.541, 2311.044, 2291.329, 2319.179, 2325.691, 2302.921, 2293.546, 2304.933, 2315.071, 2291.701, 2299.286, 2294.338, 2310.952, 2287.988, 2298.485, 2297.961, 2286.077, 2276.306, 2280.348, 2301.188, 2272.868, 2294.893, 2285.092, 2285.396, 2295.931, 2299.639, 2278.759, 2272.372, 2292.155, 2273.904, 2271.658, 2251.967, 2253.603, 2288.952, 2258.82, 2250.133, 2247.901, 2263.88, 2243.129, 2240.388, 2246.137, 2261.604, 2245.761, 2241.64, 2246.68, 2243.074, 2259.123, 2256.433, 2232.662, 2238.161, 2243.055]}	100	100	True
