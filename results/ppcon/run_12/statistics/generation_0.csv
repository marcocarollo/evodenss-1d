id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	26544.45117		452251	14	-1	218.7016670703888	{'train_loss': [421430.969, 303549.531, 275826.844, 261495.234, 253615.844, 249773.312, 246238.312, 242981.391, 241042.609, 238953.297, 237176.312, 235207.484, 233763.734, 232495.234, 231495.266, 229892.375, 228899.156, 227838.141, 226914.969, 226229.203, 224911.031, 224744.766, 223449.859, 223266.219, 222694.828, 222293.25, 221327.359, 220876.875, 220677.906, 219921.0, 219970.266, 218675.344, 218622.844, 218716.297, 218183.797, 217262.359, 217049.109, 216235.438, 215713.828, 215637.922, 215266.906, 215260.109, 214203.453, 213904.297, 213821.016, 213805.547, 213551.531, 212533.953, 212642.719, 212662.031, 212098.0, 211760.812, 212106.172, 211129.047, 211198.203, 211097.188, 210359.984, 210170.234, 209297.656, 209851.594, 208899.734, 209098.422, 209156.562, 208463.656, 208863.953, 208229.156, 208655.609, 207975.422, 207556.719, 206972.484, 207637.328, 207080.859, 207065.609, 206571.266, 206720.594, 206494.266, 206304.328, 205959.406, 206318.312, 206378.031, 205660.891, 205502.094, 205825.828, 205434.391, 205215.406, 204847.172, 204636.922, 204785.719, 205028.547, 205109.422, 204093.828, 203764.516, 204341.016, 203610.672, 203136.078, 202915.531, 203349.562, 203144.953, 202548.266, 202880.812], 'val_loss': [3859.925, 2975.31, 2894.471, 2766.505, 2655.328, 2656.647, 2618.002, 2611.483, 2599.213, 2568.838, 2544.429, 2542.738, 2531.855, 2511.984, 2518.508, 2507.421, 2515.758, 2485.282, 2488.511, 2482.148, 2474.268, 2463.277, 2464.797, 2453.599, 2435.018, 2421.58, 2434.387, 2428.179, 2421.934, 2417.965, 2408.274, 2412.35, 2403.973, 2433.955, 2410.421, 2406.703, 2401.566, 2401.84, 2404.382, 2388.245, 2403.581, 2385.754, 2379.662, 2400.905, 2384.196, 2394.918, 2391.616, 2379.679, 2390.554, 2379.021, 2389.884, 2362.847, 2371.928, 2375.904, 2390.82, 2377.182, 2364.193, 2372.702, 2393.49, 2379.807, 2360.09, 2363.522, 2351.812, 2355.569, 2371.273, 2388.123, 2366.692, 2374.252, 2352.142, 2373.367, 2337.005, 2362.984, 2341.987, 2345.808, 2341.489, 2353.818, 2360.173, 2353.96, 2349.326, 2342.262, 2334.085, 2363.056, 2334.822, 2349.695, 2350.139, 2338.663, 2364.05, 2344.159, 2341.562, 2329.698, 2362.073, 2336.729, 2348.545, 2331.845, 2339.496, 2369.468, 2353.283, 2348.545, 2339.113, 2337.542]}	100	100	True
