id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	32316.38867		452251	14	-1	223.0683753490448	{'train_loss': [408341.0, 335462.031, 318449.656, 305022.312, 294098.75, 286764.812, 282252.094, 278364.438, 273992.594, 270759.062, 268286.781, 266428.656, 264972.344, 262611.594, 260729.328, 259950.281, 257840.594, 257156.594, 256091.5, 255494.078, 254410.047, 253269.875, 252382.047, 251344.734, 250169.812, 249785.469, 249420.094, 248874.734, 247488.812, 247232.531, 246892.234, 245547.172, 245421.578, 244621.922, 244924.547, 243344.766, 243456.266, 242062.109, 242228.016, 240995.125, 241030.438, 241010.188, 240139.859, 240666.438, 240352.922, 239362.953, 238701.234, 239109.0, 237817.641, 238120.734, 237053.281, 236610.188, 236855.984, 236391.109, 236161.75, 236208.359, 234878.281, 234689.625, 235157.266, 235052.219, 233867.484, 233382.0, 234606.688, 233280.391, 233573.75, 232745.109, 232481.703, 232700.156, 231948.625, 232324.891, 232014.719, 232372.359, 230719.609, 232728.188, 231348.328, 230832.75, 229689.719, 231221.922, 230064.156, 229929.453, 229008.859, 228656.766, 229681.297, 229271.656, 229106.516, 228721.906, 227815.359, 228005.734, 227753.266, 228181.062, 228123.781, 227378.562, 227892.844, 227261.25, 226105.156, 226731.047, 226941.422, 226801.766, 225681.188, 226054.281], 'val_loss': [3235.425, 3085.922, 2946.665, 2867.098, 2787.056, 2713.035, 2736.519, 2640.414, 2616.158, 2596.227, 2581.133, 2551.994, 2553.833, 2517.929, 2510.93, 2484.012, 2473.094, 2468.389, 2453.568, 2441.272, 2439.7, 2423.988, 2436.175, 2412.461, 2407.293, 2421.955, 2419.255, 2396.682, 2381.888, 2404.26, 2390.053, 2400.785, 2394.69, 2401.489, 2404.009, 2379.83, 2382.504, 2380.421, 2354.914, 2352.547, 2364.46, 2349.975, 2329.059, 2359.1, 2337.761, 2362.855, 2346.24, 2344.668, 2333.188, 2354.508, 2343.962, 2322.785, 2322.659, 2345.188, 2293.294, 2315.138, 2303.773, 2317.275, 2302.675, 2329.865, 2311.043, 2296.337, 2296.824, 2305.98, 2270.846, 2286.735, 2270.386, 2293.085, 2274.914, 2290.864, 2311.018, 2280.379, 2289.44, 2281.613, 2282.952, 2301.082, 2296.063, 2274.633, 2258.01, 2262.44, 2262.003, 2265.152, 2270.744, 2255.519, 2275.962, 2283.031, 2279.495, 2254.121, 2244.675, 2269.92, 2264.69, 2260.038, 2250.521, 2259.383, 2259.868, 2243.593, 2242.316, 2261.391, 2260.597, 2273.33]}	100	100	True
