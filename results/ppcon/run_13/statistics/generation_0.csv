id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	26270.98047		452251	14	-1	219.1696617603302	{'train_loss': [438366.688, 331105.5, 278388.875, 259031.703, 249952.062, 243931.469, 240202.266, 236871.953, 234777.078, 232981.219, 231340.953, 229787.562, 229056.312, 227641.234, 226649.219, 225601.766, 224406.906, 223145.25, 222093.391, 221506.297, 220717.078, 219817.734, 218989.531, 218665.359, 217745.578, 216941.578, 216872.609, 216318.906, 216255.672, 214993.156, 215229.0, 214511.797, 213433.75, 213446.453, 212905.047, 212976.094, 212484.797, 212350.453, 211627.391, 211422.766, 210536.234, 210381.172, 209812.781, 209880.719, 209769.766, 209461.109, 208968.984, 208684.875, 207921.969, 208252.609, 207672.828, 207478.484, 207649.547, 207208.391, 207024.188, 206261.609, 206935.375, 206581.031, 205460.219, 205406.656, 205090.047, 204669.156, 204781.172, 204658.062, 204622.188, 203866.922, 203458.516, 202980.375, 203426.938, 202706.391, 202849.359, 202600.984, 201832.875, 202084.391, 201620.609, 201589.484, 201455.703, 201340.516, 200235.562, 199924.844, 200393.141, 199619.922, 199674.734, 199337.516, 199356.391, 198958.625, 199404.141, 199131.75, 199187.5, 198761.188, 198543.609, 197919.875, 197511.969, 198181.297, 197656.391, 197288.844, 198193.969, 197586.719, 196665.656, 197116.844], 'val_loss': [3805.684, 3013.077, 2893.317, 2842.549, 2680.151, 2627.006, 2634.086, 2640.016, 2559.52, 2554.087, 2525.003, 2530.24, 2550.99, 2552.55, 2529.078, 2495.135, 2509.045, 2477.299, 2483.942, 2492.347, 2499.136, 2506.357, 2449.359, 2424.731, 2440.502, 2483.091, 2450.087, 2437.615, 2451.141, 2437.674, 2437.779, 2439.772, 2440.943, 2428.527, 2399.124, 2424.322, 2392.496, 2379.916, 2420.161, 2373.338, 2390.396, 2446.606, 2436.381, 2421.708, 2437.352, 2381.246, 2391.131, 2412.591, 2391.709, 2422.449, 2375.565, 2375.364, 2372.097, 2371.114, 2386.97, 2394.433, 2357.221, 2352.83, 2390.211, 2368.965, 2356.1, 2357.404, 2356.592, 2333.459, 2330.259, 2361.031, 2348.005, 2284.764, 2308.348, 2305.734, 2340.471, 2323.954, 2326.869, 2311.729, 2294.759, 2322.993, 2279.624, 2318.314, 2287.435, 2298.435, 2257.103, 2288.385, 2309.232, 2297.48, 2281.649, 2291.032, 2297.91, 2308.015, 2268.772, 2267.993, 2282.86, 2289.775, 2276.065, 2278.765, 2268.629, 2290.391, 2302.813, 2263.61, 2275.398, 2274.24]}	100	100	True
