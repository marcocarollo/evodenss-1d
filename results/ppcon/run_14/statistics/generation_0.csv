id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	25490.63477		452251	14	-1	221.00702285766602	{'train_loss': [401226.156, 301510.375, 277704.469, 264482.875, 257439.359, 252498.688, 248443.594, 245526.781, 242984.031, 240406.234, 238425.234, 236369.078, 235151.328, 234052.703, 232145.344, 231316.031, 229872.812, 228900.938, 227869.734, 226829.906, 226033.984, 224896.094, 223810.609, 222915.109, 222159.828, 221397.703, 220402.328, 219705.578, 219460.844, 218493.062, 217828.266, 217276.0, 216497.438, 215691.969, 215112.203, 214913.375, 214138.641, 213426.453, 212941.781, 213031.016, 211732.875, 211730.188, 211285.047, 210901.922, 210281.812, 209537.328, 209633.625, 209593.016, 209400.0, 208303.453, 207845.141, 207367.297, 207639.719, 207003.5, 206538.766, 206733.75, 206105.156, 205481.531, 205351.297, 205418.391, 204459.219, 204891.234, 204722.641, 204283.547, 204193.719, 204285.359, 203905.875, 202959.281, 202907.875, 202779.719, 201865.578, 202544.281, 202507.203, 202110.938, 201767.828, 201756.828, 200771.016, 201342.75, 200495.812, 201019.5, 200274.484, 200640.031, 200642.812, 199973.531, 200238.172, 199445.328, 198992.219, 199184.141, 198966.938, 198264.453, 198777.328, 198896.859, 197957.031, 198386.016, 198191.781, 198482.641, 197848.391, 198088.969, 196613.719, 197194.656], 'val_loss': [3395.139, 2992.842, 3063.047, 2982.399, 2831.253, 2752.074, 2727.319, 2718.241, 2637.695, 2629.185, 2586.785, 2592.328, 2564.76, 2566.835, 2541.673, 2524.905, 2520.363, 2498.886, 2493.582, 2470.997, 2471.125, 2439.185, 2428.688, 2426.609, 2436.956, 2421.081, 2397.886, 2391.483, 2390.287, 2363.867, 2400.697, 2364.544, 2352.707, 2373.388, 2372.563, 2366.794, 2359.96, 2372.44, 2373.885, 2344.501, 2370.441, 2362.018, 2343.015, 2340.997, 2333.123, 2313.916, 2344.924, 2313.132, 2296.032, 2326.439, 2298.839, 2316.071, 2311.495, 2307.569, 2318.624, 2285.994, 2291.588, 2304.814, 2314.152, 2298.526, 2309.028, 2288.499, 2283.173, 2270.708, 2289.883, 2272.568, 2278.764, 2259.477, 2281.817, 2279.948, 2247.863, 2256.826, 2250.706, 2251.543, 2238.156, 2230.541, 2261.013, 2232.869, 2246.501, 2255.224, 2231.895, 2232.713, 2240.099, 2235.887, 2233.714, 2221.077, 2241.159, 2226.641, 2212.996, 2232.173, 2223.914, 2232.791, 2209.372, 2218.191, 2208.693, 2210.373, 2217.817, 2210.125, 2220.163, 2224.041]}	100	100	True
