id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	25485.20117		452251	14	-1	215.98868250846863	{'train_loss': [427813.125, 348282.719, 315350.688, 300424.688, 291752.125, 287304.594, 283533.469, 267780.812, 252741.672, 246397.297, 241562.797, 238414.422, 236228.031, 233473.047, 231867.203, 230596.359, 228951.031, 228340.344, 227205.656, 225503.281, 225098.812, 224714.156, 223213.25, 222939.891, 221938.688, 221687.328, 220138.766, 220008.297, 219589.297, 218688.047, 218296.734, 217878.188, 217478.719, 216654.078, 216127.203, 214858.578, 215012.844, 214498.812, 214280.906, 213728.109, 212639.984, 213527.547, 212626.562, 211997.141, 211603.609, 210902.812, 210359.625, 209733.375, 209129.562, 208690.438, 208215.234, 207519.125, 208348.281, 207867.094, 207471.312, 206731.953, 206047.734, 205604.328, 205602.734, 205166.438, 205134.672, 204555.328, 203748.031, 204181.781, 204454.828, 203575.484, 202779.047, 202632.562, 202788.484, 202537.5, 201866.312, 202160.141, 201214.938, 201876.938, 200949.812, 201093.641, 201111.906, 201099.625, 200045.719, 199637.562, 200473.891, 199727.266, 200000.0, 198798.547, 199041.016, 198626.625, 198437.156, 198643.203, 197978.0, 197662.641, 197874.5, 197737.422, 197270.297, 197218.375, 197375.203, 197012.125, 196199.938, 196578.719, 196669.359, 195960.688], 'val_loss': [3554.106, 3299.421, 3097.78, 3045.758, 3030.941, 3022.302, 2967.465, 2762.599, 2645.788, 2580.594, 2584.684, 2527.975, 2525.819, 2509.98, 2507.676, 2479.825, 2464.427, 2470.358, 2432.482, 2435.917, 2437.548, 2419.476, 2427.401, 2421.819, 2411.355, 2404.979, 2419.558, 2394.157, 2406.093, 2395.397, 2382.841, 2369.531, 2371.084, 2392.271, 2364.27, 2363.972, 2376.567, 2391.967, 2355.586, 2360.239, 2368.807, 2336.102, 2328.985, 2341.984, 2329.249, 2317.189, 2322.423, 2314.375, 2323.675, 2321.655, 2298.341, 2292.131, 2286.138, 2286.594, 2265.945, 2273.054, 2293.104, 2279.741, 2302.212, 2285.085, 2263.416, 2292.424, 2279.248, 2252.766, 2259.682, 2283.311, 2276.471, 2271.552, 2256.224, 2260.576, 2272.905, 2273.625, 2271.029, 2283.852, 2272.877, 2248.703, 2246.606, 2239.829, 2257.42, 2260.348, 2281.918, 2261.269, 2255.81, 2228.486, 2246.6, 2229.865, 2236.53, 2261.737, 2223.236, 2236.767, 2229.833, 2253.723, 2232.284, 2226.598, 2245.238, 2226.39, 2230.969, 2225.342, 2241.273, 2241.1]}	100	100	True
