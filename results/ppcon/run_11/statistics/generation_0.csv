id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	26862.35938		452251	14	-1	217.75467777252197	{'train_loss': [427921.938, 309547.875, 276142.719, 262867.969, 255332.719, 250758.297, 247005.953, 243463.531, 240916.172, 238617.906, 236869.375, 235023.656, 233491.766, 232433.016, 231000.859, 229798.547, 229016.656, 228108.812, 227439.422, 226020.234, 226029.734, 225295.484, 224239.438, 223735.797, 223367.406, 221800.547, 221612.078, 221261.391, 220643.625, 220199.781, 219757.172, 219053.0, 218911.078, 218436.031, 217378.062, 217224.391, 217016.859, 216967.484, 216791.359, 215912.469, 215563.922, 215118.156, 214781.656, 214957.328, 214393.719, 213099.625, 214276.078, 213156.781, 213197.469, 213044.156, 212322.281, 212347.094, 212800.703, 212083.891, 211890.953, 212200.234, 211677.406, 210456.734, 211160.5, 210573.703, 210356.672, 210544.203, 209749.828, 209982.875, 209773.25, 209815.562, 208846.141, 209386.828, 209201.859, 208750.031, 207964.422, 208363.578, 208195.312, 207722.672, 207844.797, 208242.938, 207808.688, 206893.0, 207142.438, 206557.719, 206734.516, 206353.266, 206532.828, 206634.672, 206179.469, 206156.094, 206190.188, 205408.188, 205513.375, 205375.516, 205303.875, 205108.812, 204884.672, 204910.406, 204409.297, 204357.75, 205041.516, 204617.172, 204779.703, 204065.172], 'val_loss': [3490.013, 2986.518, 2905.134, 2707.424, 2712.789, 2641.274, 2608.103, 2588.01, 2553.319, 2544.213, 2520.212, 2510.648, 2503.52, 2485.279, 2483.968, 2470.612, 2488.053, 2465.899, 2459.656, 2478.074, 2448.017, 2458.802, 2460.093, 2428.511, 2437.269, 2431.735, 2428.199, 2419.078, 2429.66, 2397.792, 2402.767, 2426.776, 2413.644, 2430.896, 2398.94, 2400.807, 2399.099, 2413.094, 2401.623, 2381.125, 2379.818, 2387.657, 2386.128, 2387.295, 2357.647, 2389.005, 2377.896, 2372.604, 2377.886, 2365.644, 2371.463, 2365.716, 2371.397, 2381.359, 2382.782, 2376.798, 2347.289, 2392.569, 2374.497, 2371.483, 2364.94, 2355.946, 2361.613, 2366.91, 2372.312, 2368.03, 2359.58, 2344.205, 2357.885, 2350.273, 2364.154, 2374.104, 2352.841, 2343.702, 2350.557, 2329.699, 2356.975, 2352.05, 2331.772, 2356.171, 2354.478, 2348.442, 2342.188, 2354.404, 2351.24, 2346.01, 2356.763, 2350.107, 2337.289, 2358.497, 2353.772, 2345.089, 2344.645, 2335.589, 2345.52, 2333.304, 2341.912, 2345.145, 2323.381, 2340.224]}	100	100	True
