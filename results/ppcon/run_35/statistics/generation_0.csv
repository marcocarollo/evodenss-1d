id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:64 kernel_size:2 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:8 layer:deconv1d out_channels:64 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:32 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:adadelta batch_size:32 epochs:100	100	1000	True	33076.55469		452251	14	-1	222.8376808166504	{'train_loss': [421131.531, 348103.281, 322347.156, 313747.312, 308057.562, 303177.156, 299751.688, 296920.531, 293008.562, 288450.312, 284054.719, 278816.594, 274974.281, 271240.469, 268728.469, 266178.031, 263014.5, 261615.453, 260088.406, 259065.25, 257336.953, 257193.953, 255777.422, 255213.938, 254223.922, 253560.438, 252163.281, 251994.625, 248925.969, 249682.562, 248620.625, 248999.359, 247847.688, 247707.875, 247000.406, 246956.469, 245594.438, 246345.672, 245237.453, 244787.031, 244186.656, 243110.203, 242829.641, 242939.656, 243174.609, 241751.188, 240884.656, 241310.0, 241836.828, 240186.547, 240338.562, 239508.516, 239420.094, 239166.828, 238612.766, 239117.469, 239901.875, 238539.625, 237751.094, 237614.156, 236684.188, 236980.625, 236015.016, 236938.109, 235925.031, 236938.219, 235634.969, 235556.578, 235273.953, 235450.531, 235242.812, 235123.953, 234171.516, 234477.641, 234713.922, 234415.016, 234167.406, 233015.156, 232914.156, 232931.391, 233071.031, 232826.688, 231426.078, 232749.875, 231505.641, 231380.719, 232183.203, 232169.344, 231154.875, 231083.688, 231816.719, 230943.906, 230926.922, 229954.141, 230512.797, 229309.719, 230083.359, 229660.062, 229661.547, 229639.984], 'val_loss': [3290.713, 3013.742, 2911.158, 2873.447, 2852.116, 2818.424, 2797.898, 2781.31, 2746.323, 2695.04, 2657.34, 2594.527, 2574.345, 2548.162, 2530.092, 2543.702, 2489.531, 2468.892, 2498.294, 2479.444, 2468.674, 2472.801, 2442.767, 2439.712, 2464.207, 2436.104, 2450.349, 2433.958, 2417.979, 2410.537, 2422.35, 2413.77, 2381.691, 2397.341, 2393.201, 2387.685, 2398.658, 2396.982, 2358.861, 2360.803, 2358.814, 2369.231, 2362.38, 2348.635, 2336.513, 2377.4, 2381.502, 2320.308, 2333.066, 2329.184, 2344.298, 2329.013, 2332.946, 2321.183, 2329.148, 2341.696, 2327.531, 2344.253, 2350.994, 2330.096, 2332.25, 2314.487, 2350.161, 2306.721, 2322.44, 2314.861, 2339.79, 2314.242, 2318.766, 2314.518, 2332.93, 2308.21, 2344.793, 2277.104, 2296.218, 2299.447, 2330.88, 2308.258, 2296.197, 2306.501, 2289.18, 2288.23, 2317.494, 2288.151, 2289.616, 2287.737, 2304.692, 2290.623, 2294.947, 2303.622, 2260.688, 2257.183, 2318.026, 2269.359, 2276.747, 2280.895, 2296.326, 2259.056, 2278.048, 2270.297]}	100	100	True
