id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:89 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:deconv1d out_channels:69 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:rmsprop lr:0.0003452264297263473 alpha:0.5155739071878281 weight_decay:8.5280580681159e-05 batch_size:4 epochs:50	22	200	True	0.10536		360152	10	-1	208.87248873710632	{'train_loss': [0.755, 0.378, 0.217, 0.162, 0.142, 0.133, 0.129, 0.127, 0.127, 0.125, 0.124, 0.123, 0.121, 0.121, 0.121, 0.12, 0.12, 0.119, 0.119, 0.118, 0.118, 0.118], 'val_loss': [0.482, 0.27, 0.168, 0.13, 0.135, 0.106, 0.106, 0.104, 0.109, 0.102, 0.099, 0.101, 0.099, 0.099, 0.098, 0.096, 0.097, 0.097, 0.095, 0.097, 0.096, 0.096]}	22	22	False
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:89 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:deconv1d out_channels:69 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:rmsprop lr:0.0005430668521217026 alpha:0.5155739071878281 weight_decay:8.5280580681159e-05 batch_size:4 epochs:50	22	200	True	0.10752		360152	10	-1	205.08543300628662	{'train_loss': [0.657, 0.256, 0.163, 0.142, 0.134, 0.129, 0.128, 0.126, 0.125, 0.124, 0.123, 0.122, 0.121, 0.122, 0.12, 0.121, 0.12, 0.12, 0.12, 0.121, 0.121, 0.121], 'val_loss': [0.33, 0.16, 0.126, 0.112, 0.11, 0.107, 0.107, 0.101, 0.101, 0.1, 0.1, 0.099, 0.1, 0.098, 0.099, 0.1, 0.1, 0.098, 0.099, 0.098, 0.1, 0.099]}	22	22	False
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:19 kernel_size:3 stride:1 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:66 kernel_size:1 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:115 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:13 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:deconv1d out_channels:83 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:False bias:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:rmsprop lr:0.0003452264297263473 alpha:0.5155739071878281 weight_decay:8.5280580681159e-05 batch_size:64 epochs:50	50	200	True	0.43581		1057146	11	-1	132.2866928577423	{'train_loss': [8.955, 6.508, 5.806, 5.316, 4.898, 4.539, 4.172, 3.839, 3.544, 3.257, 3.001, 2.785, 2.584, 2.423, 2.263, 2.106, 1.958, 1.869, 1.743, 1.65, 1.577, 1.519, 1.456, 1.396, 1.36, 1.305, 1.279, 1.218, 1.184, 1.157, 1.116, 1.09, 1.049, 1.025, 0.994, 0.981, 0.948, 0.935, 0.909, 0.862, 0.86, 0.832, 0.817, 0.797, 0.777, 0.764, 0.735, 0.715, 0.709, 0.695], 'val_loss': [2.736, 2.601, 2.521, 2.139, 2.072, 1.912, 1.581, 1.677, 1.366, 1.188, 1.214, 1.164, 0.986, 1.178, 1.245, 0.938, 0.887, 1.061, 0.79, 0.853, 0.741, 0.762, 0.761, 0.8, 0.695, 0.661, 0.64, 0.717, 0.717, 0.688, 0.591, 0.534, 0.565, 0.548, 0.542, 0.57, 0.55, 0.624, 0.514, 0.534, 0.475, 0.447, 0.458, 0.611, 0.454, 0.43, 0.403, 0.421, 0.482, 0.423]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:89 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:deconv1d out_channels:69 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:adam lr:0.0003452264297263473 beta1:0.8160132942187965 beta2:0.9084107796516229 weight_decay:8.5280580681159e-05 batch_size:9 epochs:50	39	200	True	0.11034		360152	10	-1	202.32260084152222	{'train_loss': [0.984, 0.588, 0.461, 0.363, 0.291, 0.237, 0.2, 0.178, 0.165, 0.158, 0.153, 0.148, 0.145, 0.141, 0.138, 0.136, 0.134, 0.133, 0.131, 0.13, 0.129, 0.127, 0.127, 0.126, 0.125, 0.125, 0.124, 0.122, 0.121, 0.121, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12], 'val_loss': [0.626, 0.475, 0.375, 0.288, 0.243, 0.193, 0.166, 0.143, 0.139, 0.135, 0.129, 0.129, 0.125, 0.119, 0.118, 0.116, 0.116, 0.116, 0.112, 0.112, 0.11, 0.111, 0.11, 0.107, 0.105, 0.105, 0.104, 0.104, 0.102, 0.103, 0.101, 0.101, 0.102, 0.102, 0.101, 0.102, 0.102, 0.102, 0.102]}	39	39	False
