id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:-1,0,1,2,3 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:90 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:98 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:rmsprop lr:0.0003452264297263473 alpha:0.5155739071878281 weight_decay:7.08634222081631e-05 batch_size:4 epochs:50	19	200	True	0.1044		317464	11	-1	202.41775393486023	{'train_loss': [0.925, 0.463, 0.264, 0.178, 0.148, 0.135, 0.129, 0.125, 0.123, 0.122, 0.121, 0.119, 0.119, 0.119, 0.118, 0.118, 0.117, 0.118, 0.117], 'val_loss': [0.587, 0.309, 0.176, 0.135, 0.115, 0.114, 0.111, 0.104, 0.101, 0.101, 0.098, 0.098, 0.1, 0.098, 0.098, 0.096, 0.098, 0.095, 0.095]}	19	19	False
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:90 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:55 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:6 layer:fc act:selu out_features:200 bias:True input:7 learning:rmsprop lr:0.0003452264297263473 alpha:0.5155739071878281 weight_decay:7.08634222081631e-05 batch_size:35 epochs:50	50	200	True	0.16271		207515	9	-1	136.1568341255188	{'train_loss': [2.693, 1.608, 1.311, 1.133, 1.01, 0.925, 0.861, 0.805, 0.756, 0.712, 0.672, 0.633, 0.6, 0.565, 0.535, 0.508, 0.48, 0.454, 0.432, 0.411, 0.391, 0.373, 0.358, 0.344, 0.331, 0.32, 0.309, 0.3, 0.292, 0.284, 0.278, 0.273, 0.267, 0.262, 0.259, 0.255, 0.251, 0.248, 0.245, 0.242, 0.24, 0.238, 0.235, 0.233, 0.231, 0.229, 0.227, 0.226, 0.225, 0.223], 'val_loss': [1.146, 0.831, 0.771, 0.665, 0.613, 0.563, 0.529, 0.488, 0.466, 0.442, 0.42, 0.4, 0.357, 0.358, 0.341, 0.316, 0.304, 0.285, 0.275, 0.267, 0.252, 0.241, 0.223, 0.222, 0.219, 0.213, 0.206, 0.197, 0.186, 0.189, 0.181, 0.179, 0.176, 0.177, 0.17, 0.169, 0.167, 0.168, 0.163, 0.163, 0.16, 0.161, 0.159, 0.159, 0.157, 0.152, 0.155, 0.153, 0.153, 0.152]}	50	50	True
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:-1,0,1,2,3 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:110 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:deconv1d out_channels:101 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:106 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:rmsprop lr:0.0003064702858214278 alpha:0.5155739071878281 weight_decay:7.08634222081631e-05 batch_size:4 epochs:50	19	200	True	0.11107		370400	11	-1	208.2829704284668	{'train_loss': [1.008, 0.526, 0.311, 0.197, 0.155, 0.139, 0.129, 0.125, 0.122, 0.121, 0.12, 0.119, 0.119, 0.118, 0.117, 0.117, 0.117, 0.117, 0.118], 'val_loss': [0.646, 0.374, 0.216, 0.187, 0.141, 0.112, 0.118, 0.119, 0.111, 0.106, 0.106, 0.103, 0.102, 0.109, 0.121, 0.112, 0.104, 0.108, 0.104]}	19	19	False
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:30 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:conv1d out_channels:90 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:deconv1d out_channels:67 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:rmsprop lr:0.0009930544431214353 alpha:0.5155739071878281 weight_decay:7.08634222081631e-05 batch_size:4 epochs:50	19	200	True	0.12099		522092	11	-1	204.7390923500061	{'train_loss': [0.94, 0.268, 0.165, 0.148, 0.14, 0.136, 0.134, 0.133, 0.131, 0.132, 0.131, 0.131, 0.131, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13], 'val_loss': [0.481, 0.158, 0.138, 0.117, 0.128, 0.117, 0.119, 0.118, 0.111, 0.115, 0.116, 0.113, 0.108, 0.109, 0.108, 0.106, 0.111, 0.106, 0.114]}	19	19	False
