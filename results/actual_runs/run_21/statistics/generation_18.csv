id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:84 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:53 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:48 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:deconv1d out_channels:69 kernel_size:4 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:77 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:False bias:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:rmsprop lr:0.0003452264297263473 alpha:0.5411303302825197 weight_decay:8.557813678454613e-05 batch_size:4 epochs:50	18	200	True	0.11687		3068889	11	-1	203.0851149559021	{'train_loss': [2.559, 1.193, 0.573, 0.435, 0.341, 0.266, 0.214, 0.18, 0.164, 0.151, 0.144, 0.139, 0.136, 0.134, 0.132, 0.133, 0.131, 0.132], 'val_loss': [1.769, 0.578, 0.446, 0.349, 0.256, 0.188, 0.171, 0.149, 0.128, 0.12, 0.117, 0.111, 0.108, 0.106, 0.107, 0.105, 0.111, 0.108]}	18	18	False
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:84 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:83 kernel_size:3 stride:2 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:48 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:103 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:77 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:True bias:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:rmsprop lr:0.0003452264297263473 alpha:0.7893630173941732 weight_decay:8.557813678454613e-05 batch_size:4 epochs:50	19	200	True	0.11556		1007925	11	-1	201.74001026153564	{'train_loss': [1.475, 0.683, 0.428, 0.311, 0.246, 0.206, 0.18, 0.164, 0.151, 0.145, 0.139, 0.135, 0.132, 0.132, 0.132, 0.131, 0.13, 0.13, 0.131], 'val_loss': [0.875, 0.501, 0.337, 0.226, 0.2, 0.155, 0.149, 0.13, 0.116, 0.114, 0.122, 0.124, 0.108, 0.102, 0.105, 0.136, 0.109, 0.156, 0.107]}	19	19	False
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:42 kernel_size:5 stride:1 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:53 kernel_size:1 stride:1 padding_deconv:3 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:4 layer:deconv1d out_channels:48 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:103 kernel_size:5 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:77 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:False bias:True input:8 layer:fc act:selu out_features:200 bias:True input:9 learning:adam lr:0.0003452264297263473 beta1:0.818276416703716 beta2:0.8511059753588789 weight_decay:8.557813678454613e-05 batch_size:21 epochs:50	50	200	True	0.12943		1680774	11	-1	177.9692301750183	{'train_loss': [3.753, 2.586, 1.966, 1.424, 0.952, 0.748, 0.653, 0.592, 0.544, 0.5, 0.465, 0.438, 0.405, 0.38, 0.361, 0.341, 0.32, 0.305, 0.292, 0.283, 0.268, 0.259, 0.248, 0.241, 0.234, 0.226, 0.22, 0.209, 0.205, 0.198, 0.195, 0.19, 0.184, 0.179, 0.175, 0.173, 0.168, 0.165, 0.163, 0.161, 0.158, 0.156, 0.154, 0.152, 0.151, 0.149, 0.147, 0.147, 0.145, 0.143], 'val_loss': [3.216, 2.04, 1.603, 1.047, 0.871, 0.663, 0.651, 0.57, 0.637, 0.494, 0.485, 0.436, 0.394, 0.372, 0.367, 0.354, 0.325, 0.311, 0.293, 0.604, 0.377, 0.284, 0.849, 0.222, 0.286, 0.357, 0.21, 0.305, 0.197, 0.205, 0.294, 0.177, 0.222, 0.165, 0.177, 0.151, 0.157, 0.164, 0.146, 0.161, 0.142, 0.132, 0.132, 0.129, 0.127, 0.129, 0.126, 0.123, 0.121, 0.121]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:deconv1d out_channels:53 kernel_size:1 stride:1 padding_deconv:0 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:48 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:9 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:111 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:6 layer:conv1d out_channels:77 kernel_size:5 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:linear internal_batch_norm:False bias:True input:7 layer:fc act:selu out_features:200 bias:True input:8 learning:rmsprop lr:0.0003452264297263473 alpha:0.5411303302825197 weight_decay:2.2355706194260857e-05 batch_size:4 epochs:50	19	200	True	0.11183		3248590	10	-1	205.3859179019928	{'train_loss': [2.396, 0.906, 0.552, 0.426, 0.333, 0.261, 0.212, 0.18, 0.162, 0.152, 0.144, 0.14, 0.135, 0.134, 0.134, 0.131, 0.131, 0.129, 0.129], 'val_loss': [1.28, 0.589, 0.456, 0.357, 0.258, 0.2, 0.16, 0.138, 0.125, 0.12, 0.118, 0.113, 0.107, 0.108, 0.106, 0.11, 0.104, 0.107, 0.103]}	19	19	False
