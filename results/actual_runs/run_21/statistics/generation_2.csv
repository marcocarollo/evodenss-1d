id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:deconv1d out_channels:29 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0004931928948659201 alpha:0.739486597662427 weight_decay:2.2562982859454887e-05 batch_size:45 epochs:50	50	200	True	0.17268		577569	13	-1	144.36794638633728	{'train_loss': [4.735, 3.239, 2.838, 2.577, 2.391, 2.217, 2.059, 1.928, 1.799, 1.676, 1.559, 1.452, 1.366, 1.282, 1.199, 1.122, 1.048, 0.974, 0.91, 0.844, 0.785, 0.73, 0.677, 0.627, 0.586, 0.545, 0.516, 0.488, 0.464, 0.44, 0.422, 0.404, 0.389, 0.376, 0.364, 0.352, 0.343, 0.333, 0.324, 0.317, 0.311, 0.303, 0.297, 0.292, 0.286, 0.282, 0.278, 0.275, 0.271, 0.266], 'val_loss': [2.177, 1.858, 1.814, 1.546, 1.393, 1.295, 1.244, 1.212, 1.138, 1.058, 0.937, 0.881, 0.849, 0.803, 0.732, 0.722, 0.64, 0.61, 0.568, 0.529, 0.496, 0.478, 0.449, 0.427, 0.377, 0.38, 0.347, 0.328, 0.299, 0.299, 0.287, 0.262, 0.254, 0.242, 0.225, 0.231, 0.212, 0.208, 0.207, 0.194, 0.193, 0.186, 0.186, 0.181, 0.184, 0.171, 0.173, 0.177, 0.164, 0.166]}	50	50	True
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:deconv1d out_channels:36 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:66 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:98 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0004931928948659201 alpha:0.739486597662427 weight_decay:2.2562982859454887e-05 batch_size:4 epochs:50	16	200	True	0.10825		614905	13	-1	201.19072103500366	{'train_loss': [1.169, 0.502, 0.248, 0.161, 0.14, 0.131, 0.127, 0.124, 0.123, 0.121, 0.121, 0.12, 0.121, 0.12, 0.12, 0.12], 'val_loss': [0.685, 0.307, 0.163, 0.13, 0.124, 0.11, 0.104, 0.102, 0.101, 0.1, 0.1, 0.1, 0.1, 0.1, 0.101, 0.1]}	16	16	False
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:deconv1d out_channels:29 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:rmsprop lr:0.00032027443858464143 alpha:0.739486597662427 weight_decay:2.2562982859454887e-05 batch_size:45 epochs:50	50	200	True	0.25138		671841	12	-1	150.91773319244385	{'train_loss': [4.69, 3.324, 2.995, 2.798, 2.632, 2.458, 2.267, 2.078, 1.967, 1.879, 1.795, 1.722, 1.648, 1.58, 1.515, 1.458, 1.399, 1.336, 1.275, 1.226, 1.176, 1.126, 1.077, 1.022, 0.977, 0.934, 0.891, 0.85, 0.81, 0.772, 0.737, 0.702, 0.668, 0.636, 0.605, 0.579, 0.555, 0.533, 0.512, 0.492, 0.474, 0.458, 0.443, 0.43, 0.415, 0.402, 0.389, 0.381, 0.371, 0.363], 'val_loss': [2.24, 1.902, 1.748, 1.554, 1.537, 1.439, 1.321, 1.225, 1.227, 1.186, 1.147, 1.11, 1.063, 1.014, 0.973, 0.9, 0.869, 0.832, 0.817, 0.771, 0.763, 0.716, 0.682, 0.67, 0.65, 0.628, 0.591, 0.561, 0.537, 0.511, 0.489, 0.477, 0.457, 0.443, 0.419, 0.409, 0.381, 0.37, 0.359, 0.346, 0.33, 0.312, 0.303, 0.286, 0.283, 0.271, 0.267, 0.256, 0.25, 0.245]}	50	50	True
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:5 layer:conv1d out_channels:128 kernel_size:3 stride:1 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:7 layer:conv1d out_channels:101 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:9 layer:fc act:selu out_features:200 bias:True input:10 learning:rmsprop lr:0.0007224286119029714 alpha:0.739486597662427 weight_decay:2.2562982859454887e-05 batch_size:45 epochs:50	50	200	True	0.16449		437465	12	-1	152.9748523235321	{'train_loss': [4.255, 2.94, 2.556, 2.272, 2.064, 1.876, 1.701, 1.563, 1.437, 1.31, 1.196, 1.082, 0.984, 0.899, 0.821, 0.757, 0.696, 0.646, 0.601, 0.566, 0.533, 0.504, 0.478, 0.457, 0.437, 0.42, 0.406, 0.392, 0.379, 0.369, 0.358, 0.35, 0.341, 0.333, 0.325, 0.319, 0.312, 0.307, 0.302, 0.296, 0.291, 0.286, 0.283, 0.278, 0.274, 0.27, 0.267, 0.264, 0.261, 0.259], 'val_loss': [1.991, 1.612, 1.461, 1.332, 1.206, 1.112, 1.041, 0.946, 0.888, 0.789, 0.737, 0.666, 0.642, 0.558, 0.525, 0.498, 0.444, 0.417, 0.406, 0.362, 0.347, 0.328, 0.326, 0.288, 0.28, 0.258, 0.246, 0.247, 0.232, 0.224, 0.219, 0.216, 0.212, 0.197, 0.196, 0.207, 0.192, 0.187, 0.202, 0.19, 0.187, 0.179, 0.182, 0.174, 0.173, 0.179, 0.17, 0.179, 0.165, 0.159]}	50	50	True
