id	phenotype	num_epochs	total_training_time_allocated	is_valid_solution	fitness	accuracy	n_trainable_parameters	n_layers	n_layers_projector	training_time_spent	losses	n_epochs	total_epochs_trained	max_epochs_reached
0	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:18 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:36 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:deconv1d out_channels:66 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:98 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0004931928948659201 alpha:0.739486597662427 weight_decay:3.96521555266397e-05 batch_size:4 epochs:50	16	200	True	0.1085		618027	14	-1	203.02015900611877	{'train_loss': [1.212, 0.51, 0.253, 0.169, 0.145, 0.135, 0.132, 0.128, 0.125, 0.122, 0.121, 0.121, 0.12, 0.12, 0.12, 0.12], 'val_loss': [0.721, 0.331, 0.161, 0.13, 0.131, 0.114, 0.121, 0.135, 0.111, 0.101, 0.1, 0.102, 0.101, 0.1, 0.103, 0.1]}	16	16	False
1	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:18 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:-1,0,1,2,3 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:4 layer:deconv1d out_channels:36 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:deconv1d out_channels:66 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:98 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:rmsprop lr:0.0004931928948659201 alpha:0.739486597662427 weight_decay:3.96521555266397e-05 batch_size:4 epochs:50	33	400	True	0.10813		618027	14	-1	417.36662197113037	{'train_loss': [1.224, 0.526, 0.245, 0.162, 0.141, 0.132, 0.127, 0.124, 0.123, 0.122, 0.121, 0.121, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.119, 0.12, 0.12, 0.119, 0.119, 0.119, 0.119, 0.12, 0.12, 0.119, 0.12, 0.119, 0.12, 0.12], 'val_loss': [0.743, 0.332, 0.155, 0.124, 0.115, 0.108, 0.107, 0.102, 0.099, 0.101, 0.106, 0.114, 0.103, 0.101, 0.099, 0.106, 0.099, 0.1, 0.106, 0.099, 0.104, 0.099, 0.099, 0.102, 0.104, 0.099, 0.1, 0.099, 0.099, 0.111, 0.098, 0.102, 0.1]}	16	33	False
2	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:False input:-1,0,1,2,3 layer:deconv1d out_channels:36 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:5 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:6 layer:deconv1d out_channels:66 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:conv1d out_channels:9 kernel_size:4 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:8 layer:conv1d out_channels:98 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:10 layer:fc act:selu out_features:200 bias:True input:11 learning:rmsprop lr:0.0004931928948659201 alpha:0.739486597662427 weight_decay:7.08634222081631e-05 batch_size:4 epochs:50	18	200	True	0.10658		407042	13	-1	208.913227558136	{'train_loss': [0.995, 0.394, 0.203, 0.154, 0.138, 0.13, 0.126, 0.123, 0.122, 0.121, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12], 'val_loss': [0.545, 0.23, 0.14, 0.119, 0.118, 0.105, 0.103, 0.105, 0.101, 0.1, 0.101, 0.099, 0.098, 0.099, 0.099, 0.101, 0.101, 0.098]}	18	18	False
3	layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:punctual_mlp input:-1 layer:conv1d out_channels:18 kernel_size:2 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:-1,0,1,2,3 layer:deconv1d out_channels:26 kernel_size:4 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:4 layer:deconv1d out_channels:61 kernel_size:1 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:5 layer:conv1d out_channels:128 kernel_size:4 stride:1 padding_deconv:2 bias:True act:selu internal_dropout_p:0.2 internal_batch_norm:True input:6 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:2 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:7 layer:deconv1d out_channels:66 kernel_size:3 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:False bias:True input:8 layer:deconv1d out_channels:128 kernel_size:2 stride:2 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:9 layer:conv1d out_channels:98 kernel_size:3 stride:1 padding_deconv:1 internal_dropout_p:0.2 act:selu internal_batch_norm:True bias:True input:10 layer:conv1d out_channels:1 kernel_size:3 stride:1 padding_deconv:1 bias:True act:linear internal_batch_norm:False input:11 layer:fc act:selu out_features:200 bias:True input:12 learning:gradient_descent lr:0.0004931928948659201 momentum:0.711845021597461 weight_decay:3.96521555266397e-05 nesterov:False batch_size:35 epochs:50	50	200	True	1.67763		948038	14	-1	181.31825137138367	{'train_loss': [4.645, 2.523, 2.176, 2.077, 2.038, 2.008, 1.98, 1.955, 1.934, 1.915, 1.898, 1.881, 1.866, 1.849, 1.831, 1.812, 1.79, 1.765, 1.739, 1.728, 1.735, 1.737, 1.737, 1.732, 1.73, 1.727, 1.725, 1.721, 1.72, 1.717, 1.715, 1.713, 1.712, 1.71, 1.707, 1.706, 1.704, 1.703, 1.7, 1.699, 1.698, 1.696, 1.695, 1.692, 1.691, 1.69, 1.689, 1.688, 1.686, 1.684], 'val_loss': [2.069, 1.852, 1.838, 1.839, 1.814, 1.795, 1.779, 1.771, 1.768, 1.767, 1.77, 1.769, 1.776, 1.773, 1.767, 1.759, 1.744, 1.725, 1.703, 1.711, 1.712, 1.73, 1.722, 1.713, 1.715, 1.712, 1.704, 1.704, 1.705, 1.7, 1.697, 1.7, 1.697, 1.699, 1.694, 1.687, 1.685, 1.687, 1.678, 1.683, 1.681, 1.675, 1.679, 1.675, 1.673, 1.672, 1.67, 1.669, 1.668, 1.667]}	50	50	True
