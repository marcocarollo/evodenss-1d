{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/marco/Desktop/units/Thesis/PPCon-evo/evodenss')\n",
    "import pandas as pd\n",
    "from evodenss.dataset.dataset_loader import FloatDataset, MyDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch\n",
    "\n",
    "\n",
    "#data = pd.read_csv('/home/marco/Desktop/units/Thesis/PPCon/ds/BBP700/float_ds_sf_removed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's merge the two datasets\n",
    "dataset = pd.concat([dataset1.df, dataset2.df], axis=1, ignore_index=True)\n",
    "#drop the first 4 rows\n",
    "dataset = dataset.drop(dataset.columns[[0,1,2,3]], axis=0)\n",
    "#transpose the dataset\n",
    "dataset = dataset.transpose()\n",
    "\n",
    "dataset.iloc[30,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = FloatDataset(path_df='/home/marco/Desktop/units/Thesis/PPCon/ds/BBP700/float_ds_sf_train.csv')\n",
    "testing_dataset = FloatDataset(path_df='/home/marco/Desktop/units/Thesis/PPCon/ds/BBP700/float_ds_sf_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manageable_data(dataset):\n",
    "    \"\"\"\n",
    "    This function is used to get the data in a format that can be used by the model, i.e. \n",
    "    the data is returned in a tensor of shape (n_samples, n_time_steps, n_features = 4)\n",
    "    Dataset is the output of __getitem__ method of the FloatDataset class, that uses the\n",
    "    from_string_to_tensor method to convert the string to a single entry of the dataset.\n",
    "    \"\"\"\n",
    "    data = dataset[0][4].unsqueeze(0)\n",
    "    for i in range(1, len(dataset)):\n",
    "        data = torch.cat((data, dataset[i][4].unsqueeze(0)),0 )\n",
    "    data = data.unsqueeze(2)\n",
    "    for j in range(5,8):\n",
    "        data2 = dataset[0][j].unsqueeze(0)\n",
    "        for i in range(1, len(dataset)):\n",
    "            data2 = torch.cat((data2, dataset[i][j].unsqueeze(0)),0 )\n",
    "        data2 = data2.unsqueeze(2)\n",
    "        data = torch.cat((data, data2),2)\n",
    "    return data\n",
    "\n",
    "train_data = get_manageable_data(training_dataset)\n",
    "test_data = get_manageable_data(testing_dataset)\n",
    "\n",
    "test_data, val_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(train_data.shape, test_data.shape, val_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's switch the last two dimensions of the data\n",
    "#train_data = train_data.permute(0,2,1)\n",
    "#test_data = test_data.permute(0,2,1)\n",
    "#val_data = val_data.permute(0,2,1)\n",
    "\n",
    "\n",
    "\n",
    "torch.save(train_data, '/home/marco/Desktop/units/PPCon-evo/evodenss/data/ds/BBP700/train_data.pt')\n",
    "torch.save(test_data, '/home/marco/Desktop/units/PPCon-evo/evodenss/data/ds/BBP700/test_data.pt')\n",
    "torch.save(val_data, '/home/marco/Desktop/units/PPCon-evo/evodenss/data/ds/BBP700/val_data.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3980, 4, 200]),\n",
       " torch.Size([498, 4, 200]),\n",
       " torch.Size([498, 4, 200]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3980, 4, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('/home/marco/Desktop/units/PPCon-evo/evodenss/data/ds/BBP700/train_data.pt')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([498, 3, 200])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_df=None, path_tensor = None, transform=None):\n",
    "        super(MyDataset, self).__init__()\n",
    "        if path_df is not None:\n",
    "            self.path_df = path_df\n",
    "            self.df = pd.read_csv(self.path_df)\n",
    "            self.data = self.df.iloc[:, :-1].values\n",
    "            self.targets = self.df.iloc[:, -1].values\n",
    "\n",
    "        elif path_tensor is not None:\n",
    "            self.df = torch.load(path_tensor)\n",
    "            self.data = self.df[:,:-1, :]\n",
    "            self.targets = self.df[:,-1, :]\n",
    "        else:\n",
    "            raise Exception(\"Paths should be given as input to initialize the Float class.\")\n",
    "        self.transform = transform\n",
    "     \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "train_data = MyDataset(path_tensor='/home/marco/Desktop/units/PPCon-evo/evodenss/data/ds/BBP700/test_data.pt')\n",
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "from parameterized import parameterized\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from evodenss.config.pydantic import DataSplits, DownstreamTrain, EvoTest, Labelled, Validation, init_context\n",
    "from evodenss.dataset.dataset_loader import DatasetProcessor, DatasetType\n",
    "from evodenss.misc.constants import DEFAULT_SEED\n",
    "from evodenss.misc.enums import LearningType\n",
    "from evodenss.networks.transformers import LegacyTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processor = DatasetProcessor(\n",
    "            ssl_transformer=None,\n",
    "            train_transformer=LegacyTransformer({}),\n",
    "            test_transformer=LegacyTransformer({})\n",
    "        )\n",
    "with init_context({'learning_type': LearningType.supervised}):\n",
    "    train_partition_ratio = 0.007\n",
    "    validation_partition_ratio = 0.001\n",
    "    test_partition_ratio = 0.002\n",
    "    data_splits = DataSplits(\n",
    "        unlabelled=None,\n",
    "        labelled=Labelled(\n",
    "            percentage=1,\n",
    "            downstream_train=DownstreamTrain(\n",
    "                partition_ratio=train_partition_ratio,\n",
    "                amount_to_use=1.0,\n",
    "                replacement=False),\n",
    "            validation=Validation(\n",
    "                partition_ratio=validation_partition_ratio,\n",
    "                amount_to_use=1.0,\n",
    "                replacement=False),\n",
    "            evo_test=EvoTest(\n",
    "                partition_ratio=test_partition_ratio,\n",
    "                amount_to_use=1.0,\n",
    "                replacement=False)\n",
    "        )\n",
    "    )\n",
    "subset_dict = dataset_processor.load_partitioned_dataset(\n",
    "        dataset_name=\"mnist\",\n",
    "        proportions=data_splits,\n",
    "        seed=DEFAULT_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n"
     ]
    }
   ],
   "source": [
    "train_labelled_data = CIFAR10(\n",
    "            root=\"data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=LegacyTransformer({})\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labelled_data.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LegacyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LegacyNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1d_1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=36, kernel_size=5, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv1d_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=36, out_channels=39, kernel_size=3, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.conv1d_3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=39, out_channels=63, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv1d_4 = nn.Conv1d(in_channels=63, out_channels=69, kernel_size=4, stride=1, padding=1)  # Padding = same\n",
    "        self.conv1d_5 = nn.Conv1d(in_channels=69, out_channels=45, kernel_size=3, stride=1, padding=1)  # Padding = same\n",
    "        self.conv1d_6 = nn.Conv1d(in_channels=45, out_channels=14, kernel_size=2, stride=2, padding=0, bias=False)\n",
    "\n",
    "        self.fc_1 = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(in_features=322, out_features=200, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=200, out_features=200, bias=True),\n",
    "            nn.Softmax(dim=None)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d_1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d_2(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d_3(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d_4(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d_5(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d_6(x)\n",
    "        print(x.shape)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        return x\n",
    "\n",
    "# Example of creating the model\n",
    "model = LegacyNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([123, 3, 200])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_train = a[:123,:3,:]\n",
    "batch_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 36, 98])\n",
      "torch.Size([123, 39, 96])\n",
      "torch.Size([123, 63, 48])\n",
      "torch.Size([123, 69, 47])\n",
      "torch.Size([123, 45, 47])\n",
      "torch.Size([123, 14, 23])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/evodenss/lib/python3.10/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0046, 0.0051, 0.0047,  ..., 0.0053, 0.0052, 0.0050],\n",
       "        [0.0046, 0.0051, 0.0047,  ..., 0.0053, 0.0052, 0.0050],\n",
       "        [0.0046, 0.0051, 0.0047,  ..., 0.0053, 0.0052, 0.0050],\n",
       "        ...,\n",
       "        [0.0046, 0.0051, 0.0047,  ..., 0.0053, 0.0052, 0.0050],\n",
       "        [0.0046, 0.0051, 0.0047,  ..., 0.0053, 0.0052, 0.0050],\n",
       "        [0.0046, 0.0051, 0.0047,  ..., 0.0053, 0.0052, 0.0050]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evodenss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
